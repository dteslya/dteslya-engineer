{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"about/","title":"About","text":"<p>My name is Dmitry Teslya. I'm a network engineer with 14+ years of experience. Most part of my career I worked for variuos Value-added Resellers building networks for our customers. My technical background includes network design and operations, customer consulting and as of recently software development.</p> <p>Here I try to write about interesting technical challenges I face in my daily work and I hope you'll find something helpful to take away.</p> <p>In March, 2022 I moved to Colombo, Sri Lanka with my family.</p> <p>If you want to get in touch you can PM me on twitter or facebook.</p>"},{"location":"blog/","title":"Blog","text":""},{"location":"blog/2019/02/25/how-to-automate-openvpn-server-deployment-and-user-management/","title":"How to Automate OpenVPN Server Deployment and User Management","text":"<p>Recently I\u2019ve been tasked to come up with a VPN solution which must support: - All major desktop and mobile OSes as clients - Clients behind NAT - Mikrotik RouterOS as a client - Site-to-site and remote access VPNs</p> <p>First, I had to decide whether it will be a dedicated hardware appliance or software running on a VM. The latter was more appealing because of its flexibility and ease of deployment.</p> <p>Second, I needed to choose the actual software. The following options were considered: - IPSEC implementations such as FreeSWAN, OpenSWAN or strongSWAN - OpenVPN - SoftEther</p> <p>OpenVPN was chosen because of its huge user base, cross-platform client support, and extensive customization options.</p> <p>Of course, I decided to adopt the \u201cinfrastructure as code\u201d approach from the start so my solution could be easily reproduced and shared across my team in the future. Once again Ansible was my weapon of choice when it came to picking an automation tool. I did some googling and came across a couple of ready-made setups on Github, namely ansible-openvpn and ansible-openvpn-hardened (the former being a fork of the latter). I liked the approach of ansible-openvpn more and used it as a starting point for my own project. I needed some extra features that\u2019s why I couldn\u2019t use that repo as it was.</p>","tags":["openvpn","ansible","mikrotik"]},{"location":"blog/2019/02/25/how-to-automate-openvpn-server-deployment-and-user-management/#setting-up-ansible","title":"Setting up Ansible","text":"<ul> <li>Install Ansible following the official installation guide</li> <li>Clone my GitHub repo and cd to ansible-ovpn-mikrotik</li> <li>Copy the sample inventory and variables files to edit for your setup. (I will use <code>my_project</code> as an example for the rest of this post)</li> </ul> <p><code>cp -r inventories/sample inventories/my_project</code> - Edit inventories/my_project/hosts.ini to target your desired host.</p> <p>Ansible uses SSH keys for authentication. You need to copy your public key to the target host in order for Ansible to work. The easiest way to do it is <code>ssh-copy-id</code> utility. Run</p> <p><code>ssh-copy-id ansible_user@target_host</code> where <code>ansible_user</code> is the username Ansible runs as on the target host.</p> <p>You also need to supply <code>ansible_become_pass</code> which Ansible \u201centers\u201d when sudoing. Please, consider using Ansible Vault to avoid storing user passwords in cleartext.</p>","tags":["openvpn","ansible","mikrotik"]},{"location":"blog/2019/02/25/how-to-automate-openvpn-server-deployment-and-user-management/#sample-network-topology","title":"Sample network topology","text":"<p>To illustrate what I was trying to achieve with OpenVPN I drew this simple network topology. </p> <p></p> <p>I have an OpenVPN server attached to <code>10.5.0.0/16</code> subnet and <code>172.16.0.0/12</code> subnet behind the Mikrotik router. Both subnets should be accessible by remote users. The <code>192.168.x.x/24</code> networks are used for tunnel interfaces. More on that later.</p>","tags":["openvpn","ansible","mikrotik"]},{"location":"blog/2019/02/25/how-to-automate-openvpn-server-deployment-and-user-management/#setting-variables","title":"Setting variables","text":"<p>Before running any of the playbooks you need to edit <code>inventories/my_project/group_vars/all.yml</code> file. Almost all options are well commented in the file itself. However, some parameters demand a more comprehensive explanation.</p> Parameter Description <code>openvpn_server_common_name_manual</code> OpenVPN server CN used in certificates. Will be generated automatically if not defined. I prefer to set this manually. <code>openvpn_instances</code> You can describe several OpenVPN instances here which will run simultaneously on the same host. I use this to create two separate instances: one listening on UDP/1194 for remote clients, and the other listening on TCP/443 for Mikrotik router which doesn't support UDP. Also, remote clients behind restrictive firewalls also can use TCP instance. <code>server_extra_options</code> This can be used to supply extra options to the server config. For example, you can use <code>route</code> option to add a route to the server's routing table or <code>push route</code> to propagate static routes to the clients. <code>client_extra_options</code> Use this to pass extra options to the clients configs. For example, you can set a DNS server for clients to use with <code>dhcp-option DNS &lt;ip&gt;</code> option. <code>valid_clients</code> This list of users is read by <code>sync_clients.yml</code> playbook to add and remove clients. You must at least set the <code>name</code> parameter to define a user. To add any custom options for a particular client specify <code>ccd</code> parameter. I use <code>ccd</code> to define networks behind the Mikrotik router with <code>iroute</code> option. Please, refer to the openvpn man page for details about the <code>--client-config-dir</code> option. <code>load_iptables_rules</code> If you apply <code>install.yml</code> playbook to the freshly installed system I recommend setting this option to <code>true</code>. However, when applying to the existing installation consider checking the <code>playbooks/roles/openvpn/templates/etc_iptables_rules.v4.j2</code> file first.","tags":["openvpn","ansible","mikrotik"]},{"location":"blog/2019/02/25/how-to-automate-openvpn-server-deployment-and-user-management/#installing-openvpn","title":"Installing OpenVPN","text":"<p>Now you can try and run the install playbook by issuing this command: <pre><code>ansible-playbook -i inventories/my_project/hosts.ini  playbooks/install.yml\n</code></pre> Sample output is shown below. <pre><code>$ ansible-playbook -i inventories/my_project/hosts.ini  playbooks/install.yml\n\nPLAY [Install required software, configure and harden] *************************************************************************************************************************************************************************************************************************\n\nTASK [OpenVPN | install | Install python2 if necessary] ************************************************************************************************************************************************************************************************************************\nThe authenticity of host '10.5.202.10 (10.5.202.10)' can't be established.\nECDSA key fingerprint is SHA256:Rl4wWtHZESb5F6wfqxF3s+FhDp9GdAZDlBq1/nRJlNw.\nAre you sure you want to continue connecting (yes/no)? yes\nok: [10.5.202.10]\n\nTASK [OpenVPN | install | Gather facts after python2 is available] *************************************************************************************************************************************************************************************************************\nok: [10.5.202.10]\n\nTASK [openvpn : OpenVPN | Install | Set Distro/Version specific variables] *****************************************************************************************************************************************************************************************************\nok: [10.5.202.10] =&gt; (item=/Users/dteslya/automation/ansible-openvpn/playbooks/roles/openvpn/vars/../vars/Debian.yml)\n\nTASK [openvpn : OpenVPN | package | Ensure the APT cache is up to date] ********************************************************************************************************************************************************************************************************\nok: [10.5.202.10]\n\nTASK [openvpn : OpenVPN | package | Install Debian specific packages] **********************************************************************************************************************************************************************************************************\nok: [10.5.202.10] =&gt; (item=None)\n\nTASK [openvpn : OpenVPN | package | Add debian backports] **********************************************************************************************************************************************************************************************************************\nskipping: [10.5.202.10]\n\nTASK [openvpn : OpenVPN | package | Upgrade systemd on debian] *****************************************************************************************************************************************************************************************************************\nskipping: [10.5.202.10]\n\nTASK [openvpn : OpenVPN | package | Install required packages] *****************************************************************************************************************************************************************************************************************\nok: [10.5.202.10] =&gt; (item=sudo)\nchanged: [10.5.202.10] =&gt; (item=python-pip)\nchanged: [10.5.202.10] =&gt; (item=python-virtualenv)\nok: [10.5.202.10] =&gt; (item=git)\nok: [10.5.202.10] =&gt; (item=gawk)\nok: [10.5.202.10] =&gt; (item=gnupg)\nok: [10.5.202.10] =&gt; (item=iptables)\nchanged: [10.5.202.10] =&gt; (item=iptables-persistent)\nok: [10.5.202.10] =&gt; (item=netfilter-persistent)\nchanged: [10.5.202.10] =&gt; (item=wamerican-huge)\nok: [10.5.202.10] =&gt; (item=openssl)\nchanged: [10.5.202.10] =&gt; (item=openvpn)\n\nTASK [openvpn : OpenVPN | package | Install pexpect via pip] *******************************************************************************************************************************************************************************************************************\nchanged: [10.5.202.10]\n\nTASK [openvpn : OpenVPN | PKI | EasyRSA Checkout] ******************************************************************************************************************************************************************************************************************************\nchanged: [10.5.202.10]\n\nTASK [openvpn : OpenVPN | PKI | Make local destination folder] *****************************************************************************************************************************************************************************************************************\nchanged: [10.5.202.10 -&gt; localhost]\n\nTASK [openvpn : OpenVPN | PKI | Generate a random server common name] **********************************************************************************************************************************************************************************************************\nskipping: [10.5.202.10]\n\nTASK [openvpn : OpenVPN | PKI | Set server common name] ************************************************************************************************************************************************************************************************************************\nchanged: [10.5.202.10]\n\nTASK [openvpn : OpenVPN | PKI | Register the OpenVPN server common name] *******************************************************************************************************************************************************************************************************\nok: [10.5.202.10]\n\nTASK [openvpn : OpenVPN | PKI | Generate CA password] **************************************************************************************************************************************************************************************************************************\nchanged: [10.5.202.10]\n\nTASK [openvpn : OpenVPN | PKI | Store CA password] *****************************************************************************************************************************************************************************************************************************\nchanged: [10.5.202.10 -&gt; localhost]\n\nTASK [openvpn : OpenVPN | PKI | Set CA password variable] **********************************************************************************************************************************************************************************************************************\nskipping: [10.5.202.10]\n\nTASK [openvpn : OpenVPN | PKI | Set common name variable] **********************************************************************************************************************************************************************************************************************\nok: [10.5.202.10]\n\nTASK [openvpn : OpenVPN | PKI | Set server key and cert path variables] ********************************************************************************************************************************************************************************************************\nok: [10.5.202.10]\n\nTASK [openvpn : OpenVPN | PKI | EasyRSA Link project] **************************************************************************************************************************************************************************************************************************\n [WARNING]: Cannot set fs attributes on a non-existent symlink target. follow should be set to False to avoid this.\n\nchanged: [10.5.202.10]\n\nTASK [openvpn : OpenVPN | PKI | Deploy vars configuration] *********************************************************************************************************************************************************************************************************************\nchanged: [10.5.202.10]\n\nTASK [openvpn : OpenVPN | PKI | Intialize PKI] *********************************************************************************************************************************************************************************************************************************\nchanged: [10.5.202.10]\n\nTASK [openvpn : OpenVPN | PKI | Build CA] **************************************************************************************************************************************************************************************************************************************\nchanged: [10.5.202.10]\n\nTASK [openvpn : OpenVPN | PKI | Build CRL] *************************************************************************************************************************************************************************************************************************************\nchanged: [10.5.202.10]\n\nTASK [openvpn : OpenVPN | PKI | Add server] ************************************************************************************************************************************************************************************************************************************\nchanged: [10.5.202.10]\n\nTASK [openvpn : OpenVPN | PKI | Build ta.key] **********************************************************************************************************************************************************************************************************************************\nchanged: [10.5.202.10]\n\nTASK [openvpn : OpenVPN | PKI | Build dh.pem] **********************************************************************************************************************************************************************************************************************************\nchanged: [10.5.202.10]\n\nTASK [openvpn : OpenVPN | Add Clients | Get CA cert] ***************************************************************************************************************************************************************************************************************************\nchanged: [10.5.202.10]\n\nTASK [openvpn : OpenVPN | sysctl | Enable IPv4 traffic forwarding] *************************************************************************************************************************************************************************************************************\nchanged: [10.5.202.10]\n\nTASK [openvpn : OpenVPN | Configuration | Create client configuration directory] ***********************************************************************************************************************************************************************************************\nchanged: [10.5.202.10]\n\nTASK [openvpn : OpenVPN | Configuration | Copy OpenVPN server configuration files into place] **********************************************************************************************************************************************************************************\nchanged: [10.5.202.10] =&gt; (item={'proto': 'udp', 'port': 1194, 'mask': '192.168.68.0 255.255.255.0', 'cidr': '192.168.68.0/24', 'server_extra_options': ['push \"redirect-gateway def1\"'], 'client_extra_options': []})\n\nTASK [openvpn : OpenVPN | systemd | Enable services] ***************************************************************************************************************************************************************************************************************************\nchanged: [10.5.202.10] =&gt; (item={'proto': 'udp', 'port': 1194, 'mask': '192.168.68.0 255.255.255.0', 'cidr': '192.168.68.0/24', 'server_extra_options': ['push \"redirect-gateway def1\"'], 'client_extra_options': []})\n\nTASK [openvpn : OpenVPN | Firewall | Reread ansible_default_ipv4] **************************************************************************************************************************************************************************************************************\nok: [10.5.202.10]\n\nTASK [openvpn : OpenVPN | Firewall | Flush existing firewall rules] ************************************************************************************************************************************************************************************************************\nok: [10.5.202.10]\n\nTASK [openvpn : OpenVPN | Firewall | Write iptables rules file] ****************************************************************************************************************************************************************************************************************\nchanged: [10.5.202.10]\n\nTASK [openvpn : OpenVPN | Firewall | Load iptables rules] **********************************************************************************************************************************************************************************************************************\nok: [10.5.202.10]\n\nRUNNING HANDLER [openvpn : start openvpn] **************************************************************************************************************************************************************************************************************************************\nchanged: [10.5.202.10] =&gt; (item={'proto': 'udp', 'port': 1194, 'mask': '192.168.68.0 255.255.255.0', 'cidr': '192.168.68.0/24', 'server_extra_options': ['push \"redirect-gateway def1\"'], 'client_extra_options': []})\n\nPLAY RECAP *********************************************************************************************************************************************************************************************************************************************************************\n10.5.202.10              : ok=33   changed=22   unreachable=0    failed=0\n</code></pre> To check if the OpenVPN process is running issue this command on the target host: <pre><code>$ systemctl status openvpn@udp-1194\n\u25cf openvpn@udp-1194.service - OpenVPN connection to udp-1194\n   Loaded: loaded (/lib/systemd/system/openvpn@.service; indirect; vendor preset: enabled)\n   Active: active (running) since Thu 2019-02-21 12:20:22 UTC; 3 days ago\n     Docs: man:openvpn(8)\n           https://community.openvpn.net/openvpn/wiki/Openvpn24ManPage\n           https://community.openvpn.net/openvpn/wiki/HOWTO\n Main PID: 30925 (openvpn)\n   Status: \"Initialization Sequence Completed\"\n    Tasks: 1 (limit: 1111)\n   CGroup: /system.slice/system-openvpn.slice/openvpn@udp-1194.service\n           \u2514\u250030925 /usr/sbin/openvpn --daemon ovpn-udp-1194 --status /run/openvpn/udp-1194.status 10 --cd /etc/openvpn --script-security 2 --config /etc/openvpn/udp-1194.conf --writepid /run/openvpn/udp-1194.pid\n\nWarning: Journal has been rotated since unit was started. Log output is incomplete or unavailable.\n</code></pre> Now we can proceed to add clients.</p>","tags":["openvpn","ansible","mikrotik"]},{"location":"blog/2019/02/25/how-to-automate-openvpn-server-deployment-and-user-management/#managing-client-keys","title":"Managing client keys","text":"<p>The list of currently valid clients is kept in <code>inventories/my_project/group_vars/all.yml</code>. A typical user entry looks like this: <pre><code>- name: user1                 # mandatory\nccd: ['option1', 'option2'] # optional\n</code></pre> You can omit <code>ccd</code> string entirely if you don't need any custom options for the client.</p> <p>After adding some clients you can run the <code>sync_clients.yml</code> playbook. At some point it will list clients to add and/or delete and ask you whether to proceed. <pre><code>$ ansible-playbook playbooks/sync_clients.yml -i inventories/my_project/hosts.ini\n\nPLAY [Sync desired valid clients with OpenVPN's current PKI] *******************************************************************************************************************************************************************************************************************\n\nTASK [Gathering Facts] *********************************************************************************************************************************************************************************************************************************************************\nok: [10.5.202.10]\n\nTASK [sync_clients : OpenVPN | Sync Clients | Register the OpenVPN server common name] *****************************************************************************************************************************************************************************************\nok: [10.5.202.10]\n\nTASK [sync_clients : OpenVPN | Sync Clients | Set server common name variable] *************************************************************************************************************************************************************************************************\nok: [10.5.202.10]\n\nTASK [sync_clients : OpenVPN | Sync Clients | Get clients that are currently valid] ********************************************************************************************************************************************************************************************\nok: [10.5.202.10]\n\nTASK [sync_clients : OpenVPN | Sync Clients | Get list of desired valid clients] ***********************************************************************************************************************************************************************************************\nok: [10.5.202.10]\n\nTASK [sync_clients : OpenVPN | Sync Clients | Set facts] ***********************************************************************************************************************************************************************************************************************\nok: [10.5.202.10]\n\nTASK [sync_clients : OpenVPN | Sync Clients | Sync clients that will be revoked] ***********************************************************************************************************************************************************************************************\nok: [10.5.202.10]\n\nTASK [sync_clients : OpenVPN | Sync Clients | Sync clients that will be added] *************************************************************************************************************************************************************************************************\nok: [10.5.202.10]\n\nTASK [sync_clients : OpenVPN | Sync Clients | Ask user if we should proceed] ***************************************************************************************************************************************************************************************************\n[sync_clients : OpenVPN | Sync Clients | Ask user if we should proceed]\nWe will add ['user1', 'user2'] and we will revoke []. Press 'Y' or 'y' to proceed:\nok: [10.5.202.10]\n\nTASK [sync_clients : OpenVPN | Sync Clients | Abort if user does not want to proceed] ******************************************************************************************************************************************************************************************\nskipping: [10.5.202.10]\n\nTASK [OpenVPN | Sync Clients | Add clients] ************************************************************************************************************************************************************************************************************************************\n\nTASK [add_clients : OpenVPN | Add Clients | Set variables] *********************************************************************************************************************************************************************************************************************\nok: [10.5.202.10]\n\nTASK [add_clients : OpenVPN | Add Clients | Register the OpenVPN server common name] *******************************************************************************************************************************************************************************************\nok: [10.5.202.10]\n\nTASK [add_clients : OpenVPN | Add Clients | Set server common name variable] ***************************************************************************************************************************************************************************************************\nok: [10.5.202.10]\n\nTASK [add_clients : OpenVPN | Add Clients | Check for existing private key passwords] ******************************************************************************************************************************************************************************************\nok: [10.5.202.10 -&gt; localhost] =&gt; (item=user1)\nok: [10.5.202.10 -&gt; localhost] =&gt; (item=user2)\n\nTASK [add_clients : OpenVPN | Add Clients | Generate private key passwords] ****************************************************************************************************************************************************************************************************\nchanged: [10.5.202.10] =&gt; (item=None)\nchanged: [10.5.202.10] =&gt; (item=None)\nchanged: [10.5.202.10]\n\nTASK [add_clients : OpenVPN | Add Clients | Make local destination] ************************************************************************************************************************************************************************************************************\nchanged: [10.5.202.10 -&gt; localhost] =&gt; (item=user1)\nchanged: [10.5.202.10 -&gt; localhost] =&gt; (item=user2)\n\nTASK [add_clients : OpenVPN | Add Clients | Write private key pass phrases] ****************************************************************************************************************************************************************************************************\nchanged: [10.5.202.10 -&gt; localhost] =&gt; (item=None)\nchanged: [10.5.202.10 -&gt; localhost] =&gt; (item=None)\nchanged: [10.5.202.10]\n\nTASK [add_clients : OpenVPN | Add Clients | Read private key pass phrases] *****************************************************************************************************************************************************************************************************\nok: [10.5.202.10 -&gt; localhost] =&gt; (item=None)\nok: [10.5.202.10 -&gt; localhost] =&gt; (item=None)\nok: [10.5.202.10]\n\nTASK [add_clients : OpenVPN | Add Clients | Build Clients] *********************************************************************************************************************************************************************************************************************\nchanged: [10.5.202.10] =&gt; (item=None)\nchanged: [10.5.202.10] =&gt; (item=None)\nchanged: [10.5.202.10]\n\nTASK [add_clients : OpenVPN | Add Clients | Make client configuration directory] ***********************************************************************************************************************************************************************************************\nok: [10.5.202.10]\n\nTASK [add_clients : OpenVPN | Add Clients | Register CA certificate contents] **************************************************************************************************************************************************************************************************\nok: [10.5.202.10]\n\nTASK [add_clients : OpenVPN | Add Clients | Register HMAC firewall key contents] ***********************************************************************************************************************************************************************************************\nok: [10.5.202.10]\n\nTASK [add_clients : OpenVPN | Add Clients | Register client key contents] ******************************************************************************************************************************************************************************************************\nok: [10.5.202.10] =&gt; (item=None)\nok: [10.5.202.10] =&gt; (item=None)\nok: [10.5.202.10]\n\nTASK [add_clients : OpenVPN | Add Clients | Register client certificate contents] **********************************************************************************************************************************************************************************************\nok: [10.5.202.10] =&gt; (item=None)\nok: [10.5.202.10] =&gt; (item=None)\nok: [10.5.202.10]\n\nTASK [add_clients : OpenVPN | Add Clients | Build client configs (.ovpn files; pki embedded)] **********************************************************************************************************************************************************************************\nchanged: [10.5.202.10] =&gt; (item=None)\nchanged: [10.5.202.10] =&gt; (item=None)\nchanged: [10.5.202.10]\n\nTASK [add_clients : OpenVPN | Add Clients | Build client configs (.ovpn files; pki external files)] ****************************************************************************************************************************************************************************\nchanged: [10.5.202.10] =&gt; (item=None)\nchanged: [10.5.202.10] =&gt; (item=None)\nchanged: [10.5.202.10]\n\nTASK [add_clients : OpenVPN | Add Clients | Get list of clients with ccd defined] **********************************************************************************************************************************************************************************************\nok: [10.5.202.10]\n\nTASK [add_clients : OpenVPN | Add Clients | Build ccd configs] *****************************************************************************************************************************************************************************************************************\n\nTASK [add_clients : OpenVPN | Add Clients | Build client configs (.ovpn files; external pkcs12)] *******************************************************************************************************************************************************************************\nchanged: [10.5.202.10] =&gt; (item=None)\nchanged: [10.5.202.10] =&gt; (item=None)\nchanged: [10.5.202.10]\n\nTASK [add_clients : OpenVPN | Add Clients | Generate PKCS#12] ******************************************************************************************************************************************************************************************************************\nchanged: [10.5.202.10] =&gt; (item=None)\nchanged: [10.5.202.10] =&gt; (item=None)\nchanged: [10.5.202.10]\n\nTASK [add_clients : OpenVPN | Add Clients | Get .ovpn files (*-pki-embedded.ovpn)] *********************************************************************************************************************************************************************************************\nchanged: [10.5.202.10] =&gt; (item=user1)\nchanged: [10.5.202.10] =&gt; (item=user2)\n\nTASK [add_clients : OpenVPN | Add Clients | Get .ovpn files (*-pki-files.ovpn)] ************************************************************************************************************************************************************************************************\nchanged: [10.5.202.10] =&gt; (item=user1)\nchanged: [10.5.202.10] =&gt; (item=user2)\n\nTASK [add_clients : OpenVPN | Add Clients | Get .ovpn files (*-pkcs12.ovpn)] ***************************************************************************************************************************************************************************************************\nchanged: [10.5.202.10] =&gt; (item=user1)\nchanged: [10.5.202.10] =&gt; (item=user2)\n\nTASK [add_clients : OpenVPN | Add Clients | Get client PKCS#12 files] **********************************************************************************************************************************************************************************************************\nchanged: [10.5.202.10] =&gt; (item=user1)\nchanged: [10.5.202.10] =&gt; (item=user2)\n\nTASK [add_clients : OpenVPN | Add Clients | Get client CA cert] ****************************************************************************************************************************************************************************************************************\nchanged: [10.5.202.10] =&gt; (item=user1)\nchanged: [10.5.202.10] =&gt; (item=user2)\n\nTASK [add_clients : OpenVPN | Add Clients | Get client certs] ******************************************************************************************************************************************************************************************************************\nchanged: [10.5.202.10] =&gt; (item=user1)\nchanged: [10.5.202.10] =&gt; (item=user2)\n\nTASK [add_clients : OpenVPN | Add Clients | Get client keys] *******************************************************************************************************************************************************************************************************************\nchanged: [10.5.202.10] =&gt; (item=user1)\nchanged: [10.5.202.10] =&gt; (item=user2)\n\nTASK [add_clients : OpenVPN | Add Clients | Clear bash history] ****************************************************************************************************************************************************************************************************************\nok: [10.5.202.10]\n\nTASK [OpenVPN | Sync Clients | Revoke clients] *********************************************************************************************************************************************************************************************************************************\nskipping: [10.5.202.10]\n\nPLAY RECAP *********************************************************************************************************************************************************************************************************************************************************************\n10.5.202.10              : ok=36   changed=15   unreachable=0    failed=0\n</code></pre> This will produce 8 files for each user and put them in <code>fetched_creds\\&lt;target_hostname&gt;\\&lt;username&gt;</code> directory: <pre><code>&lt;username&gt;-pkcs12.ovpn        # user configuration pointing to .p12 file\n&lt;username&gt;-pki-embedded.ovpn  # all-in-one user configuration file (contains ca.crt, .crt and .key)\n&lt;username&gt;-pki-files.ovpn     # user configuration pointing to .crt and .key files\n&lt;username&gt;.crt                # user certificate\n&lt;username&gt;.key                # private key\n&lt;username&gt;.p12                # user cert and key in PFX format\nca.crt                        # CA certificate\n&lt;server_CN&gt;_pk_pass.txt       # private key password\n</code></pre> You need to send this files to the user. The embedded configuration and password file are sufficient for the most desktop clients (tested on OpenVPN for Windows, Tunnelblick and OpenVPN Connect for iOS).</p> <p>If you want to delete a client just remove the corresponding entry in <code>inventories/my_project/group_vars/all.yml</code> and re-run the playbook.</p> <p>You cannot delete and then re-enable a user. When you add a user with the same username you have deleted before a new certificate will be generated and you will have to resend it to the user.</p>","tags":["openvpn","ansible","mikrotik"]},{"location":"blog/2019/02/25/how-to-automate-openvpn-server-deployment-and-user-management/#configuring-mikrotik","title":"Configuring Mikrotik","text":"<p>To configure Mikrotik router as an OpenVPN client perform the following actions:</p> <ol> <li>Go to Files - Upload and upload the following files to the router: <ul> <li><code>.crt</code></li> <li><code>.key</code></li> <li><code>ca.crt</code></li> </ul> </li> <li>Go to System - Certificates and import all the files from the previous step. Specify the password from <code>&lt;server_CN&gt;_pk_pass.txt</code> for the <code>.key</code> file. You should get something like this:      </li> <li> <p>Go to Interfaces press Add New and select OVPN Client type. Specify the following parameters (must match the parameters listed in <code>openvpn_instances</code>):</p> <ul> <li>Connect To</li> <li>Port</li> <li>User: none</li> <li>Certificate</li> <li>Auth.</li> <li>Cipher   If everything is ok you should get the \"Status: connected | running\" string.</li> </ul> </li> <li> <p>Configure static routes and masquerading if needed.</p> </li> </ol> <p>In order for OpenVPN server to route networks behind the Mikrotik router you need to provide two options in the server configuration, namely <code>route</code> and <code>iroute</code>. The first one is specified within the <code>server_extra_options</code> list in the server instance description and the second one - in the <code>ccd</code> attribute of the mikrotik user in <code>inventories/my_project/group_vars/all.yml</code>.</p> <p>You can read about the roles of <code>route</code>, <code>iroute</code> and <code>push route</code> options in this article.</p> <p>As a result, you should have something like this in your <code>all.yml</code> for the Mikrotik to work:</p> <pre><code>openvpn_instances:\n- {\n      proto: tcp,\n      port: 443,\n      mask: \"192.168.70.0 255.255.255.0\",\n      cidr: \"192.168.70.0/24\",\n      server_extra_options: ['route 172.16.0.0 255.240.0.0', 'push \"route 172.16.0.0 255.240.0.0\"'],\n      client_extra_options: [],\n}\nvalid_clients:\n- name: mikrotik\nccd: ['iroute 172.16.0.0 255.240.0.0']\n</code></pre> <p>You may have noticed that <code>172.16.0.0</code> network is specified three times. According to this configuration, a route to this network should be installed on the Mikrotik pointing to the OpenVPN server (<code>push route</code>) and another route for the same network should be installed in the server routing table effectively creating a routing loop. But according to OpenVPN logic when the same network is specified with both <code>push route</code> and <code>iroute</code> options the latter takes precedence and the former is ignored. Indeed, why push a route to the client which owns that network. When other clients (with no <code>iroute</code> in ccd) connect to this instance, they get the route to <code>172.16.0.0</code> network and can communicate with hosts behind the Mikrotik.</p>","tags":["openvpn","ansible","mikrotik"]},{"location":"blog/2019/02/25/how-to-automate-openvpn-server-deployment-and-user-management/#windows-10-dns-issue","title":"Windows 10 DNS issue","text":"<p>There is a known issue with Windows 10 not using DNS servers specified in <code>.ovpn</code> config. You can overcome this either by adding <code>block-outside-dns</code> to client's <code>ccd</code> or by changing the VPN-adapter default metric.</p>","tags":["openvpn","ansible","mikrotik"]},{"location":"blog/2019/02/25/how-to-automate-openvpn-server-deployment-and-user-management/#conclusion","title":"Conclusion","text":"<p>I hope you found this article useful. Please, leave a comment if you have any suggestions or found any inaccuracies.</p>","tags":["openvpn","ansible","mikrotik"]},{"location":"blog/2023/05/18/automating-python-project-releases-with-commitizen/","title":"Automating Python project releases with commitizen","text":"Cover photo by Brett Jordan on Unsplash <p>In my previous post, I mentioned various tools meant to help implement code management best practices, but I didn't go into much detail about any of them. This time I'd like to focus on Commitizen which introduced me to the concept of conventional commit messages and automatic versioning.</p> <p>This post is meant to help you address the following concerns:</p> <ul> <li>Keeping a consistent changelog of your Python project.</li> <li>Versioning your project.</li> <li>Writing consistent meaningful commit messages.</li> <li>Automating all of the above.</li> </ul> <p>This post is divided into two parts: theoretical and practical. First, I'll go through the concepts behind Semantic Versioning and Conventional Commits. Then I'll show you how those concepts can be integrated into your project with the help of Commitizen.</p> <p>Let's get started!</p>","tags":["git","versioning","semver"]},{"location":"blog/2023/05/18/automating-python-project-releases-with-commitizen/#semantic-versioning","title":"Semantic Versioning","text":"<p>Semantic versioning, often abbreviated as SemVer, might be the most popular approach to versioning Python packages. It is quite simple and gives a clear idea about the underlying changes with each new version release.</p> <p>In essence, Semantic Versioning uses a three-part version number like this:</p> <p><code>MAJOR.MINOR.PATCH</code></p> <p>Each of these components is incremented based on the type of changes that occur in the software:</p> <ol> <li><code>MAJOR</code> (0.2.0 -&gt; 1.0.0): This is incremented when there is a change that is not backward-compatible. Major version zero is a special case. During the early stage of development, you could be making backward-incompatible changes every day, but you shouldn't increment the major version until your API is stable. That's why version 1.0.0 is usually used for the first stable release. After that incrementing the major version number means introducing breaking changes. For example, that could be removing or modifying the behavior of an existing feature. In other words, code that depends on your package would no longer work if you upgrade your package to a new major version.</li> <li><code>MINOR</code> (0.1.1 -&gt; 0.2.0): This is incremented when new functionality is added in a backward-compatible manner. That means new features or significant improvements have been added, but they won't disrupt the existing functionality of the software. Users can expect new features, but their current workflow won't be disrupted.</li> <li><code>PATCH</code> (0.1.0 -&gt; 0.1.1): This is incremented when backward-compatible bug fixes are made. These are changes that fix something that wasn't working as intended in the previous version, without adding any new features or changing the software's overall behavior.</li> </ol> <p>For instance, if a software version is 2.3.1, the next version could be 2.3.2 if a bug was fixed, 2.4.0 if a new feature was added, or 3.0.0 if there were breaking changes.</p> <p>Tip</p> <p>Usually, most of the changes happen within the PATCH and MINOR version increments. Having 2-digit PATCH or MINOR versions is fine.</p> <p>An important aspect of Semantic Versioning is that it provides a contract for dependency management. Tools like Poetry can rely on that to restrict which updates can be automatically installed. This way, unexpected breaking changes can be avoided.</p>","tags":["git","versioning","semver"]},{"location":"blog/2023/05/18/automating-python-project-releases-with-commitizen/#conventional-commits","title":"Conventional Commits","text":"<p>From the official site:</p> <p>The Conventional Commits specification is a lightweight convention on top of commit messages. It provides an easy set of rules for creating an explicit commit history; which makes it easier to write automated tools on top of. This convention dovetails with SemVer, by describing the features, fixes, and breaking changes made in commit messages.</p> <p>A conventional commit message follows this simple format:</p> <pre><code>&lt;type&gt;[optional scope]: &lt;description&gt;\n\n[optional body]\n\n[optional footer(s)]\n</code></pre> <p>Each part of the commit message serves a specific purpose:</p> <ol> <li>Type: This denotes the type of changes being made in the commit. There are two main types: <code>feat</code> (for a new feature, corresponds to <code>MINOR</code> in SemVer) and <code>fix</code> (for a bug fix, corresponds to <code>PATCH</code>). Other types such as <code>docs</code> (for documentation changes), <code>style</code> (for code style changes, e.g., formatting, missing semicolons), <code>refactor</code> (for refactoring existing code), etc. are also allowed. Any type/scope appended with <code>!</code> is considered a <code>BREAKING CHANGE</code> and corresponds to a <code>MAJOR</code> version change.</li> <li>Scope: This is optional and specifies the part of the codebase affected by the change, such as a module, function, or component.</li> <li>Description: This is a brief, concise description of the change, written in the imperative, present tense.</li> <li>Body: Also optional, the body provides a more detailed description of the change. It's separated from the subject by a blank line.</li> <li>Footer: A footer prefixed with <code>BREAKING CHANGE:</code> corresponds to a <code>MAJOR</code> version change. It must follow the git trailer convention and can also be used, for example, for issue reference.</li> </ol> <p>Info</p> <p>See the full specification for more details.</p> <p>You can find examples of conventional commit messages on the official site.</p> <p>Following the Conventional Commits specification when writing commit messages enables tools like Commitizen to automate version bumping and changelog generation.</p>","tags":["git","versioning","semver"]},{"location":"blog/2023/05/18/automating-python-project-releases-with-commitizen/#commitizen","title":"Commitizen","text":"<p>Now when we're done with the theory let's put it into practice. As an example, I'll be using the project that was generated from the template described in the previous post.</p> <p>I will skip the steps of creating a project here. Let's assume the following prerequisites are met:</p> <ul> <li>Project directory is created</li> <li>It's initialized as a git repository</li> <li>All dependencies are installed, including the commitizen tool</li> <li>Remote repository is not configured yet</li> </ul> <p>First, let's check the current version that we have after initializing the project.</p> <pre><code>cz version -p\n0.0.1\n</code></pre> <p>Now, let's assume that we've made some changes and are ready to make an initial commit.</p> <p>Let's bump the version and see what happens.</p> <p>As you can see, commitizen detected the <code>MINOR</code> version change and updated the <code>pyproject.toml</code> with the new version <code>0.1.0</code>. It also created a changelog file. After that it committed those changes and created a <code>0.1.0</code> tag.</p> <p>What if we introduce a breaking change?</p> <p>Apparently, a breaking change should have incremented the <code>MAJOR</code> version, but it didn't happen. The <code>MINOR</code> version was incremented instead. This is because the <code>major-version-zero</code> option was set to <code>true</code> in the commitizen configuration. This option is very handy during the initial rapid development stage, where a lot of breaking changes might be introduced. When you feel ready to release the first stable version, you can set this option to <code>false</code>. After that, <code>cz bump</code> will increment the <code>MAJOR</code> version as it should.</p> <p>To follow the conventional commits specification, it's important to use <code>cz commit</code> instead of <code>git commit</code> after incorporating commitizen into your workflow. It may take some time to adjust to the new process, but it ensures consistency.</p> <p>After you introduce commitizen into your workflow, you need to make new commits with <code>cz commit</code> instead of <code>git commit</code>. This might need some getting used to at first, but it guarantees that you're adhering to the conventional commits specification.</p> <p>To guarantee that no unconventional commits are added to your repository, you can use the <code>pre-commit</code> message hook that will utilize <code>cz check</code> to lint your commit messages. This hook is already included in my project template.</p>","tags":["git","versioning","semver"]},{"location":"blog/2023/05/18/automating-python-project-releases-with-commitizen/#gitlab-ci","title":"GitLab CI","text":"<p>To go even further with versioning automation, we can make it in a Gitlab pipeline.</p> <p>Each time there is a push or merge to the main branch a pipeline job will run <code>cz bump</code> and push the changes and the new tag back to the repository.</p> <p>Below is the example of such job taken from the <code>.gitlab-ci.yml</code> of my project template.</p> <pre><code>version-bump:\nstage: version-bump\nimage: python:3.11\ntags:\n- docker\nrules: # (1)!\n- if: '$CI_COMMIT_BRANCH == \"main\" &amp;&amp; $GITLAB_USER_LOGIN != $CI_USERNAME &amp;&amp; ($CI_PIPELINE_SOURCE == \"push\" || $CI_PIPELINE_SOURCE == \"merge_request_event\")' before_script:\n- pip3 install -U commitizen\nscript:\n- git config user.email $CI_EMAIL &amp;&amp; git config user.name $CI_USERNAME\n- git config http.sslVerify false # (2)!\n- git remote rm origin &amp;&amp; git remote add origin https://oauth2:$PROJECT_ACCESS_TOKEN@gitlab.example.com/$CI_PROJECT_NAMESPACE/$CI_PROJECT_NAME.git\n- git checkout -B \"$CI_COMMIT_REF_NAME\" \"$CI_COMMIT_SHA\"\n- cz bump --yes # execute auto bump and push to main\n- git push --follow-tags origin $CI_COMMIT_BRANCH:$CI_COMMIT_BRANCH # (3)!\n- cz version -p &gt; version # get the new software version and save into artifacts\nartifacts:\npaths:\n- version # (4)!\n</code></pre> <ol> <li><code>$GITLAB_USER_LOGIN != $CI_USERNAME</code> ensures that this job won't produce an infinite loop by triggering itself when pushing back to the main branch.</li> <li>Connecting to the internal self-hosted GitLab instance from a docker container will most probably cause an SSL error.</li> <li>For <code>--follow-tags</code> option to work and actually push a new tag to the repo you need to configure commitizen to use annotated tags (already done in the template).</li> <li>You can use this artifact to get the new version number in the subsequent CI jobs (for example, to tag a Docker image).</li> </ol> <p>It's based upon the example from the Gitlab tutorial present in the commitizen documentation. This is my attempt to make it more clean and simple.</p> <p>To get it working, you need to make some preparations in your Gitlab project settings.</p> <p>First, you need to create a project access token and grant it read-write access to the repository. It's role must also have a permission to push to the main branch (<code>Maintainer</code> by default).</p> <p>Go to the <code>Settings -&gt; Access Tokens</code> to do that.</p> <p> </p> GitLab project access token <p>Second, you need to set the following environment variables in <code>Settings -&gt; CI/CD -&gt; Variables</code>.</p> <p> </p> GitLab environment variables <p>Use the name and value of the token created in the previous step for <code>CI_USERNAME</code> and <code>PROJECT_ACCESS_TOKEN</code>, respectively. </p> <p><code>CI_EMAIL</code> can be anything, for example, <code>$CI_USERNAME@example.com</code>.</p> <p>Now you can try and push some changes to the main branch. This should produce something like this in the CI job log:</p> <pre><code>&lt;skipped&gt;\nSuccessfully installed MarkupSafe-2.1.2 argcomplete-3.0.8 charset-normalizer-3.1.0 colorama-0.4.6 commitizen-3.2.2 decli-0.6.0 importlib_metadata-6.6.0 jinja2-3.1.2 packaging-23.1 prompt_toolkit-3.0.38 pyyaml-6.0 questionary-1.10.0 termcolor-2.3.0 tomlkit-0.11.8 wcwidth-0.2.6 zipp-3.15.0\nWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n[notice] A new release of pip available: 22.3.1 -&gt; 23.1.2\n[notice] To update, run: pip install --upgrade pip\n$ git config user.email $CI_EMAIL &amp;&amp; git config user.name $CI_USERNAME\n$ git config http.sslVerify false\n$ git remote rm origin &amp;&amp; git remote add origin https://oauth2:$PROJECT_ACCESS_TOKEN@gitlab.example.com/dmitry.teslya/example-project.git\n$ git checkout -B \"$CI_COMMIT_REF_NAME\" \"$CI_COMMIT_SHA\"\nSwitched to and reset branch 'main'\n$ cz bump --yes\nbump(release): 0.0.1 \u2192 0.1.0\ntag to create: 0.1.0\nincrement detected: MINOR\n[main a068c06] bump(release): 0.0.1 \u2192 0.1.0\n 2 files changed, 12 insertions(+), 2 deletions(-)\n create mode 100644 CHANGELOG.md\nDone!\n$ git push --follow-tags origin $CI_COMMIT_BRANCH:$CI_COMMIT_BRANCH\nTo https://gitlab.example.com/dmitry.teslya/example-project.git\n   bf65ac3..a068c06  main -&gt; main\n * [new tag]         0.1.0 -&gt; 0.1.0\n$ cz version -p &gt; version\nUploading artifacts for successful job\nUploading artifacts...\nversion: found 1 matching files and directories    \nUploading artifacts as \"archive\" to coordinator... 201 Created  id=19340 responseStatus=201 Created token=64_DntRy\nCleaning up project directory and file based variables\nJob succeeded\n</code></pre>","tags":["git","versioning","semver"]},{"location":"blog/2023/05/18/automating-python-project-releases-with-commitizen/#conclusion","title":"Conclusion","text":"<p>We've taken a good look at conventional commits, semantic versioning, and the commitizen tool in this blog post, and I hope you've seen how they can really tidy things up in your coding projects.</p> <p>Suppose conventional commits are the house rules for your codebase, helping everyone play nice together and keeping things tidy and easy to understand. And semantic versioning, on the other hand, is like the milestones on your project roadmap. It helps everyone know what to expect with each new update, taking the guesswork out of the question. In that case, commitizen is a faithful robot helper, always ready to ensure your commit messages follow the house rules and help steer the project along those roadmap milestones.</p> <p>Embedding these into your workflow can make life easier for you and anyone else who might work on the project. It helps avoid confusion, prevents those \"what just happened\" moments when something changes, and it can save you a lot of headaches tracking down when a particular change was made.</p>","tags":["git","versioning","semver"]},{"location":"blog/2023/05/18/automating-python-project-releases-with-commitizen/#further-reading","title":"Further reading","text":"<ol> <li>GIT - Semantic versioning and conventional commits by Roman H\u00fcsler</li> <li>Continuous Integration with Gitlab by Marcos Schroh</li> <li>Automatic Software Version Bump Using GitLab CI/CD by Emir Husic</li> <li>Automatic Semantic Versioning in GitLab CI by Mi\u0142osz Sm\u00f3\u0142ka</li> </ol>","tags":["git","versioning","semver"]},{"location":"blog/2023/06/10/next-stop-golang/","title":"Next Stop Golang","text":"Cover photo by Thanos Pal on Unsplash <p>Since I embarked on the network automation journey, Python and Python-based utilities have always been the go-to tools for the job. I started, as maybe many of you, with Ansible. Then when dealing with its DSL grew more and more tiresome, I began writing my first Python code. And I was happy. I felt like I was learning something fundamental again, not just another niche technology that would never come in handy elsewhere. Although Python had some limitations in terms of portability and speed, it didn't bother me much.</p> <p>One day as I was commuting to the office, I tuned in to episode #617 of the PacketPushers Heavy Networking podcast. The episode was called Go Vs. Python For Network Engineers. The show's guest, Darren Parkinson, advocated that network engineers should at least try to learn Go alongside Python if not switching to Go completely. That got me curious, and later I read his blog post to understand his reasoning further. While the arguments in favor of switching to Go seemed valid, I recognized that I still had a lot to learn in Python. Therefore, switching to a new language would likely distract me from my current goals and hinder my progress. I think sticking with Python was a good decision at that moment because I've learned a lot about OOP, design patterns, organizing and shipping Python code, among other things, since then.</p> <p>But time passed, and my curiosity grew. I also dealt more and more with small Python CLI utilities that I wanted my teammates to use, but the portability was a real pain in the ass. It was ok to run some tools as containers in CI/CD pipelines, but doing that on hosts manually was just too much overhead. I revisited Darren's post and decided that the time had come.</p> <p>My first exercise was to rewrite a small CLI utility written in Python by my teammate in Go. The utility was pretty simple, somewhere around 200 lines of code. What it essentially did was querying YAML files. It took me maybe one day, and it was lots of fun. As a result, we got a binary without external dependencies, and it ran ~20x faster than the Python prototype. Although speed wasn't an issue in that scenario, it still ended up being a nice little perk.</p> <p>So, here are some features of Go that I had to wrap my head around while working on that small project.</p>","tags":["golang","learning","programming"]},{"location":"blog/2023/06/10/next-stop-golang/#formatting","title":"Formatting","text":"<p>The first thing I noticed was that when I added a package to the imports list and hit save, it instantly disappeared. The thing is, Go is even more strict than Python in terms of code formatting. If you have an unused import in your code, it won't compile. The same goes for the unused variables. The official Go extension for VS Code formats the code on save by default, and when it does, it removes the unused imports. It was annoying at first, but later I learned that I could start using external packages without importing them. Just hit save, and the formatter adds the necessary imports (1).</p> <ol> <li>At least the ones from the standard library.</li> </ol>","tags":["golang","learning","programming"]},{"location":"blog/2023/06/10/next-stop-golang/#managing-dependencies","title":"Managing dependencies","text":"<p>Managing external dependencies is a breeze with Go. You just declare your imports and run <code>go mod tidy</code>. That's it. No need for <code>requirements.txt</code> and <code>venv</code>, or external tools like Poetry.</p>","tags":["golang","learning","programming"]},{"location":"blog/2023/06/10/next-stop-golang/#naming-variables","title":"Naming variables","text":"<p>Go community promotes using short but descriptive variable names. If you need a multi-word name, use camelCase instead of snake_case. Names are case-sensitive, and the case of the first character has a special meaning. For example, if you need a function to be accessible outside of the package (to be exportable), its first character should be uppercase.</p>","tags":["golang","learning","programming"]},{"location":"blog/2023/06/10/next-stop-golang/#data-modeling","title":"Data modeling","text":"<p>In Python, I rely on Pydantic when dealing with external data sources and constructing my own data models. In Go, stucts in combination with struct tags cover my needs nicely.</p> <p>For example, this is how you can parse a YAML file in Go.</p> SourceOutput <pre><code>package main\nimport (\n\"fmt\"\n\"log\"\n\"gopkg.in/yaml.v3\"\n)\ntype Config struct {\nServer string `yaml:\"server\"`\nPort   int    `yaml:\"port\"`\n}\nvar data = `---\nserver: 10.0.0.1\nport: 443`\nfunc main() {\n// Create a Config struct to hold the parsed data\nvar config Config\n// Unmarshal the YAML data into the Config struct\nerr := yaml.Unmarshal([]byte(data), &amp;config)\nif err != nil {\nlog.Fatalf(\"Failed to parse YAML: %v\", err)\n}\n// Access the parsed data\nfmt.Println(\"Server:\", config.Server)\nfmt.Println(\"Port:\", config.Port)\n}\n</code></pre> <pre><code>Server: 10.0.0.1\nPort: 443\n</code></pre> <p>You can run it in the playground.</p>","tags":["golang","learning","programming"]},{"location":"blog/2023/06/10/next-stop-golang/#typing","title":"Typing","text":"<p>I'm used to type hints in Python. But because they're optional, I have to rely on external tools such as Mypy to ensure I'm doing it right. Go is a statically typed language. This means that everything must have a type. Having types makes your code safer and less error-prone while enabling your IDE to provide accurate code completion and suggestions.</p> <p>Of course, like everything in this life, static typing has its compromises. Imagine you need to write a function that checks if an item belongs to an array. </p> <p>Note</p> <p>Well, in Python you could just use the <code>in</code> operator and be done with it, but that's not the point of this example.</p> <p>You make a loop to iterate over an array and return <code>true</code> the moment a match is found. Sounds easy, but when everything must have a type, you end up writing a separate function for each type you might need (e.g., an array of ints, an array of strings, etc.). Doesn't look DRY, right? Fortunately, Golang now has generics that are designed to solve this.</p>","tags":["golang","learning","programming"]},{"location":"blog/2023/06/10/next-stop-golang/#asterisks-and-ampersands-aka-pointers","title":"Asterisks and ampersands (AKA pointers)","text":"<p>Although the Zen of Python states that explicit is better than implicit, a lot of things in Python are actually implicit. This is true for passing data. Python is a pass by reference language, while Go is pass by value. Let's take a look at the example below.</p> PythonGo (default behavior)Go (with pointers) <pre><code>a = [1,2,3]\nb = a\nb.append(4)\nprint(a)\n</code></pre> <p>Output:</p> <pre><code>[1, 2, 3, 4]\n</code></pre> <pre><code>package main\nimport \"fmt\"\nfunc main() {\na := []int{1, 2, 3}\nb := []int{}\nb = a\nb = append(b, 4)\nfmt.Println(a)\n}\n</code></pre> <p>Output:</p> <pre><code>[1 2 3]\n</code></pre> <p>Playground link</p> <pre><code>package main\nimport \"fmt\"\nfunc main() {\na := []int{1, 2, 3}\nb := &amp;a\n*b = append(*b, 4)\nfmt.Println(a)\n}\n</code></pre> <p>Output:</p> <pre><code>[1 2 3 4]\n</code></pre> <p>Playground link</p> <p>In Python, <code>b</code> is not a copy of <code>a</code>; it's a pointer to <code>a</code>. That's why when you modify <code>b</code>, you also change <code>a</code> because they're the same object. But that's not obvious when looking at the code. Go, on the other hand, is explicit. It allows you to make a more conscious decision about how to pass the data.</p> <p>I recommend this article for a more detailed explanation of this topic with some good usage examples.</p>","tags":["golang","learning","programming"]},{"location":"blog/2023/06/10/next-stop-golang/#error-handling","title":"Error handling","text":"<p>Error handling in Go differs from what you may be used to in Python. There are no <code>try/except</code> clauses. Instead, <code>error</code> is just another return value of a function. This enables handling errors just like any other return values.</p> <p>Below is an example of idiomatic error handling in Go.</p> <pre><code>package main\nimport \"fmt\"\nfunc Divide(a, b int) (int, error) {\nif b == 0 {\nreturn 0, fmt.Errorf(\"can't divide '%d' by zero\", a)\n}\nreturn a / b, nil\n}\nfunc main() {\nr, err := Divide(2, 0)\nif err != nil {\nfmt.Printf(\"Operation failed: %s\\n\", err)\nreturn\n}\nfmt.Printf(\"Result: %d\", r)\n}\n</code></pre> <p>Playground link</p> <p>Output:</p> <pre><code>Operation failed: can't divide '2' by zero\n</code></pre> <p>I came across a good article that covers this topic in detail.</p>","tags":["golang","learning","programming"]},{"location":"blog/2023/06/10/next-stop-golang/#toolbox","title":"Toolbox","text":"<p>Go comes with batteries included. You get a dependency manager, linter, formatter, and other tools, all within the <code>go</code> executable.</p> <p>As for release management, I use GoReleaser to push binaries to Gitlab.</p> <p>In addition, some of the tools I employ for Python projects, such as commitizen and pre-commit, are applicable to Go projects too.</p>","tags":["golang","learning","programming"]},{"location":"blog/2023/06/10/next-stop-golang/#things-i-didnt-touch-yet","title":"Things I didn't touch yet","text":"<p>Because of the simplicity of my first projects, I didn't have a chance to explore concurrency in Go, which is considered one of the main areas where Go truly shines. I'm quite sure I'll tackle it when I need to interact with many network devices simultaneously.</p>","tags":["golang","learning","programming"]},{"location":"blog/2023/06/10/next-stop-golang/#final-thoughts","title":"Final thoughts","text":"<p>I like Go. It's simple, opinionated, and fun. It has its drawbacks, of course, but at this point, I find it very applicable to the tasks at hand. It's a powerful tool for tackling network automation problems. I would even argue that it's a better choice as the first language for network engineers than Python because of its simplicity and focus on speed and portability.</p> <p>However, I am by no means discarding Python. In fact, I hope that my foray into Go will enhance my skills as a Python developer. I believe that by exploring a different language and its unique features, one can gain a fresh perspective and a deeper understanding of programming concepts.</p> <p>In the end, the choice of programming language ultimately depends on the specific needs and requirements of the project. While Go has become my preferred language for my current tasks, Python remains an indispensable part of my toolkit.</p>","tags":["golang","learning","programming"]},{"location":"blog/2023/06/10/next-stop-golang/#book-recommendations","title":"Book recommendations","text":"<ul> <li>Learning Go by Jon Bodner</li> <li>Go in Action by William Kennedy</li> <li>Network Automation with Go by Nicolas Leiva and Michael Kashin</li> </ul>","tags":["golang","learning","programming"]},{"location":"blog/2023/06/10/next-stop-golang/#references-and-further-reading","title":"References and further reading","text":"<ul> <li>When Should You Use Pointers in Golang by Pavle Djuric</li> <li>Python Lessons Learned From Go by Nathaniel Brown</li> <li>The Zen of Go by Dave Cheney</li> <li>The Go Programming Language presented by Rob Pike</li> <li>Go Styleguide by Arne Bahlo</li> <li>How To Golang by Anthony GG</li> <li>Effective Error Handling in Golang by Brandon Schurman</li> </ul>","tags":["golang","learning","programming"]},{"location":"blog/2023/11/16/my-introduction-to-openbsd/","title":"My Introduction to OpenBSD","text":"Cover photo by Stelio Puccinelli on Unsplash <p>In this post, I'd like to share why I consider OpenBSD a viable but often overlooked platform for building routers and firewalls. I tried to highlight the networking features of OpenBSD that in my opinion make this OS stand out.</p> <p>Please, treat this post more as a collection of my personal notes and findings. It doesn't claim to be objective and comprehensive.</p>","tags":["openbsd"]},{"location":"blog/2023/11/16/my-introduction-to-openbsd/#preface","title":"Preface","text":"<p>Recently I was looking for an open-source routing solution to build site-to-site VPN gateways and stateful firewalls. My considerations included ease of support and automation, feature richness, and low resource footprint. I dismissed such options as VyOS and pfSense quite early because I enjoy building things myself and prefer to have more control over the system. So I continued my search among Linux distributions. But as much as I love Linux, its \"batteries not included\" approach still seemed to require too much effort. I was looking for more balance between freedom of choice and the convenience of ready-made functionality. This made me look around for other open-source alternatives and eventually led to OpenBSD.</p>","tags":["openbsd"]},{"location":"blog/2023/11/16/my-introduction-to-openbsd/#first-impressions","title":"First impressions","text":"<p>The first thing I noticed when I started working with OpenBSD was the sense of a complete and well-designed system. All my humble networking needs were covered by the base system. That included BGP, OSPF, IPSec, and a packet filter. The daemons implementing the above protocols had very similar configuration syntax and philosophy which made me feel comfortable around the system quickly.</p> <p>My next discovery was that OpenBSD had everything to build a high-availability appliance out of the box. There is CARP which covers FHRP, pfsync to keep packet filter state tables synchronized across nodes, and even sasyncd to synchronize IPSec SAs (although I didn't try the latter).</p> <p>And since I've touched <code>CARP</code> and <code>pfsync</code> I can't help but mention the use of pseudo interfaces in OpenBSD. Many things in OpenBSD are done via interfaces. For instance, you don't need a daemon to export flow data. You just configure the pflow interface with <code>ifconfig</code> and that's it. Or if you need to access firewall logs, you just point <code>tcpdump</code> to a pflog interface. How cool is that?</p>","tags":["openbsd"]},{"location":"blog/2023/11/16/my-introduction-to-openbsd/#simplicity-and-coherence","title":"Simplicity and coherence","text":"<p>To me, <code>systemd</code> and <code>netplan</code> feel like overkill when it comes to managing network interfaces of a server, especially a router. OpenBSD keeps all network interface configs in separate /etc/hostname. files which contain parameters for <code>ifconfig</code>. And if you need to make sure that the config is always applied to the right interface you can use <code>/etc/hostname.&lt;lladr&gt;</code> to bind it to the link-layer address (e.g., <code>/etc/hostname.00:00:5e:00:53:af</code>). <p>Same with the service management. The most complex case of service management on a router that comes to my mind is running multiple instances of the same daemon in different VRFs (1). That can be easily achieved with the rcctl tool even for daemons not natively aware of rdomains by passing the <code>rtable</code> option. More on that later.</p> <ol> <li>From here on I will refer to VRFs as routing domains or rdomains as a more idiomatic OpenBSD term.</li> </ol> <p>I also like how OpenBSD network daemons follow the low coupling and high cohesion design principles. A good example of that would be the utilization of kernel features such as route labels and packet tags.</p> <p>I was puzzled at first about how to configure route redistribution between BGP and OSPF because I couldn't find the <code>redistribute bgp</code> command in the ospfd.conf man page. But soon I realized I could mark BGP routes with an arbitrary label in bgpd.conf and then match that label in <code>ospfd</code> config.</p>","tags":["openbsd"]},{"location":"blog/2023/11/16/my-introduction-to-openbsd/#packet-filter","title":"Packet filter","text":"<p>The big part of the OpenBSD networking stack is of course PF, or packet filter. I don't want to dive much into technical details here. There are plenty of articles on the Internet and even a book dedicated to PF.</p> <p>In terms of traffic filtering functionality, PF is on par with iptables. Although its syntax is very straightforward and human-friendly, it takes some time to wrap your head around its operation principles if you come from iptables or traditional firewalls. PF is the only firewall I know where the last matching rule determines the outcome. This forces you to start with broad common rules, such as <code>block all</code>, and then add more and more specific ones.</p> <p>As already mentioned OpenBSD features pfsync protocol. It enables you to build highly available firewall clusters, similar to those offered by big vendors.</p>","tags":["openbsd"]},{"location":"blog/2023/11/16/my-introduction-to-openbsd/#routing","title":"Routing","text":"<p>OpenBSD supports OSPF and BGP out of the box with OpenOSPFD and OpenBGPD respectively. FRRouting and BIRD can also be installed as external packages, but I yet haven't tried them.</p> <p>Both BGPD and OSPFD have accompanying CLI tools, namely bgpctl, and ospfctl, which allow you to extract operational data (i.e., show commands) and make runtime changes such as clearing neighbors.</p> <p>As I've mentioned before OpenBSD supports virtual routing with rtables and rdomains. Since you can assign multiple rtables only to the default rdomain both terms are often interchangeable. But they should not be confused. Separate rtables in the default rdomain can be used for policy routing. This is done by matching packets with <code>pf</code> and sending them to a specific rtable where route lookup should happen. Rdomains can be used to assign interfaces and are like VRFs. I recommend this article to learn more about this topic.</p>","tags":["openbsd"]},{"location":"blog/2023/11/16/my-introduction-to-openbsd/#ipsec","title":"IPSec","text":"<p>IPSec support is provided by iked for IKEv2 and isakmpd for IKEv1 protocols. Unfortunately, you can't run them both on the same machine, because they listen on the same UDP ports (500 and 4500). Perhaps this can be circumvented by running <code>iked</code> and <code>isakmpd</code> in different rdomains, but you'll still need two public IPs for that.</p> <p>Both <code>iked</code> and <code>isakmpd</code> need only one config file to describe both Phase 1 and Phase 2. Though I find it a bit confusing that while the <code>iked</code> config is called <code>/etc/iked.conf</code>, it's <code>/etc/ipsec.conf</code> for <code>isakmpd</code>.</p> <p>OpenBSD IPSec stack utilizes a special enc pseudo-interface. It allows you to apply <code>pf</code> rules to IPSec encapsulated traffic and monitor traffic going to or from an IPSec tunnel before encryption and after decryption with <code>tcpdump</code>. In my opinion, this contributes significantly to the process of troubleshooting.</p> <p>With the recent 7.4 release, OpenBSD got support for route-based IPSec which looks very promising, but I haven't had a chance to try it yet.</p>","tags":["openbsd"]},{"location":"blog/2023/11/16/my-introduction-to-openbsd/#monitoring","title":"Monitoring","text":"<p>I used Zabbix to monitor OpenBSD boxes by installing <code>zabbix-agent</code> from packages. There is an official OpenBSD template that can be used as a starting point.</p> <p>There is also <code>node_exporter</code> available in packages if you prefer Prometheus.</p>","tags":["openbsd"]},{"location":"blog/2023/11/16/my-introduction-to-openbsd/#automation","title":"Automation","text":"<p>OpenBSD is supported by all major configuration management systems, such as Puppet, Chef, Ansible, and Salt. Although the availability of ready-made modules is not as abundant as with various Linux distributions.</p> <p>In my case, I used Puppet to automate almost all aspects of system configuration. I relied on the <code>bsd</code> module to manage network interfaces and the <code>pf</code> module to manage PF rules. For daemons like BGPD, IKED, and OSPFD, I created my own modules.</p>","tags":["openbsd"]},{"location":"blog/2023/11/16/my-introduction-to-openbsd/#documentation","title":"Documentation","text":"<p>Compared to Linux, there are relatively few articles and blog posts about OpenBSD. This is expected given the comparatively small user base. However, it is compensated by the quality and completeness of the manual pages.</p>","tags":["openbsd"]},{"location":"blog/2023/11/16/my-introduction-to-openbsd/#performance","title":"Performance","text":"<p>Up to this point, it may seem like it's too good to be true. However, I found network performance considerably lower than that of Linux when I was testing IPSec.</p> <p>I was passing iperf traffic through two OpenBSD VMs running on the same KVM host. There was a GRE over IPSec tunnel between them with AES256 GCM encryption which is hardware accelerated on both OpenBSD and Linux. A separate KVM host connected via 1 Gbit/s network was running 2 VMs with iperf which generated traffic. This wasn't the best test topology since the physical gigabit connection between hosts created a bottleneck. But unfortunately, OpenBSD didn't even hit that bottleneck as you can see in the results below.</p> OpenBSDLinuxTopology <pre><code>$ iperf3 -B 172.16.2.11 -c 172.16.2.10\nConnecting to host 172.16.2.10, port 5201\n[  5] local 172.16.2.11 port 42727 connected to 172.16.2.10 port 5201\n[ ID] Interval           Transfer     Bitrate         Retr  Cwnd\n[  5]   0.00-1.00   sec  69.4 MBytes   582 Mbits/sec   35    189 KBytes\n[  5]   1.00-2.00   sec  67.5 MBytes   566 Mbits/sec   43    189 KBytes\n[  5]   2.00-3.00   sec  63.6 MBytes   533 Mbits/sec   48    178 KBytes\n[  5]   3.00-4.00   sec  63.0 MBytes   529 Mbits/sec   38    195 KBytes\n[  5]   4.00-5.00   sec  64.0 MBytes   536 Mbits/sec   17    245 KBytes\n[  5]   5.00-6.00   sec  64.3 MBytes   540 Mbits/sec   48    218 KBytes\n[  5]   6.00-7.00   sec  60.9 MBytes   511 Mbits/sec   32    253 KBytes\n[  5]   7.00-8.00   sec  61.7 MBytes   518 Mbits/sec   32    280 KBytes\n[  5]   8.00-9.00   sec  60.0 MBytes   503 Mbits/sec   48    218 KBytes\n[  5]   9.00-10.00  sec  61.1 MBytes   513 Mbits/sec   43    245 KBytes\n- - - - - - - - - - - - - - - - - - - - - - - - -\n[ ID] Interval           Transfer     Bitrate         Retr\n[  5]   0.00-10.00  sec   636 MBytes   533 Mbits/sec  384             sender\n[  5]   0.00-10.00  sec   634 MBytes   531 Mbits/sec                  receiver\n\niperf Done.\n</code></pre> <pre><code>$ iperf3 -B 172.16.2.11 -c 172.16.2.10\nConnecting to host 172.16.2.10, port 5201\n[  5] local 172.16.2.11 port 58431 connected to 172.16.2.10 port 5201\n[ ID] Interval           Transfer     Bitrate         Retr  Cwnd\n[  5]   0.00-1.00   sec   112 MBytes   937 Mbits/sec  107    346 KBytes\n[  5]   1.00-2.00   sec   110 MBytes   923 Mbits/sec    6    324 KBytes\n[  5]   2.00-3.00   sec   109 MBytes   912 Mbits/sec   12    233 KBytes\n[  5]   3.00-4.00   sec   109 MBytes   912 Mbits/sec    9    250 KBytes\n[  5]   4.00-5.00   sec   109 MBytes   912 Mbits/sec   36    376 KBytes\n[  5]   5.00-6.00   sec   109 MBytes   912 Mbits/sec    5    254 KBytes\n[  5]   6.00-7.00   sec   109 MBytes   912 Mbits/sec   25    282 KBytes\n[  5]   7.00-8.00   sec   109 MBytes   912 Mbits/sec   11    326 KBytes\n[  5]   8.00-9.00   sec   106 MBytes   892 Mbits/sec   13    292 KBytes\n[  5]   9.00-10.00  sec   108 MBytes   902 Mbits/sec    9    319 KBytes\n- - - - - - - - - - - - - - - - - - - - - - - - -\n[ ID] Interval           Transfer     Bitrate         Retr\n[  5]   0.00-10.00  sec  1.06 GBytes   913 Mbits/sec  233             sender\n[  5]   0.00-10.00  sec  1.06 GBytes   910 Mbits/sec                  receiver\n\niperf Done.\n</code></pre> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 KVM01                                      \u2502\n\u2502     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502     \u2502openbsd01   \u2502        \u2502openbsd02   \u2502   \u2502\n\u2502     \u2502            \u2502        \u2502            \u2502   \u2502\n\u2502     \u2502          vio1\u2500\u2500\u2500\u2500\u2500\u2500vio1          \u2502   \u2502\n\u2502     \u2502            \u2502        \u2502            \u2502   \u2502\n\u2502     \u2502            \u2502        \u2502            \u2502   \u2502\n\u2502     \u2514\u2500\u2500\u2500\u2500vio2\u2500\u2500\u2500\u2500\u2518        \u2514\u2500\u2500\u2500\u2500vio2\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502           \u2502                     \u2502          \u2502\n\u2502           \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500bridge\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518          \u2502\n\u2502                      \u2502                     \u2502\n\u2502                      \u2502                     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500eth0\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                       \u2502\n                  \u250c\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2510\n                  \u2502  switch  \u2502 1 Gbit/s\n                  \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518\n                       \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500eth0\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                      \u2502                     \u2502\n\u2502                      \u2502                     \u2502\n\u2502           \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500bridge\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510          \u2502\n\u2502           \u2502                     \u2502          \u2502\n\u2502     \u250c\u2500\u2500\u2500\u2500eth0\u2500\u2500\u2500\u2500\u2510        \u250c\u2500\u2500\u2500\u2500eth0\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502     \u2502            \u2502        \u2502            \u2502   \u2502\n\u2502     \u2502lo0:        \u2502        \u2502lo0:        \u2502   \u2502\n\u2502     \u2502172.16.2.11 \u2502        \u2502172.16.2.10 \u2502   \u2502\n\u2502     \u2502            \u2502        \u2502            \u2502   \u2502\n\u2502     \u2502iperf vm    \u2502        \u2502iperf vm    \u2502   \u2502\n\u2502     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502 KVM02                                      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>This was a quick test without any kernel tuning or anything, so maybe I've missed something. Such performance was sufficient for my use case though. However, for many, it may be a deal breaker.</p>","tags":["openbsd"]},{"location":"blog/2023/11/16/my-introduction-to-openbsd/#cloud-and-virtualization-support","title":"Cloud and virtualization support","text":"<p>I run my OpenBSD boxes on KVM hosts and utilize cloud-init for the initial provisioning. Cloud-init is not a part of the base system, but, fortunately, there are prebuilt OpenBSD images with cloud-init installed available for download.</p> <p>The only issue I still have with my setup is that I can't get QEMU guest agent to communicate with the virtualization host. Because of this VMs can't be gracefully shut down which can be quite inconvenient. There is a workaround for this for Proxmox setups, but I couldn't adapt it to pure KVM.</p> <p>Running OpenBSD on the public cloud might also present some challenges from what I've gathered. You will need to build your own images if you want to run OpenBSD on AWS, Azure, or GCP. However, you can find native OpenBSD support on some smaller hosting providers, such as Vultr and openbsd.amsterdam. The latter donates a small amount from each VM to the OpenBSD Foundation.</p>","tags":["openbsd"]},{"location":"blog/2023/11/16/my-introduction-to-openbsd/#conclusion","title":"Conclusion","text":"<p>I hope this post will encourage more network engineers familiar with Linux to try OpenBSD. I believe it's a very strong candidate for the role of a network gateway or a highly available firewall. It brings diversity to the Linux-dominated open-source landscape and gives a different perspective on how things can be done.</p>","tags":["openbsd"]},{"location":"blog/2023/11/16/my-introduction-to-openbsd/#resources","title":"Resources","text":"<ul> <li>Absolute OpenBSD, 2nd Edition by Michael W. Lucas</li> <li>The Book of PF, 3rd Edition by Peter N.M. Hansteen</li> <li>PF: Firewall Ruleset Optimization</li> <li>A collection of prebuilt BSD cloud images</li> <li>OpenBSD Handbook</li> <li>OpenBSD FAQ</li> <li>Highly Available WANs With OpenBSD by Marko Cupa\u0107</li> </ul>","tags":["openbsd"]},{"location":"blog/2020/08/11/august-2020-update/","title":"August 2020 Update","text":"<p>It's been a while since my last post and I want to shed some light on what I've been up to and what are my plans for the future of this site. A lot of things happened in 2019 and 2020 in my professional life and the two most important ones were changing job and becoming a CCIE R&amp;S this February (just before the lockdown). Both of these activities were the main reason why I've been silent here for so long (not to mention living through the lockdown with a toddler).</p>","tags":["blog"]},{"location":"blog/2020/08/11/august-2020-update/#blog-migration","title":"Blog migration","text":"<p>A few days ago I've come up with an idea of a new post and began to dust off my blog which was built with Jekyll and hosted on Github Pages. I had a really hard time updating the theme and all the dependencies and finally found out that GH Pages didn't support Jekyll 4.0 (yes, I know it can be done with Github Actions). That's when I decided to look for alternatives.</p>","tags":["blog"]},{"location":"blog/2020/08/11/august-2020-update/#choosing-static-site-generator","title":"Choosing static site generator","text":"<p>It was easy with a hosting solution as I've already wanted to try out Netlify and this was a perfect opportunity. Choosing the static site generator to replace Jekyll was not so straightforward. After some research, my two main options were Hugo and Gatsby. At first, I thought it would be reasonable to go with Gatsby because it's based on React which I use in my projects, but after some digging, I found it overly complex for my fairly unsophisticated needs. Hugo on the other side seemed really simple (single binary) and had a better (to my taste) theme gallery. So after hours of choosing the right theme and more hours of tweaking it I ended up with what you can see now. My theme of choice was Axiom and I really like how it renders code snippets. I hope now it's more clear and readable than before, although HydeJack theme I used with Jekyll was also great.</p>","tags":["blog"]},{"location":"blog/2020/08/11/august-2020-update/#problems","title":"Problems","text":"<p>The only unsolved problem here is Disqus comments. Because the URL path for posts has changed (https://dteslya.engineer/automation/post1 became https://dteslya.engineer/post1) I need to perform a thread migration which can be done with Disqus URL Mapper. Unfortunately, it doesn't work and now I'm waiting for the support team to help me. I suspect that it doesn't recognize <code>.engineer</code> as a valid TLD. I hope this will be resolved soon.</p> <p>\u26a1 UPDATE Disqus support turned out to be useless (they simply never responded), so I migrated my commenting system to Staticman. I spent a couple of days integrating it with my blog and importing existing comments from Disqus but it was totally worth it. Now all the comments are stored as <code>yaml</code> files in blog repo.</p> <p>I used these guides to complete my migration: Running Staticman on Hugo Blog With Nested Comments HUGO + STATICMAN: NESTED REPLIES AND E-MAIL NOTIFICATIONS</p> <p>The next step is to add Captcha and Email notifications to comments.</p>","tags":["blog"]},{"location":"blog/2020/08/11/august-2020-update/#plans","title":"Plans","text":"<p>My focus for the last half-year was learning Python by developing a web app for our team. Its main purpose is to take putty session logs from network devices as an input and produce structured reports in xlsx format. It's based heavily on Cisco Genie Parsers and uses Flask as a backend and React + Grommet on the front. Developing this app gave me a real boost in coding and I hope it will also give me new ideas for this blog. As for the near future I hope to produce a new post very soon. It's about using Cisco Support API which can be very handy if you run a Cisco shop. I also have some ideas on making a guide for network engineers who want to dive into automation and programming and don't know where to start.</p>","tags":["blog"]},{"location":"blog/2019/02/19/automate-windows-vm-creation-and-configuration-in-vsphere-using-packer-terraform-and-ansible-part-3-of-3/","title":"Automate Windows VM Creation and Configuration in vSphere Using Packer, Terraform and Ansible (Part 3 of 3)","text":"<p>This is the final entry in the series. In this post, I want to show how Ansible can be used to automate Windows VM provisioning. As always all the scripts and configurations are available at my GitHub repository.</p>","tags":["ansible","terraform","packer","vmware","windows"]},{"location":"blog/2019/02/19/automate-windows-vm-creation-and-configuration-in-vsphere-using-packer-terraform-and-ansible-part-3-of-3/#provisioning-with-ansible","title":"Provisioning with Ansible","text":"<p>Actually, Ansible was not my first choice when it came to VM provisioning. I've spent a lot of time with Chef at first because it was used in this repo which I took as a starting point. It almost worked for me but I've encountered a problem with a domain joining process. In order to join a domain the DNS server setting of the joining machine should be pointing to the domain controller. When the DNS server setting changed, the Chef client on that machine stopped resolving the Chef server and was unable to continue operation. Of course, I could fix it by adding necessary DNS entry on the server beforehand. Instead, I decided to try out Ansible which cannot run into such problems due to its agentless design.</p>","tags":["ansible","terraform","packer","vmware","windows"]},{"location":"blog/2019/02/19/automate-windows-vm-creation-and-configuration-in-vsphere-using-packer-terraform-and-ansible-part-3-of-3/#setting-up-ansible","title":"Setting up Ansible","text":"<ul> <li>Install Ansible following the official installation guide</li> <li>Install pywinrm library by issuing <code>pip install pywinrm</code>. Ansible uses this library to connect to Windows machines.</li> <li>Clone my Github repo and <code>cd</code> to <code>ansible</code></li> <li>Edit <code>inventory.yml</code> and <code>group_vars/all.yml</code> according to your environment</li> </ul> <p>I use Ansible Vault to store my credentials in <code>group_vars/all.yml</code> in encrypted form. To create your own encrypted passwords issue  <pre><code>ansible-vault encrypt_string &lt;string_to_encrypt&gt;\n</code></pre> command for each password you want to encrypt. It will ask you for the new vault password. Put that password in <code>.vault_pass</code> file in Ansible working directory.</p>","tags":["ansible","terraform","packer","vmware","windows"]},{"location":"blog/2019/02/19/automate-windows-vm-creation-and-configuration-in-vsphere-using-packer-terraform-and-ansible-part-3-of-3/#configuration-files","title":"Configuration files","text":"<p>Ansible directory structure:</p> <pre><code>.\n\u251c\u2500\u2500 group_vars\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 all.yml\n\u251c\u2500\u2500 roles\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 common\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 tasks\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u251c\u2500\u2500 enable_rdp.yml\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u2514\u2500\u2500 main.yml\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 fileserver\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 tasks\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u2514\u2500\u2500 main.yml\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 primary_domain_controller\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 tasks\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u2514\u2500\u2500 main.yml\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 replica_domain_controller\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 tasks\n\u2502\u00a0\u00a0         \u2514\u2500\u2500 main.yml\n\u251c\u2500\u2500 .vault_pass\n\u251c\u2500\u2500 ansible.cfg\n\u251c\u2500\u2500 inventory.yml\n\u2514\u2500\u2500 winlab.yml\n</code></pre>","tags":["ansible","terraform","packer","vmware","windows"]},{"location":"blog/2019/02/19/automate-windows-vm-creation-and-configuration-in-vsphere-using-packer-terraform-and-ansible-part-3-of-3/#executing-playbooks","title":"Executing playbooks","text":"<p>When you execute <code>ansible-playbook winlab.yml</code> Ansible reads <code>ansible.cfg</code> which points to inventory file and vault password file. </p> <p><pre><code>[defaults]\ninventory = inventory.yml\nvault_password_file = ./.vault_pass\n</code></pre> Then it starts to apply roles from <code>winlab.yml</code></p> <p><pre><code>---\n- hosts: primary_domain_controller\nroles:\n- primary_domain_controller\n- common\n- hosts: replica_domain_controller\nroles:\n- replica_domain_controller\n- common\n- hosts: fileserver\nroles:\n- fileserver\n- common\n</code></pre> to hosts in <code>inventory.yml</code>.</p> <pre><code>---\nprimary_domain_controller:\nhosts:\n10.5.202.4:\nreplica_domain_controller:\nhosts:\n10.5.202.5:\nfileserver:\nhosts:\n10.5.202.6:\n</code></pre> <p>Primary domain controller (PDC) is configured by <code>roles/primary_domain_controller/tasks/main.yml</code>.</p> <pre><code>---\n- name: install ad\nwin_domain:\ndns_domain_name: \"{{ domain }}\"\ndomain_netbios_name: \"{{ netbios_domain }}\"\nsafe_mode_password: \"{{ domain_safemode_password }}\"\nregister: ad\n- name: reboot server\nwin_reboot:\nmsg: \"Installing AD. Rebooting...\"\npre_reboot_delay: 15\nreboot_timeout: 600\npost_reboot_delay: 420\nwhen: ad.changed\n</code></pre> <p>The <code>install ad</code> task installs the AD DS role on the server, creates a new forest and promotes the server to a domain controller. The <code>reboot server</code> reboots the server only if the status of the previous task returned \"changed\".</p> <p><code>win_reboot</code> module doesn't have any reliable way to tell if the system is ready for management after the reboot. When Windows is rebooted after becoming a domain controller it takes a substantial amount of time to finish all the related tasks. To address this issue I specify the <code>post_reboot_delay</code> parameter. You may have to adjust it depending on your system's performance. Please refer to official module documentation for further details.</p> <p>RDP is enabled on PDC by <code>roles/common/tasks/main.yml</code> which calls <code>roles/common/tasks/enable_rdp.yml</code>.</p> <p>This task is applied to all machines, so it is omitted hereafter.</p> <pre><code>- name: Windows | Check for xRemoteDesktopAdmin Powershell module\nwin_psmodule:\nname: xRemoteDesktopAdmin\nstate: present\n- name: Windows | Enable Remote Desktop\nwin_dsc:\nresource_name: xRemoteDesktopAdmin\nEnsure: present\nUserAuthentication: Secure\n- name: Windows | Check for xNetworking Powershell module\nwin_psmodule:\nname: xNetworking\nstate: present\n- name: Firewall | Allow RDP through Firewall\nwin_dsc:\nresource_name: xFirewall\nName: \"Administrator access for RDP (TCP-In)\"\nEnsure: present\nEnabled: True\nProfile: \"Domain\"\nDirection: \"Inbound\"\nLocalport: \"3389\"\nProtocol: \"TCP\"\nDescription: \"Opens the listener port for RDP\"\n</code></pre> <p>This one installs <code>xRemoteDesktopAdmin</code> PowerShell module with <code>win_psmodule</code> and enables RDP using PowerShell Desired State Configuration. Then <code>xNetworking</code> module is installed to open RDP port on the Windows Firewall with <code>win_dsc</code> again.</p> <p>Replica domain controller (RDC) is configured by <code>roles/replica_domain_controller/tasks/main.yml</code>script.</p> <pre><code>---\n- name: change DNS server\nwhen: not ansible_windows_domain_member\nwin_dns_client:\nadapter_names: '*'\nipv4_addresses: \"{{ groups['primary_domain_controller'][0] }}\"\n- name: join domain\nwin_domain_membership:\ndns_domain_name: \"{{ domain }}\"\ndomain_admin_user: \"{{ domain_admin }}\"\ndomain_admin_password: \"{{ domain_admin_password }}\"\nstate: domain\nregister: domain_joined\n- name: reboot after domain join\nwin_reboot:\nwhen: domain_joined.reboot_required\n- name: Wait for system to become reachable over WinRM\nwait_for_connection:\ntimeout: 900\n- name: install ad\nwin_domain_controller:\ndns_domain_name: \"{{ domain }}\"\ndomain_admin_user: \"{{ domain_admin }}\"\ndomain_admin_password: \"{{ domain_admin_password }}\"\nsafe_mode_password: \"{{ domain_safemode_password }}\"\nstate: domain_controller\nregister: ad\n- name: reboot server\nwin_reboot:\nmsg: \"Installing AD. Rebooting...\"\npre_reboot_delay: 15\nwhen: ad.changed\n</code></pre> <p>First DNS server is changed to point to the PDC. Then the server joins the domain and reboots. After that AD role is installed and server reboots. </p> <p>The file server is configured by <code>roles/fileserver/tasks/main.yml</code>.</p> <pre><code>---\n- name: change DNS server\nwin_dns_client:\nadapter_names: '*'\nipv4_addresses: - \"{{ groups['primary_domain_controller'][0] }}\"\n- \"{{ groups['replica_domain_controller'][0] }}\"\n- name: join domain\nwin_domain_membership:\ndns_domain_name: \"{{ domain }}\"\ndomain_admin_user: \"{{ domain_admin }}\"\ndomain_admin_password: \"{{ domain_admin_password }}\"\nstate: domain\nregister: domain_joined\n- name: reboot after domain join\nwin_reboot:\nwhen: domain_joined.reboot_required\n</code></pre> <p>It repeats the steps taken with SDC except <code>install ad</code> task.</p> <p>Here is the sample output of <code>ansible-playbook winlab.yml</code>:</p> <p></p> <p>As you can see not everything went smooth at first. I guess there were some issues with Internet connectivity when Ansible tried to install <code>xRemoteDesktopAdmin</code> module. Fortunately, it succeeded on the second try. And here is what I like about Ansible: it didn't try to install AD during the second run, because it was already there. This idempotency feature is very handy because it allows you to run playbooks against the same hosts over and over again and not to worry about making any changes to already configured resources.</p>","tags":["ansible","terraform","packer","vmware","windows"]},{"location":"blog/2019/02/19/automate-windows-vm-creation-and-configuration-in-vsphere-using-packer-terraform-and-ansible-part-3-of-3/#conclusion","title":"Conclusion","text":"<p>Now you have a fully functional basic Windows domain setup which you can use to prepare for MCSA exams or to build custom PoC setups.</p>","tags":["ansible","terraform","packer","vmware","windows"]},{"location":"blog/2019/02/19/automate-windows-vm-creation-and-configuration-in-vsphere-using-packer-terraform-and-ansible-part-3-of-3/#references-and-further-reading","title":"References and further reading","text":"<ol> <li>Ansible Windows Guide</li> <li>Ansible &amp; DSC</li> <li>Manage Windows like Linux with Ansible</li> <li>Configure An Ansible Testing System On Windows (Part 2)</li> <li>Configure An Ansible Testing System On Windows (Part 3)</li> </ol>","tags":["ansible","terraform","packer","vmware","windows"]},{"location":"blog/2018/12/20/automate-windows-vm-creation-and-configuration-in-vsphere-using-packer-terraform-and-ansible-part-1-of-3/","title":"Automate Windows VM Creation and Configuration in vSphere Using Packer, Terraform and Ansible (Part 1 of 3)","text":"<p>In this series of posts I'd like to show how to automate the process of setting up virtual infrastructure consisting of several Windows Server 2016 machines. Most articles I've come across cover the use of cloud providers (e.g. AWS) as a virtualization platform, so I decided to make a write up about my experience with VMware vSphere.</p> <p>The whole process can be devided in three stages: 1. Prepare VM template 2. Deploy the desired number of VMs using template from the previous step 3. Configure those VMs with Ansible</p> <p>All the scripts and configurations I use in this series of articles are available at my GitHub repository.</p> <p>In this post I will cover the first stage, i.e. VM template creation.</p>","tags":["ansible","terraform","packer","vmware","windows"]},{"location":"blog/2018/12/20/automate-windows-vm-creation-and-configuration-in-vsphere-using-packer-terraform-and-ansible-part-1-of-3/#creating-vm-template-using-packer","title":"Creating VM template using Packer","text":"<p>As stated on the official Packer page</p> <p>Packer is an open source tool for creating identical machine images for multiple platforms from a single source configuration. </p>","tags":["ansible","terraform","packer","vmware","windows"]},{"location":"blog/2018/12/20/automate-windows-vm-creation-and-configuration-in-vsphere-using-packer-terraform-and-ansible-part-1-of-3/#choosing-the-right-builder","title":"Choosing the right builder","text":"<p>Packer uses builder plugins to actually build images. There are two builders for VMware available out of the box: <code>vmware-iso</code> and <code>vmware-vmx</code>. The latter uses existing VMs to create images, so it doesn't fit in my concept of building everything from scratch. <code>vmware-iso</code> however starts from ISO file and creates brand new VM. But to use <code>vmware-iso</code> builder remotely on VMware vSphere hypervisor you need to modify your ESXi host to allow SSH access, because <code>vmware-iso</code> uses SSH instead of API to talk to VMware hypervisor. Looks pretty much like a dirty hack to me, not to mention that I don't have enough privileges to make such modifications to ESXi hosts in my environment.</p> <p>Fortunately there is a third-party builder by JetBrains called <code>vsphere-iso</code> which does pretty much the same as <code>vmware-iso</code> but using vCenter API instead of SSH (they also have a <code>vsphere-clone</code> builder as a <code>vmware-vmx</code> alternative).</p>","tags":["ansible","terraform","packer","vmware","windows"]},{"location":"blog/2018/12/20/automate-windows-vm-creation-and-configuration-in-vsphere-using-packer-terraform-and-ansible-part-1-of-3/#setting-up-packer","title":"Setting up Packer","text":"<p>First you need to install Packer on your workstation. I use Ubuntu, but the installation process is fairly similar on all supported OSes. There are no packages of Packer for Ubuntu, but it can be installed as a precompiled binary very easily.</p> <p>Just download the appropriate package, unzip Packer binary and place it somewhere on your $PATH. I use <code>~/bin</code> for this purpose. You can read about other installation options on the official guide.</p> <p>To install <code>vpshere-iso</code> plugin download its binary from the releases page and put it in the same directory where you put <code>packer</code> binary. In my case it is <code>~/bin</code>.</p>","tags":["ansible","terraform","packer","vmware","windows"]},{"location":"blog/2018/12/20/automate-windows-vm-creation-and-configuration-in-vsphere-using-packer-terraform-and-ansible-part-1-of-3/#build-process-overview","title":"Build process overview","text":"<p>After you clone my Github repo and tweak the config files in accrordance with your environment all you need to do is run this command:</p> <pre><code>$ packer build -var-file=vars.json windows-server-2016.json\n</code></pre> <p>This tells <code>packer</code> to do the following: 1. Connect to vSphere and create virtual machine 2. Mount ISO images specified in json file 3. Create floppy disk and put files from <code>setup</code> dir on it 4. Mount floppy disk 5. Power on VM and wait for it to get an IP address     * When VM is powered on it boots from the first ISO which is Windows installation disk     * Windows setup reads <code>autounattend.xml</code> from floppy drive     * <code>autounattend.xml</code> runs <code>vmtools.cmd</code> batch script during the \"specialize\" pass     * <code>autounattend.xml</code> runs <code>setup.ps1</code> Powershell script after the first autologon     * <code>autounattend.xml</code> sets local administrator user and password which are later used by <code>packer</code> to connect to Windows via WinRM 6. Connect to Windows via WinRM 7. Run provisioning script (in my case it just lists files on C: drive) 8. Shut down VM and convert it to VM template</p> <p>Now lets take a look at each config file in more detail.</p>","tags":["ansible","terraform","packer","vmware","windows"]},{"location":"blog/2018/12/20/automate-windows-vm-creation-and-configuration-in-vsphere-using-packer-terraform-and-ansible-part-1-of-3/#preparing-necessary-files","title":"Preparing necessary files","text":"<p>I don't present complete file listings here assuming that you just clone my git repo and work with prepared files. You can do it by issuing this command:</p> <pre><code>$ git clone https://github.com/dteslya/win-iac-lab\n</code></pre> <p>This repo contains configs for Packer, Terraform and Ansible and since this article's focus is Packer let's take a look at <code>packer</code> directory structure.</p> <pre><code>.\n\u251c\u2500\u2500 setup\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 autounattend.xml\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 setup.ps1\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 vmtools.cmd\n\u251c\u2500\u2500 vars.json.example\n\u2514\u2500\u2500 windows-server-2016.json\n</code></pre> <p>Each file's description is listed below.</p>","tags":["ansible","terraform","packer","vmware","windows"]},{"location":"blog/2018/12/20/automate-windows-vm-creation-and-configuration-in-vsphere-using-packer-terraform-and-ansible-part-1-of-3/#varsjsonexample","title":"vars.json.example","text":"<p>I try to use variables for everything and put actual values in a separate file. This file is just an example and you should rename it to <code>vars.json</code> and change all the values according to your environment.</p>","tags":["ansible","terraform","packer","vmware","windows"]},{"location":"blog/2018/12/20/automate-windows-vm-creation-and-configuration-in-vsphere-using-packer-terraform-and-ansible-part-1-of-3/#windows-server-2016json","title":"windows-server-2016.json","text":"<p>This is the main configuration file for <code>packer</code>. The first section just declares all the variables and marks <code>vsphere_password</code> and <code>winadmin_password</code> as sensitive so that their values are not echoed during the build run. Next section called <code>builders</code> tells <code>vpshere-iso</code> how to connect to vSphere and where to put the VM template.</p> <pre><code>      \"communicator\": \"winrm\",\n\"winrm_username\": \"Administrator\",\n\"winrm_password\": \"{{user `winadmin_password`}}\",\n</code></pre> <p>This section is crucial as it tells packer how to connect to the guest OS. This username and password are set during the Windows setup (see autounattend.xml).</p> <pre><code>      \"iso_paths\": [\n\"{{user `os_iso_path`}}\",\n\"{{user `vmtools_iso_path`}}\"\n],\n</code></pre> <p>Here you point to Windows ISO file and VMware tools ISO which will be presented to guest OS as CDROM drives. Guest OS will mount this ISOs exactly in that order (Windows ISO as \"D:\", vmtools as \"E:\"). This is important because other scripts refer to particular Windows drive letters.</p> <pre><code>      \"floppy_files\": [\n\"setup/autounattend.xml\",\n\"setup/setup.ps1\",\n\"setup/vmtools.cmd\"\n]\n</code></pre> <p>This section tells <code>packer</code> to create a virtual floppy drive and put those files on it. More on that later.</p>","tags":["ansible","terraform","packer","vmware","windows"]},{"location":"blog/2018/12/20/automate-windows-vm-creation-and-configuration-in-vsphere-using-packer-terraform-and-ansible-part-1-of-3/#autounattendxml","title":"autounattend.xml","text":"<p>This is the second most important file called answer file which allows to fully automate Windows installation. Windows setup reads this file either from installation media (ISO) or floppy drive automatically. You can create this file by yourself or use one from my repository. If you choose to make your own answer file I recommend to read this article by Derek Seaman. Although it is focused on Windows Server 2012 it works for Windows 2016 too, except for this two details:</p> <ul> <li>Change image name to Windows Server 2016 SERVERSTANDARD</li> <li>Set first partition size to 500 (Default size with 2016)</li> </ul> <p>In any case let's take a look at the important sections of this file. First section of interest is \"specialize\" pass:</p> <pre><code>    &lt;settings pass=\"specialize\"&gt;\n...\n            &lt;RunSynchronous&gt;\n&lt;RunSynchronousCommand wcm:action=\"add\"&gt;\n&lt;Path&gt;a:\\vmtools.cmd&lt;/Path&gt;\n&lt;Order&gt;1&lt;/Order&gt;\n&lt;WillReboot&gt;Always&lt;/WillReboot&gt;\n&lt;/RunSynchronousCommand&gt;\n&lt;/RunSynchronous&gt;\n...\n    &lt;/settings&gt;\n</code></pre> <p>It tells Windows setup to run vmtools.cmd batch script from virtual floppy drive.</p> <p>Second section of interest is \"oobeSystem\" pass:</p> <pre><code>    &lt;settings pass=\"oobeSystem\"&gt;\n...\n            &lt;AutoLogon&gt;\n&lt;Password&gt;\n&lt;Value&gt;S3cret!&lt;/Value&gt;\n&lt;PlainText&gt;true&lt;/PlainText&gt;\n&lt;/Password&gt;\n&lt;LogonCount&gt;2&lt;/LogonCount&gt;\n&lt;Username&gt;Administrator&lt;/Username&gt;\n&lt;Enabled&gt;true&lt;/Enabled&gt;\n&lt;/AutoLogon&gt;\n&lt;FirstLogonCommands&gt;\n&lt;SynchronousCommand wcm:action=\"add\"&gt;\n&lt;Order&gt;1&lt;/Order&gt;\n&lt;!-- Enable WinRM service --&gt;\n&lt;CommandLine&gt;powershell -ExecutionPolicy Bypass -File a:\\setup.ps1&lt;/CommandLine&gt;\n&lt;RequiresUserInput&gt;true&lt;/RequiresUserInput&gt;\n&lt;/SynchronousCommand&gt;\n&lt;/FirstLogonCommands&gt;\n&lt;UserAccounts&gt;\n&lt;AdministratorPassword&gt;\n&lt;Value&gt;S3cret!&lt;/Value&gt;\n&lt;PlainText&gt;true&lt;/PlainText&gt;\n&lt;/AdministratorPassword&gt;\n&lt;/UserAccounts&gt;\n...\n    &lt;/settings&gt;\n</code></pre> <p>This section tells Windows setup to perform autologon using \"Administrator\" account which is also set in this section and run the setup.ps1 powershell script.</p>","tags":["ansible","terraform","packer","vmware","windows"]},{"location":"blog/2018/12/20/automate-windows-vm-creation-and-configuration-in-vsphere-using-packer-terraform-and-ansible-part-1-of-3/#setupps1","title":"setup.ps1","text":"<p>This script does three things. First, it changes Windows Firewall profile to private in order for Windows to accept incoming network connections.</p> <pre><code>$profile = Get-NetConnectionProfile\nSet-NetConnectionProfile -Name $profile.Name -NetworkCategory Private\n</code></pre> <p>Then it enables WinRM service for <code>packer</code> to be able to connect to Windows.</p> <pre><code>winrm quickconfig -quiet\nwinrm set winrm/config/service '@{AllowUnencrypted=\"true\"}'\nwinrm set winrm/config/service/auth '@{Basic=\"true\"}'\n</code></pre> <p>And finally it resets autologon count to zero for obvious security reasons.</p> <pre><code>Set-ItemProperty -Path 'HKLM:\\SOFTWARE\\Microsoft\\Windows NT\\CurrentVersion\\Winlogon' -Name AutoLogonCount -Value 0\n</code></pre>","tags":["ansible","terraform","packer","vmware","windows"]},{"location":"blog/2018/12/20/automate-windows-vm-creation-and-configuration-in-vsphere-using-packer-terraform-and-ansible-part-1-of-3/#vmtoolscmd","title":"vmtools.cmd","text":"<p>The sole perpose of this script is to install VMware tools. </p> <pre><code>e:\\setup64 /s /v \"/qb REBOOT=R\"\n</code></pre> <p></p> <p>Please note the drive letter. It is E: because VMware tools ISO is listed after Windows ISO (which is D:) in json file.</p>","tags":["ansible","terraform","packer","vmware","windows"]},{"location":"blog/2018/12/20/automate-windows-vm-creation-and-configuration-in-vsphere-using-packer-terraform-and-ansible-part-1-of-3/#build-process-example","title":"Build process example","text":"<p>Now when you've got all files prepared you can actually try and call <code>packer</code> to build a VM template for you.</p> <p>When you run <code>packer build -var-file=vars.json windows-server-2016.json</code> it will look something like this:</p> <p></p> <p>As you can see it takes about 20 minutes to finish Windows setup and installation in my case.</p>","tags":["ansible","terraform","packer","vmware","windows"]},{"location":"blog/2018/12/20/automate-windows-vm-creation-and-configuration-in-vsphere-using-packer-terraform-and-ansible-part-1-of-3/#conclusion","title":"Conclusion","text":"<p>Now you have very basic but working configuration that lets you fully automate Windows Server 2016 build. There are a lot of things you can add and improve here. To name a few, you can automate Windows updates installation, pre-install software using Chocolatey, enable remote desktop and so on. I provided a couple of resources below which can serve as a good source of inspiration.</p>","tags":["ansible","terraform","packer","vmware","windows"]},{"location":"blog/2018/12/20/automate-windows-vm-creation-and-configuration-in-vsphere-using-packer-terraform-and-ansible-part-1-of-3/#references-and-further-reading","title":"References and further reading","text":"<ol> <li>Official Packer documentation</li> <li>Packer Builder for VMware vSphere</li> <li>Using Packer to create Windows images by Jordan Borean</li> <li>Big collection of Windows templates by Stefan Scherer on Github</li> </ol>","tags":["ansible","terraform","packer","vmware","windows"]},{"location":"blog/2019/01/21/automate-windows-vm-creation-and-configuration-in-vsphere-using-packer-terraform-and-ansible-part-2-of-3/","title":"Automate Windows VM Creation and Configuration in vSphere Using Packer, Terraform and Ansible (Part 2 of 3)","text":"<p>In the first entry of this series I showed how to create VM templates using Packer. Now we can use those templates to spin up actual VMs with help of Terraform.</p> <p>All the scripts and configurations I use in this series of articles are available at my GitHub repository.</p>","tags":["ansible","terraform","packer","vmware","windows"]},{"location":"blog/2019/01/21/automate-windows-vm-creation-and-configuration-in-vsphere-using-packer-terraform-and-ansible-part-2-of-3/#creating-vms-with-terraform","title":"Creating VMs with Terraform","text":"<p>Terraform is a tool by Hashicorp which lets you turn your virtual infrastructure into code by writing declarative configuration files. It supports all the popular cloud infrastructure providers and most importantly VMware vSphere among others.</p>","tags":["ansible","terraform","packer","vmware","windows"]},{"location":"blog/2019/01/21/automate-windows-vm-creation-and-configuration-in-vsphere-using-packer-terraform-and-ansible-part-2-of-3/#setting-up-terraform","title":"Setting up Terraform","text":"<ul> <li>Install Terraform on your workstation by downloading the binary file. Put it somewhere on your $PATH. I use <code>~/bin</code> for this purpose.</li> <li>Clone my Github repo and <code>cd</code> to <code>terraform</code></li> <li>Run <code>terraform init</code>. It will download the VMware vSphere provider plugin. </li> </ul> <p>Now everything is ready to proceed with editing the configuration files and running Terraform.</p>","tags":["ansible","terraform","packer","vmware","windows"]},{"location":"blog/2019/01/21/automate-windows-vm-creation-and-configuration-in-vsphere-using-packer-terraform-and-ansible-part-2-of-3/#configuration-files","title":"Configuration files","text":"<p>When Terraform is run it reads all the <code>.tf</code> files in the working directory. This lets you group different logical parts of the configuration into separate files. In my example I have the following directory structure:</p> <pre><code>.\n\u251c\u2500\u2500 01-PDC.tf\n\u251c\u2500\u2500 02-ReplicaDC.tf\n\u251c\u2500\u2500 03-FileServer.tf\n\u251c\u2500\u2500 base.tf\n\u251c\u2500\u2500 terraform.tfvars.example\n\u2514\u2500\u2500 variables.tf\n</code></pre> <p>I start with the <code>base.tf</code> where I define connection to vCenter and basic parameters such as datacenter name, compute and storage clusters and most importantly template VM. Template VM is used to set target VMs parameters such as number of CPUs, RAM and disk size etc. Those parameters are set in separate configuration files for each VM (<code>01-PDC.tf</code>, <code>02-ReplicaDC.tf</code> and <code>03-FileServer.tf</code>). I also use <code>variables.tf</code> to define all the variables and <code>terraform.tfvars</code> to set the actual values.</p> <p>It is considered best practice to add <code>terraform.tfvars</code> to <code>.gitignore</code> file to avoid leaking of sensitive data to version control system.</p>","tags":["ansible","terraform","packer","vmware","windows"]},{"location":"blog/2019/01/21/automate-windows-vm-creation-and-configuration-in-vsphere-using-packer-terraform-and-ansible-part-2-of-3/#running-terraform","title":"Running Terraform","text":"<p>After you have modified configuration files according to your environment you can run <code>terraform plan</code>. This will give you the idea of what will happen when you run <code>terraform apply</code> so you can review your configuration and double check everything before actually making any changes to the infrastructure. This step is crucial in production environments, but in our case, you can skip it and run <code>terraform apply</code> straight away. It will still list all the actions to be performed and ask you for confirmation before making any changes to the infrastructure. \"terraform apply\" output</p> <pre><code>dteslya@ubuntu ~/a/terraform&gt; terraform apply\ndata.vsphere_datacenter.dc: Refreshing state...\ndata.vsphere_virtual_machine.Win2016GUI_template: Refreshing state...\ndata.vsphere_datastore_cluster.datastore_cluster: Refreshing state...\ndata.vsphere_network.network: Refreshing state...\ndata.vsphere_compute_cluster.cluster: Refreshing state...\n\nAn execution plan has been generated and is shown below.\nResource actions are indicated with the following symbols:\n  + create\n\nTerraform will perform the following actions:\n\n+ vsphere_virtual_machine.01-PDC\n      id:                                                            &lt;computed&gt;\n      boot_retry_delay:                                              \"10000\"\nchange_version:                                                &lt;computed&gt;\n      clone.#:                                                       \"1\"\nclone.0.customize.#:                                           \"1\"\nclone.0.customize.0.ipv4_gateway:                              \"10.5.202.1\"\nclone.0.customize.0.network_interface.#:                       \"1\"\nclone.0.customize.0.network_interface.0.dns_server_list.#:     \"1\"\nclone.0.customize.0.network_interface.0.dns_server_list.0:     \"10.5.202.3\"\nclone.0.customize.0.network_interface.0.ipv4_address:          \"10.5.202.4\"\nclone.0.customize.0.network_interface.0.ipv4_netmask:          \"24\"\nclone.0.customize.0.timeout:                                   \"10\"\nclone.0.customize.0.windows_options.#:                         \"1\"\nclone.0.customize.0.windows_options.0.admin_password:          &lt;sensitive&gt;\n      clone.0.customize.0.windows_options.0.auto_logon:              \"true\"\nclone.0.customize.0.windows_options.0.auto_logon_count:        \"1\"\nclone.0.customize.0.windows_options.0.computer_name:           \"01-pdc\"\nclone.0.customize.0.windows_options.0.full_name:               \"Administrator\"\nclone.0.customize.0.windows_options.0.organization_name:       \"Managed by Terraform\"\nclone.0.customize.0.windows_options.0.run_once_command_list.#: \"5\"\nclone.0.customize.0.windows_options.0.run_once_command_list.0: \"winrm quickconfig -force\"\nclone.0.customize.0.windows_options.0.run_once_command_list.1: \"winrm set winrm/config @{MaxEnvelopeSizekb=\\\"100000\\\"}\"\nclone.0.customize.0.windows_options.0.run_once_command_list.2: \"winrm set winrm/config/Service @{AllowUnencrypted=\\\"true\\\"}\"\nclone.0.customize.0.windows_options.0.run_once_command_list.3: \"winrm set winrm/config/Service/Auth @{Basic=\\\"true\\\"}\"\nclone.0.customize.0.windows_options.0.run_once_command_list.4: \"netsh advfirewall set allprofiles state off\"\nclone.0.customize.0.windows_options.0.time_zone:               \"85\"\nclone.0.template_uuid:                                         \"422e95b1-dfe9-25cd-b223-c87077093ae9\"\nclone.0.timeout:                                               \"30\"\ncpu_limit:                                                     \"-1\"\ncpu_share_count:                                               &lt;computed&gt;\n      cpu_share_level:                                               \"normal\"\ndatastore_cluster_id:                                          \"group-p289\"\ndatastore_id:                                                  &lt;computed&gt;\n      default_ip_address:                                            &lt;computed&gt;\n      disk.#:                                                        \"1\"\ndisk.0.attach:                                                 \"false\"\ndisk.0.datastore_id:                                           \"&lt;computed&gt;\"\ndisk.0.device_address:                                         &lt;computed&gt;\n      disk.0.disk_mode:                                              \"persistent\"\ndisk.0.disk_sharing:                                           \"sharingNone\"\ndisk.0.eagerly_scrub:                                          \"false\"\ndisk.0.io_limit:                                               \"-1\"\ndisk.0.io_reservation:                                         \"0\"\ndisk.0.io_share_count:                                         \"0\"\ndisk.0.io_share_level:                                         \"normal\"\ndisk.0.keep_on_remove:                                         \"false\"\ndisk.0.key:                                                    \"0\"\ndisk.0.label:                                                  \"disk0\"\ndisk.0.path:                                                   &lt;computed&gt;\n      disk.0.size:                                                   \"32\"\ndisk.0.thin_provisioned:                                       \"true\"\ndisk.0.unit_number:                                            \"0\"\ndisk.0.uuid:                                                   &lt;computed&gt;\n      disk.0.write_through:                                          \"false\"\nept_rvi_mode:                                                  \"automatic\"\nfirmware:                                                      \"bios\"\nfolder:                                                        \"Teslya/mcsa\"\nforce_power_off:                                               \"true\"\nguest_id:                                                      \"windows9Server64Guest\"\nguest_ip_addresses.#:                                          &lt;computed&gt;\n      host_system_id:                                                &lt;computed&gt;\n      hv_mode:                                                       \"hvAuto\"\nimported:                                                      &lt;computed&gt;\n      latency_sensitivity:                                           \"normal\"\nmemory:                                                        \"8192\"\nmemory_limit:                                                  \"-1\"\nmemory_share_count:                                            &lt;computed&gt;\n      memory_share_level:                                            \"normal\"\nmigrate_wait_timeout:                                          \"30\"\nmoid:                                                          &lt;computed&gt;\n      name:                                                          \"01-pdc\"\nnetwork_interface.#:                                           \"1\"\nnetwork_interface.0.adapter_type:                              \"vmxnet3\"\nnetwork_interface.0.bandwidth_limit:                           \"-1\"\nnetwork_interface.0.bandwidth_reservation:                     \"0\"\nnetwork_interface.0.bandwidth_share_count:                     &lt;computed&gt;\n      network_interface.0.bandwidth_share_level:                     \"normal\"\nnetwork_interface.0.device_address:                            &lt;computed&gt;\n      network_interface.0.key:                                       &lt;computed&gt;\n      network_interface.0.mac_address:                               &lt;computed&gt;\n      network_interface.0.network_id:                                \"dvportgroup-262\"\nnum_cores_per_socket:                                          \"1\"\nnum_cpus:                                                      \"4\"\nreboot_required:                                               &lt;computed&gt;\n      resource_pool_id:                                              \"resgroup-62\"\nrun_tools_scripts_after_power_on:                              \"true\"\nrun_tools_scripts_after_resume:                                \"true\"\nrun_tools_scripts_before_guest_shutdown:                       \"true\"\nrun_tools_scripts_before_guest_standby:                        \"true\"\nscsi_bus_sharing:                                              \"noSharing\"\nscsi_controller_count:                                         \"1\"\nscsi_type:                                                     \"lsilogic-sas\"\nshutdown_wait_timeout:                                         \"3\"\nswap_placement_policy:                                         \"inherit\"\nuuid:                                                          &lt;computed&gt;\n      vapp_transport.#:                                              &lt;computed&gt;\n      vmware_tools_status:                                           &lt;computed&gt;\n      vmx_path:                                                      &lt;computed&gt;\n      wait_for_guest_net_routable:                                   \"true\"\nwait_for_guest_net_timeout:                                    \"5\"\n+ vsphere_virtual_machine.02-ReplicaDC\n      id:                                                            &lt;computed&gt;\n      boot_retry_delay:                                              \"10000\"\nchange_version:                                                &lt;computed&gt;\n      clone.#:                                                       \"1\"\nclone.0.customize.#:                                           \"1\"\nclone.0.customize.0.ipv4_gateway:                              \"10.5.202.1\"\nclone.0.customize.0.network_interface.#:                       \"1\"\nclone.0.customize.0.network_interface.0.dns_server_list.#:     \"1\"\nclone.0.customize.0.network_interface.0.dns_server_list.0:     \"10.5.202.3\"\nclone.0.customize.0.network_interface.0.ipv4_address:          \"10.5.202.5\"\nclone.0.customize.0.network_interface.0.ipv4_netmask:          \"24\"\nclone.0.customize.0.timeout:                                   \"10\"\nclone.0.customize.0.windows_options.#:                         \"1\"\nclone.0.customize.0.windows_options.0.admin_password:          &lt;sensitive&gt;\n      clone.0.customize.0.windows_options.0.auto_logon:              \"true\"\nclone.0.customize.0.windows_options.0.auto_logon_count:        \"1\"\nclone.0.customize.0.windows_options.0.computer_name:           \"02-replicadc\"\nclone.0.customize.0.windows_options.0.full_name:               \"Administrator\"\nclone.0.customize.0.windows_options.0.organization_name:       \"Managed by Terraform\"\nclone.0.customize.0.windows_options.0.run_once_command_list.#: \"5\"\nclone.0.customize.0.windows_options.0.run_once_command_list.0: \"winrm quickconfig -force\"\nclone.0.customize.0.windows_options.0.run_once_command_list.1: \"winrm set winrm/config @{MaxEnvelopeSizekb=\\\"100000\\\"}\"\nclone.0.customize.0.windows_options.0.run_once_command_list.2: \"winrm set winrm/config/Service @{AllowUnencrypted=\\\"true\\\"}\"\nclone.0.customize.0.windows_options.0.run_once_command_list.3: \"winrm set winrm/config/Service/Auth @{Basic=\\\"true\\\"}\"\nclone.0.customize.0.windows_options.0.run_once_command_list.4: \"netsh advfirewall set allprofiles state off\"\nclone.0.customize.0.windows_options.0.time_zone:               \"85\"\nclone.0.template_uuid:                                         \"422e95b1-dfe9-25cd-b223-c87077093ae9\"\nclone.0.timeout:                                               \"30\"\ncpu_limit:                                                     \"-1\"\ncpu_share_count:                                               &lt;computed&gt;\n      cpu_share_level:                                               \"normal\"\ndatastore_cluster_id:                                          \"group-p289\"\ndatastore_id:                                                  &lt;computed&gt;\n      default_ip_address:                                            &lt;computed&gt;\n      disk.#:                                                        \"1\"\ndisk.0.attach:                                                 \"false\"\ndisk.0.datastore_id:                                           \"&lt;computed&gt;\"\ndisk.0.device_address:                                         &lt;computed&gt;\n      disk.0.disk_mode:                                              \"persistent\"\ndisk.0.disk_sharing:                                           \"sharingNone\"\ndisk.0.eagerly_scrub:                                          \"false\"\ndisk.0.io_limit:                                               \"-1\"\ndisk.0.io_reservation:                                         \"0\"\ndisk.0.io_share_count:                                         \"0\"\ndisk.0.io_share_level:                                         \"normal\"\ndisk.0.keep_on_remove:                                         \"false\"\ndisk.0.key:                                                    \"0\"\ndisk.0.label:                                                  \"disk0\"\ndisk.0.path:                                                   &lt;computed&gt;\n      disk.0.size:                                                   \"32\"\ndisk.0.thin_provisioned:                                       \"true\"\ndisk.0.unit_number:                                            \"0\"\ndisk.0.uuid:                                                   &lt;computed&gt;\n      disk.0.write_through:                                          \"false\"\nept_rvi_mode:                                                  \"automatic\"\nfirmware:                                                      \"bios\"\nfolder:                                                        \"Teslya/mcsa\"\nforce_power_off:                                               \"true\"\nguest_id:                                                      \"windows9Server64Guest\"\nguest_ip_addresses.#:                                          &lt;computed&gt;\n      host_system_id:                                                &lt;computed&gt;\n      hv_mode:                                                       \"hvAuto\"\nimported:                                                      &lt;computed&gt;\n      latency_sensitivity:                                           \"normal\"\nmemory:                                                        \"8192\"\nmemory_limit:                                                  \"-1\"\nmemory_share_count:                                            &lt;computed&gt;\n      memory_share_level:                                            \"normal\"\nmigrate_wait_timeout:                                          \"30\"\nmoid:                                                          &lt;computed&gt;\n      name:                                                          \"02-replicadc\"\nnetwork_interface.#:                                           \"1\"\nnetwork_interface.0.adapter_type:                              \"vmxnet3\"\nnetwork_interface.0.bandwidth_limit:                           \"-1\"\nnetwork_interface.0.bandwidth_reservation:                     \"0\"\nnetwork_interface.0.bandwidth_share_count:                     &lt;computed&gt;\n      network_interface.0.bandwidth_share_level:                     \"normal\"\nnetwork_interface.0.device_address:                            &lt;computed&gt;\n      network_interface.0.key:                                       &lt;computed&gt;\n      network_interface.0.mac_address:                               &lt;computed&gt;\n      network_interface.0.network_id:                                \"dvportgroup-262\"\nnum_cores_per_socket:                                          \"1\"\nnum_cpus:                                                      \"4\"\nreboot_required:                                               &lt;computed&gt;\n      resource_pool_id:                                              \"resgroup-62\"\nrun_tools_scripts_after_power_on:                              \"true\"\nrun_tools_scripts_after_resume:                                \"true\"\nrun_tools_scripts_before_guest_shutdown:                       \"true\"\nrun_tools_scripts_before_guest_standby:                        \"true\"\nscsi_bus_sharing:                                              \"noSharing\"\nscsi_controller_count:                                         \"1\"\nscsi_type:                                                     \"lsilogic-sas\"\nshutdown_wait_timeout:                                         \"3\"\nswap_placement_policy:                                         \"inherit\"\nuuid:                                                          &lt;computed&gt;\n      vapp_transport.#:                                              &lt;computed&gt;\n      vmware_tools_status:                                           &lt;computed&gt;\n      vmx_path:                                                      &lt;computed&gt;\n      wait_for_guest_net_routable:                                   \"true\"\nwait_for_guest_net_timeout:                                    \"5\"\n+ vsphere_virtual_machine.03-FileServer\n      id:                                                            &lt;computed&gt;\n      boot_retry_delay:                                              \"10000\"\nchange_version:                                                &lt;computed&gt;\n      clone.#:                                                       \"1\"\nclone.0.customize.#:                                           \"1\"\nclone.0.customize.0.ipv4_gateway:                              \"10.5.202.1\"\nclone.0.customize.0.network_interface.#:                       \"1\"\nclone.0.customize.0.network_interface.0.dns_server_list.#:     \"1\"\nclone.0.customize.0.network_interface.0.dns_server_list.0:     \"10.5.202.3\"\nclone.0.customize.0.network_interface.0.ipv4_address:          \"10.5.202.6\"\nclone.0.customize.0.network_interface.0.ipv4_netmask:          \"24\"\nclone.0.customize.0.timeout:                                   \"10\"\nclone.0.customize.0.windows_options.#:                         \"1\"\nclone.0.customize.0.windows_options.0.admin_password:          &lt;sensitive&gt;\n      clone.0.customize.0.windows_options.0.auto_logon:              \"true\"\nclone.0.customize.0.windows_options.0.auto_logon_count:        \"1\"\nclone.0.customize.0.windows_options.0.computer_name:           \"03-fileserver\"\nclone.0.customize.0.windows_options.0.full_name:               \"Administrator\"\nclone.0.customize.0.windows_options.0.organization_name:       \"Managed by Terraform\"\nclone.0.customize.0.windows_options.0.run_once_command_list.#: \"5\"\nclone.0.customize.0.windows_options.0.run_once_command_list.0: \"winrm quickconfig -force\"\nclone.0.customize.0.windows_options.0.run_once_command_list.1: \"winrm set winrm/config @{MaxEnvelopeSizekb=\\\"100000\\\"}\"\nclone.0.customize.0.windows_options.0.run_once_command_list.2: \"winrm set winrm/config/Service @{AllowUnencrypted=\\\"true\\\"}\"\nclone.0.customize.0.windows_options.0.run_once_command_list.3: \"winrm set winrm/config/Service/Auth @{Basic=\\\"true\\\"}\"\nclone.0.customize.0.windows_options.0.run_once_command_list.4: \"netsh advfirewall set allprofiles state off\"\nclone.0.customize.0.windows_options.0.time_zone:               \"85\"\nclone.0.template_uuid:                                         \"422e95b1-dfe9-25cd-b223-c87077093ae9\"\nclone.0.timeout:                                               \"30\"\ncpu_limit:                                                     \"-1\"\ncpu_share_count:                                               &lt;computed&gt;\n      cpu_share_level:                                               \"normal\"\ndatastore_cluster_id:                                          \"group-p289\"\ndatastore_id:                                                  &lt;computed&gt;\n      default_ip_address:                                            &lt;computed&gt;\n      disk.#:                                                        \"1\"\ndisk.0.attach:                                                 \"false\"\ndisk.0.datastore_id:                                           \"&lt;computed&gt;\"\ndisk.0.device_address:                                         &lt;computed&gt;\n      disk.0.disk_mode:                                              \"persistent\"\ndisk.0.disk_sharing:                                           \"sharingNone\"\ndisk.0.eagerly_scrub:                                          \"false\"\ndisk.0.io_limit:                                               \"-1\"\ndisk.0.io_reservation:                                         \"0\"\ndisk.0.io_share_count:                                         \"0\"\ndisk.0.io_share_level:                                         \"normal\"\ndisk.0.keep_on_remove:                                         \"false\"\ndisk.0.key:                                                    \"0\"\ndisk.0.label:                                                  \"disk0\"\ndisk.0.path:                                                   &lt;computed&gt;\n      disk.0.size:                                                   \"32\"\ndisk.0.thin_provisioned:                                       \"true\"\ndisk.0.unit_number:                                            \"0\"\ndisk.0.uuid:                                                   &lt;computed&gt;\n      disk.0.write_through:                                          \"false\"\nept_rvi_mode:                                                  \"automatic\"\nfirmware:                                                      \"bios\"\nfolder:                                                        \"Teslya/mcsa\"\nforce_power_off:                                               \"true\"\nguest_id:                                                      \"windows9Server64Guest\"\nguest_ip_addresses.#:                                          &lt;computed&gt;\n      host_system_id:                                                &lt;computed&gt;\n      hv_mode:                                                       \"hvAuto\"\nimported:                                                      &lt;computed&gt;\n      latency_sensitivity:                                           \"normal\"\nmemory:                                                        \"8192\"\nmemory_limit:                                                  \"-1\"\nmemory_share_count:                                            &lt;computed&gt;\n      memory_share_level:                                            \"normal\"\nmigrate_wait_timeout:                                          \"30\"\nmoid:                                                          &lt;computed&gt;\n      name:                                                          \"03-fileserver\"\nnetwork_interface.#:                                           \"1\"\nnetwork_interface.0.adapter_type:                              \"vmxnet3\"\nnetwork_interface.0.bandwidth_limit:                           \"-1\"\nnetwork_interface.0.bandwidth_reservation:                     \"0\"\nnetwork_interface.0.bandwidth_share_count:                     &lt;computed&gt;\n      network_interface.0.bandwidth_share_level:                     \"normal\"\nnetwork_interface.0.device_address:                            &lt;computed&gt;\n      network_interface.0.key:                                       &lt;computed&gt;\n      network_interface.0.mac_address:                               &lt;computed&gt;\n      network_interface.0.network_id:                                \"dvportgroup-262\"\nnum_cores_per_socket:                                          \"1\"\nnum_cpus:                                                      \"4\"\nreboot_required:                                               &lt;computed&gt;\n      resource_pool_id:                                              \"resgroup-62\"\nrun_tools_scripts_after_power_on:                              \"true\"\nrun_tools_scripts_after_resume:                                \"true\"\nrun_tools_scripts_before_guest_shutdown:                       \"true\"\nrun_tools_scripts_before_guest_standby:                        \"true\"\nscsi_bus_sharing:                                              \"noSharing\"\nscsi_controller_count:                                         \"1\"\nscsi_type:                                                     \"lsilogic-sas\"\nshutdown_wait_timeout:                                         \"3\"\nswap_placement_policy:                                         \"inherit\"\nuuid:                                                          &lt;computed&gt;\n      vapp_transport.#:                                              &lt;computed&gt;\n      vmware_tools_status:                                           &lt;computed&gt;\n      vmx_path:                                                      &lt;computed&gt;\n      wait_for_guest_net_routable:                                   \"true\"\nwait_for_guest_net_timeout:                                    \"5\"\nPlan: 3 to add, 0 to change, 0 to destroy.\n\nDo you want to perform these actions?\n  Terraform will perform the actions described above.\n  Only 'yes' will be accepted to approve.\n\nEnter a value: yes\n\nvsphere_virtual_machine.02-ReplicaDC: Creating...\n  boot_retry_delay:                                              \"\" =&gt; \"10000\"\nchange_version:                                                \"\" =&gt; \"&lt;computed&gt;\"\nclone.#:                                                       \"\" =&gt; \"1\"\nclone.0.customize.#:                                           \"\" =&gt; \"1\"\nclone.0.customize.0.ipv4_gateway:                              \"\" =&gt; \"10.5.202.1\"\nclone.0.customize.0.network_interface.#:                       \"\" =&gt; \"1\"\nclone.0.customize.0.network_interface.0.dns_server_list.#:     \"\" =&gt; \"1\"\nclone.0.customize.0.network_interface.0.dns_server_list.0:     \"\" =&gt; \"10.5.202.3\"\nclone.0.customize.0.network_interface.0.ipv4_address:          \"\" =&gt; \"10.5.202.5\"\nclone.0.customize.0.network_interface.0.ipv4_netmask:          \"\" =&gt; \"24\"\nclone.0.customize.0.timeout:                                   \"\" =&gt; \"10\"\nclone.0.customize.0.windows_options.#:                         \"\" =&gt; \"1\"\nclone.0.customize.0.windows_options.0.admin_password:          \"&lt;sensitive&gt;\" =&gt; \"&lt;sensitive&gt;\"\nclone.0.customize.0.windows_options.0.auto_logon:              \"\" =&gt; \"true\"\nclone.0.customize.0.windows_options.0.auto_logon_count:        \"\" =&gt; \"1\"\nclone.0.customize.0.windows_options.0.computer_name:           \"\" =&gt; \"02-replicadc\"\nclone.0.customize.0.windows_options.0.full_name:               \"\" =&gt; \"Administrator\"\nclone.0.customize.0.windows_options.0.organization_name:       \"\" =&gt; \"Managed by Terraform\"\nclone.0.customize.0.windows_options.0.run_once_command_list.#: \"\" =&gt; \"5\"\nclone.0.customize.0.windows_options.0.run_once_command_list.0: \"\" =&gt; \"winrm quickconfig -force\"\nclone.0.customize.0.windows_options.0.run_once_command_list.1: \"\" =&gt; \"winrm set winrm/config @{MaxEnvelopeSizekb=\\\"100000\\\"}\"\nclone.0.customize.0.windows_options.0.run_once_command_list.2: \"\" =&gt; \"winrm set winrm/config/Service @{AllowUnencrypted=\\\"true\\\"}\"\nclone.0.customize.0.windows_options.0.run_once_command_list.3: \"\" =&gt; \"winrm set winrm/config/Service/Auth @{Basic=\\\"true\\\"}\"\nclone.0.customize.0.windows_options.0.run_once_command_list.4: \"\" =&gt; \"netsh advfirewall set allprofiles state off\"\nclone.0.customize.0.windows_options.0.time_zone:               \"\" =&gt; \"85\"\nclone.0.template_uuid:                                         \"\" =&gt; \"422e95b1-dfe9-25cd-b223-c87077093ae9\"\nclone.0.timeout:                                               \"\" =&gt; \"30\"\ncpu_limit:                                                     \"\" =&gt; \"-1\"\ncpu_share_count:                                               \"\" =&gt; \"&lt;computed&gt;\"\ncpu_share_level:                                               \"\" =&gt; \"normal\"\ndatastore_cluster_id:                                          \"\" =&gt; \"group-p289\"\ndatastore_id:                                                  \"\" =&gt; \"&lt;computed&gt;\"\ndefault_ip_address:                                            \"\" =&gt; \"&lt;computed&gt;\"\ndisk.#:                                                        \"\" =&gt; \"1\"\ndisk.0.attach:                                                 \"\" =&gt; \"false\"\ndisk.0.datastore_id:                                           \"\" =&gt; \"&lt;computed&gt;\"\ndisk.0.device_address:                                         \"\" =&gt; \"&lt;computed&gt;\"\ndisk.0.disk_mode:                                              \"\" =&gt; \"persistent\"\ndisk.0.disk_sharing:                                           \"\" =&gt; \"sharingNone\"\ndisk.0.eagerly_scrub:                                          \"\" =&gt; \"false\"\ndisk.0.io_limit:                                               \"\" =&gt; \"-1\"\ndisk.0.io_reservation:                                         \"\" =&gt; \"0\"\ndisk.0.io_share_count:                                         \"\" =&gt; \"0\"\ndisk.0.io_share_level:                                         \"\" =&gt; \"normal\"\ndisk.0.keep_on_remove:                                         \"\" =&gt; \"false\"\ndisk.0.key:                                                    \"\" =&gt; \"0\"\ndisk.0.label:                                                  \"\" =&gt; \"disk0\"\ndisk.0.path:                                                   \"\" =&gt; \"&lt;computed&gt;\"\ndisk.0.size:                                                   \"\" =&gt; \"32\"\ndisk.0.thin_provisioned:                                       \"\" =&gt; \"true\"\ndisk.0.unit_number:                                            \"\" =&gt; \"0\"\ndisk.0.uuid:                                                   \"\" =&gt; \"&lt;computed&gt;\"\ndisk.0.write_through:                                          \"\" =&gt; \"false\"\nept_rvi_mode:                                                  \"\" =&gt; \"automatic\"\nfirmware:                                                      \"\" =&gt; \"bios\"\nfolder:                                                        \"\" =&gt; \"Teslya/mcsa\"\nforce_power_off:                                               \"\" =&gt; \"true\"\nguest_id:                                                      \"\" =&gt; \"windows9Server64Guest\"\nguest_ip_addresses.#:                                          \"\" =&gt; \"&lt;computed&gt;\"\nhost_system_id:                                                \"\" =&gt; \"&lt;computed&gt;\"\nhv_mode:                                                       \"\" =&gt; \"hvAuto\"\nimported:                                                      \"\" =&gt; \"&lt;computed&gt;\"\nlatency_sensitivity:                                           \"\" =&gt; \"normal\"\nmemory:                                                        \"\" =&gt; \"8192\"\nmemory_limit:                                                  \"\" =&gt; \"-1\"\nmemory_share_count:                                            \"\" =&gt; \"&lt;computed&gt;\"\nmemory_share_level:                                            \"\" =&gt; \"normal\"\nmigrate_wait_timeout:                                          \"\" =&gt; \"30\"\nmoid:                                                          \"\" =&gt; \"&lt;computed&gt;\"\nname:                                                          \"\" =&gt; \"02-replicadc\"\nnetwork_interface.#:                                           \"\" =&gt; \"1\"\nnetwork_interface.0.adapter_type:                              \"\" =&gt; \"vmxnet3\"\nnetwork_interface.0.bandwidth_limit:                           \"\" =&gt; \"-1\"\nnetwork_interface.0.bandwidth_reservation:                     \"\" =&gt; \"0\"\nnetwork_interface.0.bandwidth_share_count:                     \"\" =&gt; \"&lt;computed&gt;\"\nnetwork_interface.0.bandwidth_share_level:                     \"\" =&gt; \"normal\"\nnetwork_interface.0.device_address:                            \"\" =&gt; \"&lt;computed&gt;\"\nnetwork_interface.0.key:                                       \"\" =&gt; \"&lt;computed&gt;\"\nnetwork_interface.0.mac_address:                               \"\" =&gt; \"&lt;computed&gt;\"\nnetwork_interface.0.network_id:                                \"\" =&gt; \"dvportgroup-262\"\nnum_cores_per_socket:                                          \"\" =&gt; \"1\"\nnum_cpus:                                                      \"\" =&gt; \"4\"\nreboot_required:                                               \"\" =&gt; \"&lt;computed&gt;\"\nresource_pool_id:                                              \"\" =&gt; \"resgroup-62\"\nrun_tools_scripts_after_power_on:                              \"\" =&gt; \"true\"\nrun_tools_scripts_after_resume:                                \"\" =&gt; \"true\"\nrun_tools_scripts_before_guest_shutdown:                       \"\" =&gt; \"true\"\nrun_tools_scripts_before_guest_standby:                        \"\" =&gt; \"true\"\nscsi_bus_sharing:                                              \"\" =&gt; \"noSharing\"\nscsi_controller_count:                                         \"\" =&gt; \"1\"\nscsi_type:                                                     \"\" =&gt; \"lsilogic-sas\"\nshutdown_wait_timeout:                                         \"\" =&gt; \"3\"\nswap_placement_policy:                                         \"\" =&gt; \"inherit\"\nuuid:                                                          \"\" =&gt; \"&lt;computed&gt;\"\nvapp_transport.#:                                              \"\" =&gt; \"&lt;computed&gt;\"\nvmware_tools_status:                                           \"\" =&gt; \"&lt;computed&gt;\"\nvmx_path:                                                      \"\" =&gt; \"&lt;computed&gt;\"\nwait_for_guest_net_routable:                                   \"\" =&gt; \"true\"\nwait_for_guest_net_timeout:                                    \"\" =&gt; \"5\"\nvsphere_virtual_machine.01-PDC: Creating...\n  boot_retry_delay:                                              \"\" =&gt; \"10000\"\nchange_version:                                                \"\" =&gt; \"&lt;computed&gt;\"\nclone.#:                                                       \"\" =&gt; \"1\"\nclone.0.customize.#:                                           \"\" =&gt; \"1\"\nclone.0.customize.0.ipv4_gateway:                              \"\" =&gt; \"10.5.202.1\"\nclone.0.customize.0.network_interface.#:                       \"\" =&gt; \"1\"\nclone.0.customize.0.network_interface.0.dns_server_list.#:     \"\" =&gt; \"1\"\nclone.0.customize.0.network_interface.0.dns_server_list.0:     \"\" =&gt; \"10.5.202.3\"\nclone.0.customize.0.network_interface.0.ipv4_address:          \"\" =&gt; \"10.5.202.4\"\nclone.0.customize.0.network_interface.0.ipv4_netmask:          \"\" =&gt; \"24\"\nclone.0.customize.0.timeout:                                   \"\" =&gt; \"10\"\nclone.0.customize.0.windows_options.#:                         \"\" =&gt; \"1\"\nclone.0.customize.0.windows_options.0.admin_password:          \"&lt;sensitive&gt;\" =&gt; \"&lt;sensitive&gt;\"\nclone.0.customize.0.windows_options.0.auto_logon:              \"\" =&gt; \"true\"\nclone.0.customize.0.windows_options.0.auto_logon_count:        \"\" =&gt; \"1\"\nclone.0.customize.0.windows_options.0.computer_name:           \"\" =&gt; \"01-pdc\"\nclone.0.customize.0.windows_options.0.full_name:               \"\" =&gt; \"Administrator\"\nclone.0.customize.0.windows_options.0.organization_name:       \"\" =&gt; \"Managed by Terraform\"\nclone.0.customize.0.windows_options.0.run_once_command_list.#: \"\" =&gt; \"5\"\nclone.0.customize.0.windows_options.0.run_once_command_list.0: \"\" =&gt; \"winrm quickconfig -force\"\nclone.0.customize.0.windows_options.0.run_once_command_list.1: \"\" =&gt; \"winrm set winrm/config @{MaxEnvelopeSizekb=\\\"100000\\\"}\"\nclone.0.customize.0.windows_options.0.run_once_command_list.2: \"\" =&gt; \"winrm set winrm/config/Service @{AllowUnencrypted=\\\"true\\\"}\"\nclone.0.customize.0.windows_options.0.run_once_command_list.3: \"\" =&gt; \"winrm set winrm/config/Service/Auth @{Basic=\\\"true\\\"}\"\nclone.0.customize.0.windows_options.0.run_once_command_list.4: \"\" =&gt; \"netsh advfirewall set allprofiles state off\"\nclone.0.customize.0.windows_options.0.time_zone:               \"\" =&gt; \"85\"\nclone.0.template_uuid:                                         \"\" =&gt; \"422e95b1-dfe9-25cd-b223-c87077093ae9\"\nclone.0.timeout:                                               \"\" =&gt; \"30\"\ncpu_limit:                                                     \"\" =&gt; \"-1\"\ncpu_share_count:                                               \"\" =&gt; \"&lt;computed&gt;\"\ncpu_share_level:                                               \"\" =&gt; \"normal\"\ndatastore_cluster_id:                                          \"\" =&gt; \"group-p289\"\ndatastore_id:                                                  \"\" =&gt; \"&lt;computed&gt;\"\ndefault_ip_address:                                            \"\" =&gt; \"&lt;computed&gt;\"\ndisk.#:                                                        \"\" =&gt; \"1\"\ndisk.0.attach:                                                 \"\" =&gt; \"false\"\ndisk.0.datastore_id:                                           \"\" =&gt; \"&lt;computed&gt;\"\ndisk.0.device_address:                                         \"\" =&gt; \"&lt;computed&gt;\"\ndisk.0.disk_mode:                                              \"\" =&gt; \"persistent\"\ndisk.0.disk_sharing:                                           \"\" =&gt; \"sharingNone\"\ndisk.0.eagerly_scrub:                                          \"\" =&gt; \"false\"\ndisk.0.io_limit:                                               \"\" =&gt; \"-1\"\ndisk.0.io_reservation:                                         \"\" =&gt; \"0\"\ndisk.0.io_share_count:                                         \"\" =&gt; \"0\"\ndisk.0.io_share_level:                                         \"\" =&gt; \"normal\"\ndisk.0.keep_on_remove:                                         \"\" =&gt; \"false\"\ndisk.0.key:                                                    \"\" =&gt; \"0\"\ndisk.0.label:                                                  \"\" =&gt; \"disk0\"\ndisk.0.path:                                                   \"\" =&gt; \"&lt;computed&gt;\"\ndisk.0.size:                                                   \"\" =&gt; \"32\"\ndisk.0.thin_provisioned:                                       \"\" =&gt; \"true\"\ndisk.0.unit_number:                                            \"\" =&gt; \"0\"\ndisk.0.uuid:                                                   \"\" =&gt; \"&lt;computed&gt;\"\ndisk.0.write_through:                                          \"\" =&gt; \"false\"\nept_rvi_mode:                                                  \"\" =&gt; \"automatic\"\nfirmware:                                                      \"\" =&gt; \"bios\"\nfolder:                                                        \"\" =&gt; \"Teslya/mcsa\"\nforce_power_off:                                               \"\" =&gt; \"true\"\nguest_id:                                                      \"\" =&gt; \"windows9Server64Guest\"\nguest_ip_addresses.#:                                          \"\" =&gt; \"&lt;computed&gt;\"\nhost_system_id:                                                \"\" =&gt; \"&lt;computed&gt;\"\nhv_mode:                                                       \"\" =&gt; \"hvAuto\"\nimported:                                                      \"\" =&gt; \"&lt;computed&gt;\"\nlatency_sensitivity:                                           \"\" =&gt; \"normal\"\nmemory:                                                        \"\" =&gt; \"8192\"\nmemory_limit:                                                  \"\" =&gt; \"-1\"\nmemory_share_count:                                            \"\" =&gt; \"&lt;computed&gt;\"\nmemory_share_level:                                            \"\" =&gt; \"normal\"\nmigrate_wait_timeout:                                          \"\" =&gt; \"30\"\nmoid:                                                          \"\" =&gt; \"&lt;computed&gt;\"\nname:                                                          \"\" =&gt; \"01-pdc\"\nnetwork_interface.#:                                           \"\" =&gt; \"1\"\nnetwork_interface.0.adapter_type:                              \"\" =&gt; \"vmxnet3\"\nnetwork_interface.0.bandwidth_limit:                           \"\" =&gt; \"-1\"\nnetwork_interface.0.bandwidth_reservation:                     \"\" =&gt; \"0\"\nnetwork_interface.0.bandwidth_share_count:                     \"\" =&gt; \"&lt;computed&gt;\"\nnetwork_interface.0.bandwidth_share_level:                     \"\" =&gt; \"normal\"\nnetwork_interface.0.device_address:                            \"\" =&gt; \"&lt;computed&gt;\"\nnetwork_interface.0.key:                                       \"\" =&gt; \"&lt;computed&gt;\"\nnetwork_interface.0.mac_address:                               \"\" =&gt; \"&lt;computed&gt;\"\nnetwork_interface.0.network_id:                                \"\" =&gt; \"dvportgroup-262\"\nnum_cores_per_socket:                                          \"\" =&gt; \"1\"\nnum_cpus:                                                      \"\" =&gt; \"4\"\nreboot_required:                                               \"\" =&gt; \"&lt;computed&gt;\"\nresource_pool_id:                                              \"\" =&gt; \"resgroup-62\"\nrun_tools_scripts_after_power_on:                              \"\" =&gt; \"true\"\nrun_tools_scripts_after_resume:                                \"\" =&gt; \"true\"\nrun_tools_scripts_before_guest_shutdown:                       \"\" =&gt; \"true\"\nrun_tools_scripts_before_guest_standby:                        \"\" =&gt; \"true\"\nscsi_bus_sharing:                                              \"\" =&gt; \"noSharing\"\nscsi_controller_count:                                         \"\" =&gt; \"1\"\nscsi_type:                                                     \"\" =&gt; \"lsilogic-sas\"\nshutdown_wait_timeout:                                         \"\" =&gt; \"3\"\nswap_placement_policy:                                         \"\" =&gt; \"inherit\"\nuuid:                                                          \"\" =&gt; \"&lt;computed&gt;\"\nvapp_transport.#:                                              \"\" =&gt; \"&lt;computed&gt;\"\nvmware_tools_status:                                           \"\" =&gt; \"&lt;computed&gt;\"\nvmx_path:                                                      \"\" =&gt; \"&lt;computed&gt;\"\nwait_for_guest_net_routable:                                   \"\" =&gt; \"true\"\nwait_for_guest_net_timeout:                                    \"\" =&gt; \"5\"\nvsphere_virtual_machine.03-FileServer: Creating...\n  boot_retry_delay:                                              \"\" =&gt; \"10000\"\nchange_version:                                                \"\" =&gt; \"&lt;computed&gt;\"\nclone.#:                                                       \"\" =&gt; \"1\"\nclone.0.customize.#:                                           \"\" =&gt; \"1\"\nclone.0.customize.0.ipv4_gateway:                              \"\" =&gt; \"10.5.202.1\"\nclone.0.customize.0.network_interface.#:                       \"\" =&gt; \"1\"\nclone.0.customize.0.network_interface.0.dns_server_list.#:     \"\" =&gt; \"1\"\nclone.0.customize.0.network_interface.0.dns_server_list.0:     \"\" =&gt; \"10.5.202.3\"\nclone.0.customize.0.network_interface.0.ipv4_address:          \"\" =&gt; \"10.5.202.6\"\nclone.0.customize.0.network_interface.0.ipv4_netmask:          \"\" =&gt; \"24\"\nclone.0.customize.0.timeout:                                   \"\" =&gt; \"10\"\nclone.0.customize.0.windows_options.#:                         \"\" =&gt; \"1\"\nclone.0.customize.0.windows_options.0.admin_password:          \"&lt;sensitive&gt;\" =&gt; \"&lt;sensitive&gt;\"\nclone.0.customize.0.windows_options.0.auto_logon:              \"\" =&gt; \"true\"\nclone.0.customize.0.windows_options.0.auto_logon_count:        \"\" =&gt; \"1\"\nclone.0.customize.0.windows_options.0.computer_name:           \"\" =&gt; \"03-fileserver\"\nclone.0.customize.0.windows_options.0.full_name:               \"\" =&gt; \"Administrator\"\nclone.0.customize.0.windows_options.0.organization_name:       \"\" =&gt; \"Managed by Terraform\"\nclone.0.customize.0.windows_options.0.run_once_command_list.#: \"\" =&gt; \"5\"\nclone.0.customize.0.windows_options.0.run_once_command_list.0: \"\" =&gt; \"winrm quickconfig -force\"\nclone.0.customize.0.windows_options.0.run_once_command_list.1: \"\" =&gt; \"winrm set winrm/config @{MaxEnvelopeSizekb=\\\"100000\\\"}\"\nclone.0.customize.0.windows_options.0.run_once_command_list.2: \"\" =&gt; \"winrm set winrm/config/Service @{AllowUnencrypted=\\\"true\\\"}\"\nclone.0.customize.0.windows_options.0.run_once_command_list.3: \"\" =&gt; \"winrm set winrm/config/Service/Auth @{Basic=\\\"true\\\"}\"\nclone.0.customize.0.windows_options.0.run_once_command_list.4: \"\" =&gt; \"netsh advfirewall set allprofiles state off\"\nclone.0.customize.0.windows_options.0.time_zone:               \"\" =&gt; \"85\"\nclone.0.template_uuid:                                         \"\" =&gt; \"422e95b1-dfe9-25cd-b223-c87077093ae9\"\nclone.0.timeout:                                               \"\" =&gt; \"30\"\ncpu_limit:                                                     \"\" =&gt; \"-1\"\ncpu_share_count:                                               \"\" =&gt; \"&lt;computed&gt;\"\ncpu_share_level:                                               \"\" =&gt; \"normal\"\ndatastore_cluster_id:                                          \"\" =&gt; \"group-p289\"\ndatastore_id:                                                  \"\" =&gt; \"&lt;computed&gt;\"\ndefault_ip_address:                                            \"\" =&gt; \"&lt;computed&gt;\"\ndisk.#:                                                        \"\" =&gt; \"1\"\ndisk.0.attach:                                                 \"\" =&gt; \"false\"\ndisk.0.datastore_id:                                           \"\" =&gt; \"&lt;computed&gt;\"\ndisk.0.device_address:                                         \"\" =&gt; \"&lt;computed&gt;\"\ndisk.0.disk_mode:                                              \"\" =&gt; \"persistent\"\ndisk.0.disk_sharing:                                           \"\" =&gt; \"sharingNone\"\ndisk.0.eagerly_scrub:                                          \"\" =&gt; \"false\"\ndisk.0.io_limit:                                               \"\" =&gt; \"-1\"\ndisk.0.io_reservation:                                         \"\" =&gt; \"0\"\ndisk.0.io_share_count:                                         \"\" =&gt; \"0\"\ndisk.0.io_share_level:                                         \"\" =&gt; \"normal\"\ndisk.0.keep_on_remove:                                         \"\" =&gt; \"false\"\ndisk.0.key:                                                    \"\" =&gt; \"0\"\ndisk.0.label:                                                  \"\" =&gt; \"disk0\"\ndisk.0.path:                                                   \"\" =&gt; \"&lt;computed&gt;\"\ndisk.0.size:                                                   \"\" =&gt; \"32\"\ndisk.0.thin_provisioned:                                       \"\" =&gt; \"true\"\ndisk.0.unit_number:                                            \"\" =&gt; \"0\"\ndisk.0.uuid:                                                   \"\" =&gt; \"&lt;computed&gt;\"\ndisk.0.write_through:                                          \"\" =&gt; \"false\"\nept_rvi_mode:                                                  \"\" =&gt; \"automatic\"\nfirmware:                                                      \"\" =&gt; \"bios\"\nfolder:                                                        \"\" =&gt; \"Teslya/mcsa\"\nforce_power_off:                                               \"\" =&gt; \"true\"\nguest_id:                                                      \"\" =&gt; \"windows9Server64Guest\"\nguest_ip_addresses.#:                                          \"\" =&gt; \"&lt;computed&gt;\"\nhost_system_id:                                                \"\" =&gt; \"&lt;computed&gt;\"\nhv_mode:                                                       \"\" =&gt; \"hvAuto\"\nimported:                                                      \"\" =&gt; \"&lt;computed&gt;\"\nlatency_sensitivity:                                           \"\" =&gt; \"normal\"\nmemory:                                                        \"\" =&gt; \"8192\"\nmemory_limit:                                                  \"\" =&gt; \"-1\"\nmemory_share_count:                                            \"\" =&gt; \"&lt;computed&gt;\"\nmemory_share_level:                                            \"\" =&gt; \"normal\"\nmigrate_wait_timeout:                                          \"\" =&gt; \"30\"\nmoid:                                                          \"\" =&gt; \"&lt;computed&gt;\"\nname:                                                          \"\" =&gt; \"03-fileserver\"\nnetwork_interface.#:                                           \"\" =&gt; \"1\"\nnetwork_interface.0.adapter_type:                              \"\" =&gt; \"vmxnet3\"\nnetwork_interface.0.bandwidth_limit:                           \"\" =&gt; \"-1\"\nnetwork_interface.0.bandwidth_reservation:                     \"\" =&gt; \"0\"\nnetwork_interface.0.bandwidth_share_count:                     \"\" =&gt; \"&lt;computed&gt;\"\nnetwork_interface.0.bandwidth_share_level:                     \"\" =&gt; \"normal\"\nnetwork_interface.0.device_address:                            \"\" =&gt; \"&lt;computed&gt;\"\nnetwork_interface.0.key:                                       \"\" =&gt; \"&lt;computed&gt;\"\nnetwork_interface.0.mac_address:                               \"\" =&gt; \"&lt;computed&gt;\"\nnetwork_interface.0.network_id:                                \"\" =&gt; \"dvportgroup-262\"\nnum_cores_per_socket:                                          \"\" =&gt; \"1\"\nnum_cpus:                                                      \"\" =&gt; \"4\"\nreboot_required:                                               \"\" =&gt; \"&lt;computed&gt;\"\nresource_pool_id:                                              \"\" =&gt; \"resgroup-62\"\nrun_tools_scripts_after_power_on:                              \"\" =&gt; \"true\"\nrun_tools_scripts_after_resume:                                \"\" =&gt; \"true\"\nrun_tools_scripts_before_guest_shutdown:                       \"\" =&gt; \"true\"\nrun_tools_scripts_before_guest_standby:                        \"\" =&gt; \"true\"\nscsi_bus_sharing:                                              \"\" =&gt; \"noSharing\"\nscsi_controller_count:                                         \"\" =&gt; \"1\"\nscsi_type:                                                     \"\" =&gt; \"lsilogic-sas\"\nshutdown_wait_timeout:                                         \"\" =&gt; \"3\"\nswap_placement_policy:                                         \"\" =&gt; \"inherit\"\nuuid:                                                          \"\" =&gt; \"&lt;computed&gt;\"\nvapp_transport.#:                                              \"\" =&gt; \"&lt;computed&gt;\"\nvmware_tools_status:                                           \"\" =&gt; \"&lt;computed&gt;\"\nvmx_path:                                                      \"\" =&gt; \"&lt;computed&gt;\"\nwait_for_guest_net_routable:                                   \"\" =&gt; \"true\"\nwait_for_guest_net_timeout:                                    \"\" =&gt; \"5\"\nvsphere_virtual_machine.02-ReplicaDC: Still creating... (10s elapsed)\nvsphere_virtual_machine.01-PDC: Still creating... (10s elapsed)\nvsphere_virtual_machine.03-FileServer: Still creating... (10s elapsed)\n...\nvsphere_virtual_machine.02-ReplicaDC: Still creating... (7m50s elapsed)\nvsphere_virtual_machine.01-PDC: Still creating... (7m50s elapsed)\nvsphere_virtual_machine.03-FileServer: Still creating... (7m50s elapsed)\nvsphere_virtual_machine.01-PDC: Creation complete after 7m51s (ID: 422e621f-dcb4-d8c6-f5d1-865d1b06521a)\nvsphere_virtual_machine.02-ReplicaDC: Still creating... (8m0s elapsed)\nvsphere_virtual_machine.03-FileServer: Still creating... (8m0s elapsed)\nvsphere_virtual_machine.02-ReplicaDC: Still creating... (8m10s elapsed)\nvsphere_virtual_machine.03-FileServer: Still creating... (8m10s elapsed)\nvsphere_virtual_machine.02-ReplicaDC: Still creating... (8m20s elapsed)\nvsphere_virtual_machine.03-FileServer: Still creating... (8m20s elapsed)\nvsphere_virtual_machine.02-ReplicaDC: Creation complete after 8m23s (ID: 422e7b9f-34fd-f513-4bce-df84a85c812a)\nvsphere_virtual_machine.03-FileServer: Still creating... (8m30s elapsed)\nvsphere_virtual_machine.03-FileServer: Creation complete after 8m32s (ID: 422e8ef8-63c1-6c91-8df7-877c6a1f91c6)\nApply complete! Resources: 3 added, 0 changed, 0 destroyed.\n</code></pre> <p>As you can see 3 VMs were successfully created during the <code>terraform apply</code> run. If you need to change something in the VMs configuration, for example add some RAM or CPU, you can run <code>terraform apply</code> once again. If you're done with your lab and want to delete the VMs, you can run <code>terraform destroy</code>.</p> <p>One important note here. As you may have noticed there is a <code>customize</code> section in VMs configurations. This is actually guest customization which can be done manually in vSphere when deploying a new VM from a template. During this process Windows is sysprepped and that is why I have to set an administrator password and configure WinRM the second time (first time it was done during the template creation).</p>","tags":["ansible","terraform","packer","vmware","windows"]},{"location":"blog/2019/01/21/automate-windows-vm-creation-and-configuration-in-vsphere-using-packer-terraform-and-ansible-part-2-of-3/#conclusion","title":"Conclusion","text":"<p>Now you can create and destroy VMs with one command which is very handy when you need to setup an ad-hoc lab. In the next post I will cover how to configure Windows with Ansible and perform such tasks as installing roles and services and creating and joining a domain.</p>","tags":["ansible","terraform","packer","vmware","windows"]},{"location":"blog/2019/01/21/automate-windows-vm-creation-and-configuration-in-vsphere-using-packer-terraform-and-ansible-part-2-of-3/#references-and-further-reading","title":"References and further reading","text":"<ol> <li>Running Terraform in Automation</li> <li>An Introduction to Terraform</li> <li>Datanauts 137: Automating Infrastructure As Code With Terraform</li> <li>Sysprep and VMware Guest Customization with Terraform</li> </ol>","tags":["ansible","terraform","packer","vmware","windows"]},{"location":"blog/2022/07/14/how-to-run-a-python-cli-tool-inside-a-docker-container/","title":"How to Run a Python CLI Tool Inside a Docker Container","text":"Cover photo by Diomari Madulara <p>Have you ever faced a problem sharing your python scripts with the rest of your team? You need to ensure a lot of things for your script to run on a recipient's machine. This often involves ensuring that the Python interpreter's correct version and all the dependencies are installed among other things. To put it mildly, portability is not Python's strong suit. That's where Docker can come in handy.</p> <p>There are a lot of articles on how to run Flask or FastAPI apps in Docker. But I had a hard time finding tutorials about running CLI utilities in a container in an ad-hoc fashion with the ability to pass arguments.</p> <p>I relied heavily on these articles while making this tutorial:</p> <ul> <li>Python CLI Utilities with Poetry and Typer by John Walk</li> <li>Python and Poetry on Docker by Baptiste Maingret</li> <li>Hypermodern Python by Claudio Jolowicz</li> </ul> <p>This tutorial comes with an accompanying GitHub repository.</p>","tags":["python","docker","poetry","typer"]},{"location":"blog/2022/07/14/how-to-run-a-python-cli-tool-inside-a-docker-container/#building-the-python-app","title":"Building the Python App","text":"<p>For this tutorial, I will use a simple command-line application that utilizes the Nornir framework to render device configurations from a Jinja2 template. It relies on the Typer library to create a command-line interface.</p> <p>I use Pyenv and Poetry to manage the local dev environment. Setting up and using those tools is out of the scope of this tutorial. Please, refer to the Hypermodern Python series of articles for more info.</p> <p>You can clone the accompanying Git repo so it will be easier to follow this tutorial.</p> <pre><code>git clone https://github.com/dteslya/blog-dockerize-python-cli-tool\n</code></pre> <p>Let's take a look at the project structure.</p> <pre><code>\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 configs\n\u251c\u2500\u2500 docker\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 Dockerfile\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 docker-entrypoint.sh\n\u251c\u2500\u2500 inventory\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 hosts.yml\n\u251c\u2500\u2500 nornir_config.yml\n\u251c\u2500\u2500 poetry.lock\n\u251c\u2500\u2500 pyproject.toml\n\u251c\u2500\u2500 run-in-docker.sh\n\u251c\u2500\u2500 src\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 nornir_example\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 __init__.py\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 cli.py\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 functions.py\n\u2514\u2500\u2500 templates\n    \u2514\u2500\u2500 config.j2\n</code></pre> <p>Let's begin with the <code>src/nornir_example</code> directory where the Python app resides. The <code>cli.py</code> is the main script we invoke in order to use the app. It takes two arguments as commands:</p> <ul> <li><code>init</code> which simply creates a local directory to put rendered configs to</li> <li><code>create-configs</code> which renders the configurations and puts them in the local dir</li> </ul> <p>Let's take a closer look at the <code>create-configs</code> command. Below is the source code of the function which is called by this command:</p> <pre><code>@app.command()\ndef create_configs(\ntemplate_dir: Optional[str] = typer.Option(\nTEMPLATE_DIR, help=\"Directory to look for configuration templates\"\n),\noutput_dir: Optional[str] = typer.Option(\nOUTPUT_DIR, help=\"Directory to put resulting configs\"\n),\n):\n\"\"\"\n    Generate device configurations and put them to local directory.\n    \"\"\"\nnr = InitNornir(config_file=\"nornir_config.yml\")\nprint_result(nr.run(task=render_config, template_dir=template_dir))\nprint_result(nr.run(task=write_config, output_dir=output_dir))\n</code></pre> <p>It can take two options from the user:</p> <ul> <li><code>--template-dir</code> - where to look for the Jinja2 template files</li> <li><code>--output-dir</code> - where to put the resulting configs</li> </ul> <p>If those options are not passed by the user the default values take place.</p> <p>So what happens here.</p> <p>First, a <code>Nornir</code> object is initialized with the <code>nornir_config.yml</code> configuration file. In this simple example, the sole purpose of this config is to tell Nornir where to look for the inventory. I use only the <code>host_file</code> here which is <code>inventory/hosts.yml</code>.</p> <pre><code>swtich01:\ndata:\ninterfaces:\n- name: Vlan10\ndescription: Management\nip: 10.0.10.1\nmask: 255.255.255.0\nswtich02:\ndata:\ninterfaces:\n- name: Vlan10\ndescription: Management\nip: 10.0.10.2\nmask: 255.255.255.0\nswtich03:\ndata:\ninterfaces:\n- name: Vlan10\ndescription: Management\nip: 10.0.10.3\nmask: 255.255.255.0\n</code></pre> <p>As you can see it's quite simple and describes 3 devices and their interface data.</p> <p>Second, the <code>render_config</code> task creates a device configuration by populating the Jinja2 template with the device data. It then puts the resulting config in the dedicated host variable <code>task.host['config']</code>.</p> <p>The Jinja2 template is also very simple.</p> <pre><code>hostname {{ host }}\n!\n{% for interface in host.interfaces %}\ninterface {{ interface.name }}\ndescription {{ interface.description }}\nip address {{ interface.ip }} {{ interface.mask }}\n!\n{% endfor %}\n</code></pre> <p>And finally, the <code>write_config</code> task takes the config saved in the <code>task.host[\"config\"]</code> variable and writes it to a file in a local directory for each host in the inventory.</p>","tags":["python","docker","poetry","typer"]},{"location":"blog/2022/07/14/how-to-run-a-python-cli-tool-inside-a-docker-container/#running-the-app-in-the-local-environment","title":"Running the App in the Local Environment","text":"<p>Now that we figured out how our app works let's try to run it locally. First, we need to initialize a virtual environment and install dependencies.</p> <pre><code>$ poetry install\nInstalling dependencies from lock file\n\nPackage operations: 28 installs, 0 updates, 0 removals\n\n\u2022 Installing ruamel.yaml.clib (0.2.6)\n\u2022 Installing markupsafe (2.1.1)\n\u2022 Installing mypy-extensions (0.4.3)\n\u2022 Installing pyparsing (3.0.9)\n\u2022 Installing ruamel.yaml (0.17.21)\n\u2022 Installing typing-extensions (4.3.0)\n\u2022 Installing attrs (21.4.0)\n\u2022 Installing click (8.1.3)\n\u2022 Installing colorama (0.4.5)\n\u2022 Installing jinja2 (3.1.2)\n\u2022 Installing mccabe (0.6.1)\n\u2022 Installing more-itertools (8.13.0)\n\u2022 Installing nornir (3.3.0)\n\u2022 Installing packaging (21.3)\n\u2022 Installing pathspec (0.9.0)\n\u2022 Installing platformdirs (2.5.2)\n\u2022 Installing pluggy (0.13.1)\n\u2022 Installing py (1.11.0)\n\u2022 Installing pycodestyle (2.8.0)\n\u2022 Installing pyflakes (2.4.0)\n\u2022 Installing wcwidth (0.2.5)\n\u2022 Installing tomli (2.0.1)\n\u2022 Installing black (22.6.0)\n\u2022 Installing flake8 (4.0.1)\n\u2022 Installing nornir-jinja2 (0.2.0)\n\u2022 Installing nornir-utils (0.2.0)\n\u2022 Installing pytest (5.4.3)\n\u2022 Installing typer (0.4.2)\nInstalling the current project: nornir-example (0.1.0)\n</code></pre> <p>Then we can run the app by issuing the <code>poetry run cli</code> command.</p> <pre><code>$ poetry run cli\nUsage: cli [OPTIONS] COMMAND [ARGS]...\nTry 'cli --help' for help.\n\nError: Missing command.\n</code></pre> <p>As you can see it gives an error because we didn't supply any arguments.</p> <p>With the <code>--help</code> argument we can see the help message automatically generated by <code>Typer</code>.</p> <pre><code>$ poetry run cli --help\nUsage: cli [OPTIONS] COMMAND [ARGS]...\n\nSimple Nornir Example\n\nOptions:\n  --install-completion [bash|zsh|fish|powershell|pwsh]\nInstall completion for the specified shell.\n  --show-completion [bash|zsh|fish|powershell|pwsh]\nShow completion for the specified shell, to\n                                  copy it or customize the installation.\n  --help                          Show this message and exit.\n\nCommands:\n  create-configs  Generate device configurations and put them to local...\n  init            Initialize working directory\n</code></pre> <p>Let's create config files.</p> <p>First, we need to create a directory where configs will be written.</p> <pre><code>$ poetry run cli init\nCreating directories...\nDirectory 'configs' created\nInit complete\n</code></pre> <p>Now we can run the <code>create-configs</code> command.</p> <pre><code>$ poetry run cli create-configs\nrender_config*******************************************************************\n* switch01 ** changed : False **************************************************\nvvvv render_config ** changed : False vvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvv INFO\n---- Render config ** changed : False ------------------------------------------ INFO\nhostname switch01\n!\ninterface Vlan10\n description Management\n ip address 10.0.10.1 255.255.255.0\n!\n\n^^^^ END render_config ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n* switch02 ** changed : False **************************************************\nvvvv render_config ** changed : False vvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvv INFO\n---- Render config ** changed : False ------------------------------------------ INFO\nhostname switch02\n!\ninterface Vlan10\n description Management\n ip address 10.0.10.2 255.255.255.0\n!\n\n^^^^ END render_config ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n* switch03 ** changed : False **************************************************\nvvvv render_config ** changed : False vvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvv INFO\n---- Render config ** changed : False ------------------------------------------ INFO\nhostname switch03\n!\ninterface Vlan10\n description Management\n ip address 10.0.10.3 255.255.255.0\n!\n\n^^^^ END render_config ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nwrite_config********************************************************************\n* switch01 ** changed : True ***************************************************\nvvvv write_config ** changed : False vvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvv INFO\n---- Save configs ** changed : True -------------------------------------------- INFO\n--- configs/switch01-config.txt\n\n+++ new\n\n@@ -0,0 +1,6 @@\n\n+hostname switch01\n+!\n+interface Vlan10\n+ description Management\n+ ip address 10.0.10.1 255.255.255.0\n+!\n^^^^ END write_config ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n* switch02 ** changed : True ***************************************************\nvvvv write_config ** changed : False vvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvv INFO\n---- Save configs ** changed : True -------------------------------------------- INFO\n--- configs/switch02-config.txt\n\n+++ new\n\n@@ -0,0 +1,6 @@\n\n+hostname switch02\n+!\n+interface Vlan10\n+ description Management\n+ ip address 10.0.10.2 255.255.255.0\n+!\n^^^^ END write_config ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n* switch03 ** changed : True ***************************************************\nvvvv write_config ** changed : False vvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvv INFO\n---- Save configs ** changed : True -------------------------------------------- INFO\n--- configs/switch03-config.txt\n\n+++ new\n\n@@ -0,0 +1,6 @@\n\n+hostname switch03\n+!\n+interface Vlan10\n+ description Management\n+ ip address 10.0.10.3 255.255.255.0\n+!\n^^^^ END write_config ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n</code></pre> <p>Now, if we look at the <code>configs</code> directory, we'll find three files there.</p> <pre><code>$ ls -l configs\ntotal 12\n-rw-rw-r-- 1 dmitry.teslya dmitry.teslya 99 Jul 12 12:36 switch01-config.txt\n-rw-rw-r-- 1 dmitry.teslya dmitry.teslya 99 Jul 12 12:36 switch02-config.txt\n-rw-rw-r-- 1 dmitry.teslya dmitry.teslya 99 Jul 12 12:36 switch03-config.txt\n</code></pre> <p>Here is the first device config, for example.</p> <pre><code>$ cat configs/switch01-config.txt\nhostname switch01\n!\ninterface Vlan10\n description Management\n ip address 10.0.10.1 255.255.255.0\n!\n</code></pre> <p>So at this point, our example app runs in the local environment as expected. Now let's put it into a container.</p>","tags":["python","docker","poetry","typer"]},{"location":"blog/2022/07/14/how-to-run-a-python-cli-tool-inside-a-docker-container/#building-a-docker-image","title":"Building a Docker Image","text":"<p>To build an image we'll use the <code>Dockerfile</code> located in the <code>docker</code> directory. This is a slightly modified version of the Dockerfile from Baptiste Maingret's blog post Python and Poetry on Docker. Below are the main differences:</p> <ul> <li>No <code>development</code> stage</li> <li><code>python:&lt;version&gt;-slim</code> base image instead of <code>python:&lt;version&gt;</code> to achieve smaller image size</li> </ul> <p>If you wish to learn more about multi-stage builds and how each stage works I encourage you to read the original post. I don't see a point in repeating it all here.</p> <p>Now let's try and build the image.</p> <pre><code>$ docker build --tag nornir_example --file docker/Dockerfile .\nSending build context to Docker daemon  264.7kB\nStep 1/33 : ARG APP_NAME=nornir_example\nStep 2/33 : ARG APP_PATH=/opt/$APP_NAME\nStep 3/33 : ARG PYTHON_VERSION=3.10.5\nStep 4/33 : ARG POETRY_VERSION=1.1.14\nStep 5/33 : FROM python:$PYTHON_VERSION-slim as staging\n3.10.5-slim: Pulling from library/python\n461246efe0a7: Pull complete\ne37ebf440f7f: Pull complete\n07053eece5a2: Pull complete\n912bc51860fb: Pull complete\n40c89643d0cd: Pull complete\nDigest: sha256:b208c71e1d72864460394cc648c6b5c1ddac6f8587af4a3a54b7be575353f5d0\nStatus: Downloaded newer image for python:3.10.5-slim\n ---&gt; ba94a8d11761\nStep 6/33 : ARG APP_NAME\n ---&gt; Running in a776b2225274\nRemoving intermediate container a776b2225274\n ---&gt; 29cdb0b73534\nStep 7/33 : ARG APP_PATH\n ---&gt; Running in 21a63ae8c42a\nRemoving intermediate container 21a63ae8c42a\n ---&gt; ae644555434e\nStep 8/33 : ARG POETRY_VERSION\n ---&gt; Running in fea008b79cef\nRemoving intermediate container fea008b79cef\n ---&gt; 6abfb54c244b\nStep 9/33 : ENV     PYTHONDONTWRITEBYTECODE=1     PYTHONUNBUFFERED=1     PYTHONFAULTHANDLER=1\n---&gt; Running in 835da12b6314\nRemoving intermediate container 835da12b6314\n ---&gt; 19ecf8de5dc7\nStep 10/33 : ENV     POETRY_VERSION=$POETRY_VERSION     POETRY_HOME=\"/opt/poetry\"     POETRY_VIRTUALENVS_IN_PROJECT=true     POETRY_NO_INTERACTION=1\n---&gt; Running in e5fd0702b6a6\nRemoving intermediate container e5fd0702b6a6\n ---&gt; 9db6bc0e296f\nStep 11/33 : RUN apt-get update     &amp;&amp; apt-get install --no-install-recommends -y         curl         build-essential\n ---&gt; Running in 3677cc0af114\n\n&lt;SKIPPED&gt;\n\nRemoving intermediate container 3677cc0af114\n ---&gt; c5bda617b63c\nStep 12/33 : RUN curl -sSL https://raw.githubusercontent.com/python-poetry/poetry/master/install-poetry.py | python\n ---&gt; Running in 3c75a7c4d1d9\nThe canonical source for Poetry\\'s installation script is now https://install.python-poetry.org. Please update your usage to reflect this.\nRetrieving Poetry metadata\n\n# Welcome to Poetry!\nThis will download and install the latest version of Poetry,\na dependency and package manager for Python.\n\nIt will add the `poetry` command to Poetry\\'s bin directory, located at:\n\n/opt/poetry/bin\n\nYou can uninstall at any time by executing this script with the --uninstall option,\nand these changes will be reverted.\n\nInstalling Poetry (1.1.14)\nInstalling Poetry (1.1.14): Creating environment\nInstalling Poetry (1.1.14): Installing Poetry\nInstalling Poetry (1.1.14): Creating script\nInstalling Poetry (1.1.14): Done\n\nPoetry (1.1.14) is installed now. Great!\n\nTo get started you need Poetry\\'s bin directory (/opt/poetry/bin) in your `PATH`\nenvironment variable.\n\nAdd `export PATH=\"/opt/poetry/bin:$PATH\"` to your shell configuration file.\n\nAlternatively, you can call Poetry explicitly with `/opt/poetry/bin/poetry`.\n\nYou can test that everything is set up by executing:\n\n`poetry --version`\nRemoving intermediate container 3c75a7c4d1d9\n ---&gt; e68500b33d93\nStep 13/33 : ENV PATH=\"$POETRY_HOME/bin:$PATH\"\n---&gt; Running in 9419724f2c8f\nRemoving intermediate container 9419724f2c8f\n ---&gt; d21e67124847\nStep 14/33 : WORKDIR $APP_PATH\n---&gt; Running in b5c81bfadabc\nRemoving intermediate container b5c81bfadabc\n ---&gt; 42c9d8478d01\nStep 15/33 : COPY ./poetry.lock ./pyproject.toml ./\n ---&gt; aca27919e86c\nStep 16/33 : COPY ./src/$APP_NAME ./src/$APP_NAME\n---&gt; c0e14f41b02d\nStep 17/33 : FROM staging as build\n ---&gt; c0e14f41b02d\nStep 18/33 : ARG APP_PATH\n ---&gt; Running in 4494ee70b3d4\nRemoving intermediate container 4494ee70b3d4\n ---&gt; 1a0107af91c4\nStep 19/33 : WORKDIR $APP_PATH\n---&gt; Running in 980956355e03\nRemoving intermediate container 980956355e03\n ---&gt; bc18c71f9e76\nStep 20/33 : RUN poetry build --format wheel\n ---&gt; Running in 3ae79f203263\nCreating virtualenv nornir-example in /opt/nornir_example/.venv\nBuilding nornir-example (0.1.0)\n- Building wheel\n  - Built nornir_example-0.1.0-py3-none-any.whl\nRemoving intermediate container 3ae79f203263\n ---&gt; 29fbb6dbc6a1\nStep 21/33 : RUN poetry export --format requirements.txt --output constraints.txt --without-hashes\n ---&gt; Running in 6e2db6b40cef\nRemoving intermediate container 6e2db6b40cef\n ---&gt; e89a9d03f210\nStep 22/33 : FROM python:$PYTHON_VERSION-slim as production\n ---&gt; ba94a8d11761\nStep 23/33 : ARG APP_NAME\n ---&gt; Using cache\n ---&gt; 29cdb0b73534\nStep 24/33 : ARG APP_PATH\n ---&gt; Using cache\n ---&gt; ae644555434e\nStep 25/33 : ENV     PYTHONDONTWRITEBYTECODE=1     PYTHONUNBUFFERED=1     PYTHONFAULTHANDLER=1\n---&gt; Running in eef7402691d2\nRemoving intermediate container eef7402691d2\n ---&gt; a0f9365b2042\nStep 26/33 : ENV     PIP_NO_CACHE_DIR=off     PIP_DISABLE_PIP_VERSION_CHECK=on     PIP_DEFAULT_TIMEOUT=100\n---&gt; Running in 25aca6fae069\nRemoving intermediate container 25aca6fae069\n ---&gt; 5c78828a234b\nStep 27/33 : WORKDIR $APP_PATH\n---&gt; Running in bafbe527e199\nRemoving intermediate container bafbe527e199\n ---&gt; 5baf48bc673a\nStep 28/33 : COPY --from=build $APP_PATH/dist/*.whl ./\n ---&gt; 5a36bbbaff1c\nStep 29/33 : COPY --from=build $APP_PATH/constraints.txt ./\n ---&gt; 4418032f2b79\nStep 30/33 : RUN pip install ./$APP_NAME*.whl --constraint constraints.txt\n ---&gt; Running in 6dee852a57b2\nProcessing ./nornir_example-0.1.0-py3-none-any.whl\nCollecting typer&lt;0.5.0,&gt;=0.4.2\n  Downloading typer-0.4.2-py3-none-any.whl (27 kB)\nCollecting nornir&lt;4.0.0,&gt;=3.3.0\n  Downloading nornir-3.3.0-py3-none-any.whl (30 kB)\nCollecting nornir-jinja2&lt;0.3.0,&gt;=0.2.0\n  Downloading nornir_jinja2-0.2.0-py3-none-any.whl (7.2 kB)\nCollecting nornir-utils&lt;0.3.0,&gt;=0.2.0\n  Downloading nornir_utils-0.2.0-py3-none-any.whl (15 kB)\nCollecting typing_extensions&lt;5.0,&gt;=4.1\n  Downloading typing_extensions-4.3.0-py3-none-any.whl (25 kB)\nCollecting mypy_extensions&lt;0.5.0,&gt;=0.4.1\n  Downloading mypy_extensions-0.4.3-py2.py3-none-any.whl (4.5 kB)\nCollecting ruamel.yaml&gt;=0.17\n  Downloading ruamel.yaml-0.17.21-py3-none-any.whl (109 kB)\n\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 109.5/109.5 KB 2.7 MB/s eta 0:00:00\nCollecting jinja2&lt;4,&gt;=2.11.2\n  Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\n\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 133.1/133.1 KB 15.3 MB/s eta 0:00:00\nCollecting colorama&lt;0.5.0,&gt;=0.4.3\n  Downloading colorama-0.4.5-py2.py3-none-any.whl (16 kB)\nCollecting click&lt;9.0.0,&gt;=7.1.1\n  Downloading click-8.1.3-py3-none-any.whl (96 kB)\n\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 96.6/96.6 KB 5.5 MB/s eta 0:00:00\nCollecting MarkupSafe&gt;=2.0\n  Downloading MarkupSafe-2.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\nCollecting ruamel.yaml.clib&gt;=0.2.6\n  Downloading ruamel.yaml.clib-0.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (519 kB)\n\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 519.3/519.3 KB 8.5 MB/s eta 0:00:00\nInstalling collected packages: mypy_extensions, typing_extensions, ruamel.yaml.clib, MarkupSafe, colorama, click, typer, ruamel.yaml, jinja2, nornir, nornir-utils, nornir-jinja2, nornir-example\nSuccessfully installed MarkupSafe-2.1.1 click-8.1.3 colorama-0.4.5 jinja2-3.1.2 mypy_extensions-0.4.3 nornir-3.3.0 nornir-example-0.1.0 nornir-jinja2-0.2.0 nornir-utils-0.2.0 ruamel.yaml-0.17.21 ruame\nl.yaml.clib-0.2.6 typer-0.4.2 typing_extensions-4.3.0\nWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.\npypa.io/warnings/venv\nRemoving intermediate container 6dee852a57b2\n ---&gt; 5a3be02fcc1a\nStep 31/33 : COPY ./docker/docker-entrypoint.sh /docker-entrypoint.sh\n ---&gt; 445bd843b629\nStep 32/33 : RUN chmod +x /docker-entrypoint.sh\n ---&gt; Running in 53d731f0222f\nRemoving intermediate container 53d731f0222f\n ---&gt; 504187ebd4d1\nStep 33/33 : ENTRYPOINT [\"/docker-entrypoint.sh\"]\n---&gt; Running in 17562594a0df\nRemoving intermediate container 17562594a0df\n ---&gt; 0cab130862b5\nSuccessfully built 0cab130862b5\nSuccessfully tagged nornir_example:latest\n</code></pre> <p>You can see that the image was created and tagged:</p> <pre><code>$ docker images\nREPOSITORY                                                      TAG           IMAGE ID       CREATED          SIZE\nnornir_example                                                  latest        0cab130862b5   19 minutes ago   130MB\n&lt;none&gt;                                                          &lt;none&gt;        e89a9d03f210   19 minutes ago   496MB\npython                                                          3.10.5-slim   ba94a8d11761   3 hours ago      125MB\n</code></pre> <p>Now lets run it.</p>","tags":["python","docker","poetry","typer"]},{"location":"blog/2022/07/14/how-to-run-a-python-cli-tool-inside-a-docker-container/#running-the-app-inside-a-container","title":"Running the App Inside a Container","text":"<p>When you start a container, Docker looks for <code>CMD</code> or <code>ENTRYPOINT</code> instructions which tell what to execute inside a container. In our case, we specify only the <code>ENTRYPOINT</code>:</p> <pre><code>ENTRYPOINT [\"/docker-entrypoint.sh\"]\n</code></pre> <p>Let's take a look at this entry point script:</p> <pre><code>#!/bin/sh\nset -e\n\nif [ \"${1#-}\" != \"${1}\" ] || [ -z \"$(command -v \"${1}\")\" ]; then\nset -- cli \"$@\"\nfi\nexec \"$@\"\n</code></pre> <p>To be honest I stole it from the curl Docker image entrypoint </p> <p>So let's break it down and try to understand what it does:</p> <ul> <li><code>\"${1#-}\" != \"${1}\"</code> checks if the first passed argument starts with a <code>-</code></li> <li><code>||</code> execute the second check only if the first one returned <code>False</code></li> <li><code>-z \"$(command -v \"${1}\")\"</code> checks if the passed argument is not a legitimate executable (<code>command -v</code> is an equivalent of <code>which</code>)</li> <li>If either of the checks returns <code>True</code> the passed arguments are added to the <code>cli</code> arguments</li> <li>Otherwise, the passed arguments are treated as a command</li> </ul> <p>This allows you either to pass arguments to the <code>cli</code> app or run other commands inside the container. For example, you can list files inside the container with the <code>ls</code> command.</p> <pre><code>$ docker run nornir_example ls -l\ntotal 8\n-rw-r--r-- 1 root root 1268 Jul 13 08:00 constraints.txt\n-rw-r--r-- 1 root root 2945 Jul 13 08:00 nornir_example-0.1.0-py3-none-any.whl\n</code></pre> <p>But when for instance you pass the <code>--help</code> argument it becomes the <code>cli</code> app option.</p> <pre><code>$ docker run nornir_example --help\nUsage: cli [OPTIONS] COMMAND [ARGS]...\n\nSimple Nornir Example\n\nOptions:\n  --install-completion [bash|zsh|fish|powershell|pwsh]\nInstall completion for the specified shell.\n  --show-completion [bash|zsh|fish|powershell|pwsh]\nShow completion for the specified shell, to\n                                  copy it or customize the installation.\n  --help                          Show this message and exit.\n\nCommands:\n  create-configs  Generate device configurations and put them to local...\n  init            Initialize working directory\n</code></pre> <p>At this point, everything seems fine. But as you remember, our example app interacts with files and directories. So for it to be able to read and write files, we need to mount the working directory inside the container.</p> <p>Let's do it and run the <code>init</code> command.</p> <pre><code>$ docker run  -v $(pwd):/opt/nornir_example nornir_example init\nCreating directories...\nDirectory 'configs' created\nInit complete\n</code></pre> <p>Ok, now we can try and create config files.</p> <pre><code>$ docker run -v $(pwd):/opt/nornir_example nornir_example create-configs\nrender_config*******************************************************************\n* switch01 ** changed : False **************************************************\nvvvv render_config ** changed : False vvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvv INFO\n---- Render config ** changed : False ------------------------------------------ INFO\nhostname switch01\n!\ninterface Vlan10\n description Management\n ip address 10.0.10.1 255.255.255.0\n!\n\n^^^^ END render_config ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n* switch02 ** changed : False **************************************************\nvvvv render_config ** changed : False vvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvv INFO\n---- Render config ** changed : False ------------------------------------------ INFO\nhostname switch02\n!\ninterface Vlan10\n description Management\n ip address 10.0.10.2 255.255.255.0\n!\n\n^^^^ END render_config ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n* switch03 ** changed : False **************************************************\nvvvv render_config ** changed : False vvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvv INFO\n---- Render config ** changed : False ------------------------------------------ INFO\nhostname switch03\n!\ninterface Vlan10\n description Management\n ip address 10.0.10.3 255.255.255.0\n!\n\n^^^^ END render_config ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nwrite_config********************************************************************\n* switch01 ** changed : True ***************************************************\nvvvv write_config ** changed : False vvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvv INFO\n---- Save configs ** changed : True -------------------------------------------- INFO\n--- configs/switch01-config.txt\n\n+++ new\n\n@@ -0,0 +1,6 @@\n\n+hostname switch01\n+!\n+interface Vlan10\n+ description Management\n+ ip address 10.0.10.1 255.255.255.0\n+!\n^^^^ END write_config ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n* switch02 ** changed : True ***************************************************\nvvvv write_config ** changed : False vvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvv INFO\n---- Save configs ** changed : True -------------------------------------------- INFO\n--- configs/switch02-config.txt\n\n+++ new\n\n@@ -0,0 +1,6 @@\n\n+hostname switch02\n+!\n+interface Vlan10\n+ description Management\n+ ip address 10.0.10.2 255.255.255.0\n+!\n^^^^ END write_config ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n* switch03 ** changed : True ***************************************************\nvvvv write_config ** changed : False vvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvv INFO\n---- Save configs ** changed : True -------------------------------------------- INFO\n--- configs/switch03-config.txt\n\n+++ new\n\n@@ -0,0 +1,6 @@\n\n+hostname switch03\n+!\n+interface Vlan10\n+ description Management\n+ ip address 10.0.10.3 255.255.255.0\n+!\n^^^^ END write_config ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n</code></pre> <p>Let's take a look at the resulting files.</p> <pre><code>$ ls -la configs\ntotal 20\ndrwxr-xr-x 2 root          root          4096 Jul 13 09:49 .\ndrwxrwxr-x 9 dmitry.teslya dmitry.teslya 4096 Jul 13 09:43 ..\n-rw-r--r-- 1 root          root            99 Jul 13 09:49 switch01-config.txt\n-rw-r--r-- 1 root          root            99 Jul 13 09:49 switch02-config.txt\n-rw-r--r-- 1 root          root            99 Jul 13 09:49 switch03-config.txt\n</code></pre> <p>As you can see the <code>configs</code> directory and config files are owned by the <code>root</code> user. This happens because the app is running as <code>root</code> inside a container. To mitigate this we can do two things: mount host user database files inside a container and tell docker to run <code>entrypoint</code> as the current user.</p> <p>The resulting command will look bulky though.</p> <pre><code>docker run --user $(id -u):$(id -g) -v /etc/passwd:/etc/passwd:ro -v /etc/shadow:/etc/shadow:ro -v /etc/group:/etc/group:ro -v $(pwd):/opt/nornir_example nornir_example\n</code></pre> <p>For the sake of convenience, you can use the <code>run-in-docker.sh</code> bash script which is included in the repo.</p> <pre><code>./run-in-docker.sh init\nCreating directories...\nDirectory 'configs' already exists\nInit complete\n</code></pre>","tags":["python","docker","poetry","typer"]},{"location":"blog/2022/07/14/how-to-run-a-python-cli-tool-inside-a-docker-container/#wrapping-up","title":"Wrapping Up","text":"<p>In this tutorial, we built a simple Python command-line app and packaged it in a Docker image. Then we learned how we could use <code>ENTRYPOINT</code> to pass arguments to our app running inside a container. And finally, we touched upon the problem of working with files on a host machine.</p> <p>I hope this tutorial will serve you as a good starting point for your future projects. Please, don't hesitate to leave a comment if you find any mistakes or have any suggestions.</p>","tags":["python","docker","poetry","typer"]},{"location":"blog/2020/10/05/network-automation-101/","title":"Network Automation 101","text":"<p>This blog post moved to a dedicated section of this site.</p>"},{"location":"blog/2023/04/24/building-a-template-for-a-network-automation-project/","title":"Building a Template for a Network Automation Project","text":"Cover photo by Alex on Unsplash <p>Using templates for device configurations is a common practice and it has obvious benefits, such as speed and consistency. Working on many small Python automation projects made me think of employing the same approach. Previously I had to copy and adjust a lot of code-related things such as directory structure, poetry settings, CI/CD pipelines, etc. Templating all of this allowed me to reduce the initial scaffolding overhead to a minimum and jump straight into writing code. In this article, I want to share my experience in building such a template.</p> <p>But first, let's focus more on the whys of project templating. Here is what I make of it:</p> <ul> <li>It brings consistency to the projects, especially when working in a team (and there are always at least you and your future self).</li> <li>It enforces the use of best practices, such as linting and formatting.</li> <li>It saves a lot of time for initial project scaffolding.</li> </ul> <p>Info</p> <p>You can find the source code of the template in this  repository.</p> TL;DR <p>To use the template just run: <pre><code>copier gh:dteslya/network-automation-template /path/to/your/new/project\n</code></pre></p> <p>Before going further with the implementation details, I want to clearly define the scope of the template I'm sharing.</p>","tags":["python","copier","poetry","templating"]},{"location":"blog/2023/04/24/building-a-template-for-a-network-automation-project/#goals-and-requirements","title":"Goals and requirements","text":"<p>I didn't have a goal of creating an all-encompassing template to cover every possible use case. This template is heavily opinionated and tailored to my needs. But I believe you can adapt it to your needs without much effort.</p> <p>Below are the assumptions I kept in mind while creating the template.</p>","tags":["python","copier","poetry","templating"]},{"location":"blog/2023/04/24/building-a-template-for-a-network-automation-project/#functional-requirements","title":"Functional requirements","text":"<ul> <li>The project intended use is fairly simple network automation scripting.</li> <li>It must be consumed as a CLI tool (Typer and Rich).</li> <li>It can be run either as a Python script or as a Docker container (see my previous post).</li> <li>It can be run either locally (when developing) or as a CI/CD job on a self-hosted Gitlab CI instance.</li> <li>It's supposed to connect to network devices and query the Source of Truth system, in my case Nautobot (Nornir and Netmiko).</li> <li>Because it interacts with external data sources, data must be parsed and validated (Pydantic).</li> </ul>","tags":["python","copier","poetry","templating"]},{"location":"blog/2023/04/24/building-a-template-for-a-network-automation-project/#code-management-requirements","title":"Code management requirements","text":"<ul> <li>Packaging and dependency management must be automated (Poetry).</li> <li>The resulting project must adhere to the src layout.</li> <li>Common housekeeping tasks must be automated (Invoke).</li> <li>The code must be type-hinted and checked with mypy.</li> <li>Linting and formatting must be applied to code before committing to Git (pre-commit).</li> <li>Commit messages must follow the Conventional Commits specification (Commitizen).</li> <li>Changelog must be created automatically and follow the Keep a Changelog specification. Also covered by Commitizen.</li> <li>There should be a choice of license when creating a project. Currently, I included only APL 2.0, GPLv3, and MIT. Easily extendable.</li> </ul>","tags":["python","copier","poetry","templating"]},{"location":"blog/2023/04/24/building-a-template-for-a-network-automation-project/#what-was-left-out-of-the-scope","title":"What was left out of the scope","text":"<p>At least for now, this template doesn't include:</p> <ul> <li>Documentation building tools</li> <li>Test automation tools</li> <li><code>CODE_OF_CONDUCT.md</code></li> <li><code>CONTRIBUTING.md</code></li> </ul>","tags":["python","copier","poetry","templating"]},{"location":"blog/2023/04/24/building-a-template-for-a-network-automation-project/#choice-of-tooling","title":"Choice of tooling","text":"<p>A quick googling for project templating software gives not so many options.</p> <p>This is the list I've been stumbling upon here and there:</p> <ul> <li>Cookiecutter. Probably the most popular one, with lots of pre-made templates. Written in Python.</li> <li>Yeoman. A bit less popular, and focused on web apps. Written in JS.</li> <li>Copier. The least popular, but modern and has some unique features. Written in Python.</li> </ul> <p>I chose Copier because of my irrational desire to try everything new and shiny. The ability to apply updated templates to already created projects also had its appeal.</p> <p>The project's documentation features a nice comparison table where you can find key differences from other templating tools.</p>","tags":["python","copier","poetry","templating"]},{"location":"blog/2023/04/24/building-a-template-for-a-network-automation-project/#project-structure","title":"Project structure","text":"<p>Now that we know what we want let's look closer at the template implementation.</p> <p>Below is the project structure of the template. Click  for more details.</p> <pre><code>.\n\u251c\u2500\u2500 project # (1)!\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 docker\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 Dockerfile.jinja # (2)!\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 docker-entrypoint.sh.jinja # (3)!\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 src # (4)!\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 {{python_package_import_name}} # (5)!\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u251c\u2500\u2500 __init__.py.jinja\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u251c\u2500\u2500 cli.py.jinja # (6)!\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u251c\u2500\u2500 data_models.py.jinja # (7)!\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u251c\u2500\u2500 logger.py.jinja # (8)!\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u251c\u2500\u2500 py.typed # (9)!\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u251c\u2500\u2500 run.py.jinja # (10)!\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u2514\u2500\u2500 settings.py.jinja # (11)!\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 tests # (12)!\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 test_version.py.jinja\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 .gitignore\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 .gitlab-ci.yml.jinja # (13)!\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 .pre-commit-config.yaml.jinja # (14)!\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 LICENSE.md.jinja\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 README.md.jinja\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 pyproject.toml.jinja # (15)!\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 run-in-docker.sh # (16)!\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 tasks.py.jinja # (17)!\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 {{_copier_conf.answers_file}}.jinja # (18)!\n\u251c\u2500\u2500 .cz.toml # (19)!\n\u251c\u2500\u2500 .gitignore\n\u251c\u2500\u2500 .pre-commit-config.yaml # (20)!\n\u251c\u2500\u2500 CHANGELOG.md\n\u251c\u2500\u2500 LICENSE.md\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 copier.yml # (21)!\n\u2514\u2500\u2500 tasks.py # (22)!\n</code></pre> <ol> <li>Project template directory. I prefer to store all the template files in a separate directory.</li> <li><code>Dockerfile</code> used to build a docker image to run the script as a container.</li> <li>Docker image entrypoint script</li> <li>Where the Python package code resides. See src layout.</li> <li>You can use Jinja variables to generate directory and file names.</li> <li>Python package entrypoint (i.e., what executes when you run the package).</li> <li>A place for Pydantic datamodels.</li> <li>Custom logger is defined here.</li> <li>A marker file indicating that the package is type-hinted. See this post for more details.</li> <li>Example module where the main logic is supposed to reside.</li> <li>Script settings, such as API access tokens.</li> <li>Where tests should go. I included a simple test to check the package version just as a placeholder.</li> <li>Gitlab CI/CD configuration.</li> <li>Project pre-commit configuration.</li> <li>Project meta-information. Used mostly by Poetry, but also includes settings for linters and formatters.</li> <li>Helper script to run the script as a container.</li> <li>Invoke housekeeping tasks.</li> <li>Copier answers file. Used for updating the project with a new version of the template.</li> <li>Template repository commitizen configuration.</li> <li>Template repository pre-commit configuration.</li> <li>Copier configuration file.</li> <li>Invoke housekeeping tasks for the template repository.</li> </ol> <p>Info</p> <p>A few words on how Copier works. On a basic level, it's pretty straightforward: a user runs <code>copier</code> command, answers configured questions, Copier renders the target files from Jinja2 templates, substituting the variables with values provided by a user.</p> <p>This layout differs a bit from what Copier expects by default by placing the template in a separate directory called <code>project</code>(1). This enables a clear separation of the template and its metadata.</p> <ol> <li><code>_subdirectory</code> setting in <code>copier.yml</code></li> </ol>","tags":["python","copier","poetry","templating"]},{"location":"blog/2023/04/24/building-a-template-for-a-network-automation-project/#gitlab-ci-requirements","title":"Gitlab CI requirements","text":"<p>The <code>.gitlab-ci.yml</code> configuration supplied with this template expects the following from your self-hosted Gitlab CI instance:</p> <ul> <li>A runner with the Docker executor tagged with <code>docker</code>.</li> <li>A runner with the Linux shell executor tagged with <code>shell</code>.</li> <li>Because the <code>shell</code> runner is used to run your automation script it is supposed to have network access to the external resources your script interacts with (e.g., ssh access to network devices).</li> </ul> <p>The following environment variables are supposed to be set and accessible by your Gitlab project:</p> Variable Description <code>PROJECT_ACCESS_TOKEN</code> Project access token with read-write access to the repository and the ability to push to the main branch <code>CI_USERNAME</code> Arbitrary git username for the <code>version-bump</code> CI job, e.g. ci-bot <code>CI_EMAIL</code> Email address of the <code>CI_USERNAME</code>, e.g. ci-bot@example.com <code>DOCKER_REGISTRY_RO_PASSWORD</code> Account password with read-only access to the private Docker registry <code>DOCKER_REGISTRY_RO_USER</code> Account username with read-only access to the private Docker registry <code>DOCKER_REGISTRY_RW_PASSWORD</code> Account password with read-write access to the private Docker registry <code>DOCKER_REGISTRY_RW_USER</code> Account username with read-write access to the private Docker registry <code>DOCKER_REGISTRY_URL</code> Private Docker registry URL <p>Of course, you are free to adjust anything to your needs. Just make sure that the environment variables used in the <code>.gitlab-ci.yml</code> match those configured in Gitlab.</p>","tags":["python","copier","poetry","templating"]},{"location":"blog/2023/04/24/building-a-template-for-a-network-automation-project/#demo","title":"Demo","text":"<p>Now let's generate a project out of this template.</p> <p>This created the project directory with all the needed files.</p> <p>Now we can install the dependencies and check that the <code>hello_world</code> function from the included script works.</p> <p>Warning</p> <p>I deliberately included a couple of dummy secrets in <code>settings.py</code> file just for the demo to work out of the box. Otherwise, I'd have to define them as environment variables before running the demo. Don't forget to remove them before committing your changes.</p> <p>At this point, you're ready to proceed with the development of your script.</p>","tags":["python","copier","poetry","templating"]},{"location":"blog/2023/04/24/building-a-template-for-a-network-automation-project/#acknowledgments","title":"Acknowledgments","text":"<ol> <li>How to use copier to create project templates by Haseeb Majid</li> <li>Copier Poetry template by Timoth\u00e9e Mazzucotelli</li> <li>Python Packages Project Generator by Roman Tezikov</li> </ol>","tags":["python","copier","poetry","templating"]},{"location":"blog/2022/09/21/september-2022-update/","title":"September 2022 Update","text":"<p>Yesterday I migrated my blog from Hugo to MkDocs static site generator, supercharged with Material for MkDocs theme. I've been a fan of the project for some time now and was super excited when the blog plugin was announced and finally released.</p> <p>Aside from look and feel, this also brought some other significant changes to this blog:</p> <ul> <li>I decided to drop Staticman comment system in favor of Giscus. Unfortunately, all the old comments had to go, also. I didn't find a quick and reliable way to transfer them to Giscus.</li> <li>Network Automation 101 is now a full-fledged stand-alone document divided into sections for easier reading and editing. And this brings us to the next change.</li> <li>The source code of the whole site is now hosted on the public GitHub repository meaning you can submit PRs if you want to update or add something.</li> </ul> <p>There are still a few things here and there that need polishing, but overall I'm thrilled with the result.</p>"},{"location":"blog/2020/08/14/using-cisco-support-api-with-postman/","title":"Using Cisco Support API with Postman","text":"<p>In this post, I would like to make a quick introduction on how to make use of Cisco Support APIs. Cisco has several Data APIs which allow their partners and customers to consume a lot of different information about their products and services programmatically. Here is the list of all available Data APIs:</p> <ul> <li>Support APIs</li> <li>Services APIs</li> <li>Product Security Incident Reponse Team</li> <li>Business Critical Insights</li> </ul> <p>This post takes Cisco Support API as an example. Actually, Cisco Support API is an umbrella term which includes the following APIs:</p> <ul> <li>Automated Software Distribution</li> <li>Bug</li> <li>Case</li> <li>EoX</li> <li>Product Information</li> <li>Serial Number to Information</li> <li>Service Order Return (RMA)</li> <li>Software Suggestion</li> </ul> <p>As you can see its quite a lot. Here is a few examples of what can be done with it:</p> <ul> <li>Find a recommended software image for a device and download it</li> <li>Find out what devices in your network had EoL announced</li> <li>List all known bugs for a device</li> <li>etc. etc.</li> </ul> <p>As for me, I find EoX and Software Suggestion as most useful in my daily work, because I do customer network audits often.</p>","tags":["cisco","restapi","postman"]},{"location":"blog/2020/08/14/using-cisco-support-api-with-postman/#prerequisites","title":"Prerequisites","text":"<p>This is the bad part. You need a valid contract with Cisco, either SNTC or PSS (Partner Support Service) to get access to Support APIs. Without a contract, you can only get access to a couple of APIs, and the only useful one is the PSIRT openVuln API.</p> <p>This is actually pretty lame because information such as EoX announcements and recommended software is publicly available. Why Cisco demands having a contract to access those APIs is beyound my comprehension.</p>","tags":["cisco","restapi","postman"]},{"location":"blog/2020/08/14/using-cisco-support-api-with-postman/#onboarding","title":"Onboarding","text":"<p>Assuming you have the contract number you need to perform the following tasks to acquire access to APIs.</p>","tags":["cisco","restapi","postman"]},{"location":"blog/2020/08/14/using-cisco-support-api-with-postman/#sntc","title":"SNTC","text":"<p>Your Cisco account must have an API developer role. To check this:</p> <ol> <li>Login to cisco.com</li> <li>Go to Manage Profile</li> <li>Find Smart Services section</li> <li>Check if API Developer role is active</li> </ol> <p>If not, either:</p> <ol> <li>Find out who in your company is a company administrator by clicking on Contact Company Administrator</li> <li>Ask them to assign that role to your account</li> </ol> <p>Or</p> <ol> <li>Become your company administrator by following this guide</li> <li>Assign API developer role to your account</li> </ol>","tags":["cisco","restapi","postman"]},{"location":"blog/2020/08/14/using-cisco-support-api-with-postman/#pss","title":"PSS","text":"<p>This is the path I took as our company has Cisco partner status. The detailed guide can be found here, but there is a catch. When I followed this guide to open a support case I ran into an issue. I couldn't bypass the entitlement check when opening a case as its described in the guide, so I had to click the \"Chat Now\" button and ask for support (to open a support case ). Fortunately, they responded quickly and created a case on my behalf. All I needed to provide was our company PSS contract number and a list of APIs I needed access to. After that, it took about 2 days for the actual support case to complete.</p>","tags":["cisco","restapi","postman"]},{"location":"blog/2020/08/14/using-cisco-support-api-with-postman/#cisco-api-console","title":"Cisco API Console","text":"<p>At last, after finishing all the administrative quests we can proceed to the technical part. To use any of the APIs you first need to register your application. This is done in the Cisco API Console. Below are the detailed steps:</p> <ol> <li>Log in with you cisco.com credentials</li> <li>Go to My Apps &amp; Keys</li> <li>Click Register a New App</li> <li>Enter the Name of your application. This can be anything and is needed only to distinguish between different applications</li> <li>In the OAuth2.0 Credentials section check only the Client Credentials checkbox {{&lt; alert message=\"When I selected more than one grant type I always got invalid_client error. More on this here.\" type=\"warn\" badge=\"Important\" &gt;}}</li> <li>Select one or more APIs you plan to use with this application (this can be changed later)</li> <li>Check I agree to the terms of service and click Register</li> <li>You will be redirected to a page saying that your application has been registered</li> <li>Now click on My Apps &amp; Keys and you will see something like this:      Cisco API Console - Apps &amp; Keys </li> <li>Make note of the KEY and CLIENT SECRET values</li> </ol>","tags":["cisco","restapi","postman"]},{"location":"blog/2020/08/14/using-cisco-support-api-with-postman/#postman-setup","title":"Postman setup","text":"<p>Postman is a great tool to test and develop APIs. It has a simple GUI and is available on Windows, Linux, and macOS. It's also extensively featured in various DevNet docs. Installation is pretty straightforward and I don't want to linger on it here.</p> <p>To simplify Support API consumption in Postman you can download WADL files from Cisco and then import them as collections. Collections in Postman are just pre-configured API requests.</p>","tags":["cisco","restapi","postman"]},{"location":"blog/2020/08/14/using-cisco-support-api-with-postman/#eox-example","title":"EoX Example","text":"<p>Now let's try and make an API call to EoX API as an example. If you have imported a WADL file in the previous steps then your Postman window should look like this:</p> <p> </p> Postman - Collections <p>I use Get EoX by Product ID(s) method in this example.</p> <p>To make an API call we first need to get an auth token. To do this switch to the Authorization tab and select OAuth 2.0 type and Request Headers in the \"Add authorization data to\" field.</p> <p> </p> Postman - Authorization <p>Now click on Get New Access Token button and fill the following fields accordingly:</p> <p> </p> Postman - New Access Token <ul> <li>Token Name - just any name for the token, <code>eox_test</code> for example</li> <li>Grant Type - Client Credentials (remember we selected it during the app registration)</li> <li>Access Token URL - <code>https://cloudsso.cisco.com/as/token.oauth2</code> (I learned this URL from here)</li> <li>Client ID - your application KEY</li> <li>Client Secret - your application CLIENT SECRET</li> <li>Client Authentication - Send as Basic Auth header</li> </ul> <p>Click Request Token and you should see the following result:</p> <p> </p> Postman - Manage Access Tokens <p>Click Use Token and that's it for the authorization.</p> <p>Now we need to specify request parameters. Take a look at the Path Variables section of the request. Here you need to specify <code>version</code> which is <code>5</code> and <code>productIDs</code> which can be a single PID or a list separated by commas (250 symbols max).</p> <p> </p> Postman - Request Params <p>You can also specify the <code>responseencoding</code> which can be either JSON (default) or XML.</p> <p>When all is set click Send button and you should get the response in the lower half of the Postman window.</p> <p> </p> Postman - Response body Click here to see the whole response I've got in this example <pre><code>{\n\"PaginationResponseRecord\": {\n\"PageIndex\": 1,\n\"LastIndex\": 1,\n\"TotalRecords\": 2,\n\"PageRecords\": 2\n},\n\"EOXRecord\": [\n{\n\"EOLProductID\": \"WIC-1T=\",\n\"ProductIDDescription\": \"1-Port Serial WAN Interface Card\",\n\"ProductBulletinNumber\": \"EOL6640\",\n\"LinkToProductBulletinURL\": \"http://www.cisco.com/en/US/prod/      collateral/routers/ps5854/eol_c51_513300.html\",\n\"EOXExternalAnnouncementDate\": {\n\"value\": \"2008-12-28\",\n\"dateFormat\": \"YYYY-MM-DD\"\n},\n\"EndOfSaleDate\": {\n\"value\": \"2009-12-28\",\n\"dateFormat\": \"YYYY-MM-DD\"\n},\n\"EndOfSWMaintenanceReleases\": {\n\"value\": \"2010-12-28\",\n\"dateFormat\": \"YYYY-MM-DD\"\n},\n\"EndOfSecurityVulSupportDate\": {\n\"value\": \"\",\n\"dateFormat\": \"YYYY-MM-DD\"\n},\n\"EndOfRoutineFailureAnalysisDate\": {\n\"value\": \"2010-12-28\",\n\"dateFormat\": \"YYYY-MM-DD\"\n},\n\"EndOfServiceContractRenewal\": {\n\"value\": \"2014-03-28\",\n\"dateFormat\": \"YYYY-MM-DD\"\n},\n\"LastDateOfSupport\": {\n\"value\": \"2014-12-31\",\n\"dateFormat\": \"YYYY-MM-DD\"\n},\n\"EndOfSvcAttachDate\": {\n\"value\": \"2010-12-28\",\n\"dateFormat\": \"YYYY-MM-DD\"\n},\n\"UpdatedTimeStamp\": {\n\"value\": \"2012-12-06\",\n\"dateFormat\": \"YYYY-MM-DD\"\n},\n\"EOXMigrationDetails\": {\n\"PIDActiveFlag\": \"Y\",\n\"MigrationInformation\": \"1-Port Serial WAN Interface Card\",\n\"MigrationOption\": \"Enter PID(s)\",\n\"MigrationProductId\": \"HWIC-1T=\",\n\"MigrationProductName\": \"\",\n\"MigrationStrategy\": \"\",\n\"MigrationProductInfoURL\": \"http://www.cisco.com/en/US/prod/       collateral/modules/ps5949/datasheet_c78-491363.html\"\n},\n\"EOXInputType\": \"ShowEOXByPids\",\n\"EOXInputValue\": \"WIC-1T= \"\n},\n{\n\"EOLProductID\": \"ASA5505-K8\",\n\"ProductIDDescription\": \"ASA 5505 Appliance with SW, 10 Users, 8       ports, DES\",\n\"ProductBulletinNumber\": \"EOL11376\",\n\"LinkToProductBulletinURL\": \"https://www.cisco.com/c/en/us/products/       collateral/security/asa-5505-adaptive-security-appliance/      eos-eol-notice-c51-738642.html\",\n\"EOXExternalAnnouncementDate\": {\n\"value\": \"2017-02-24\",\n\"dateFormat\": \"YYYY-MM-DD\"\n},\n\"EndOfSaleDate\": {\n\"value\": \"2017-08-25\",\n\"dateFormat\": \"YYYY-MM-DD\"\n},\n\"EndOfSWMaintenanceReleases\": {\n\"value\": \"2018-08-25\",\n\"dateFormat\": \"YYYY-MM-DD\"\n},\n\"EndOfSecurityVulSupportDate\": {\n\"value\": \"2020-08-24\",\n\"dateFormat\": \"YYYY-MM-DD\"\n},\n\"EndOfRoutineFailureAnalysisDate\": {\n\"value\": \"2018-08-25\",\n\"dateFormat\": \"YYYY-MM-DD\"\n},\n\"EndOfServiceContractRenewal\": {\n\"value\": \"2021-11-20\",\n\"dateFormat\": \"YYYY-MM-DD\"\n},\n\"LastDateOfSupport\": {\n\"value\": \"2022-08-31\",\n\"dateFormat\": \"YYYY-MM-DD\"\n},\n\"EndOfSvcAttachDate\": {\n\"value\": \"2018-08-25\",\n\"dateFormat\": \"YYYY-MM-DD\"\n},\n\"UpdatedTimeStamp\": {\n\"value\": \"2017-09-27\",\n\"dateFormat\": \"YYYY-MM-DD\"\n},\n\"EOXMigrationDetails\": {\n\"PIDActiveFlag\": \"Y\",\n\"MigrationInformation\": \"\",\n\"MigrationOption\": \"Enter Product Name(s)\",\n\"MigrationProductId\": \"\",\n\"MigrationProductName\": \"ASA5506-X Series\",\n\"MigrationStrategy\": \"\",\n\"MigrationProductInfoURL\": \"http://www.cisco.com/c/en/us/      support/security/asa-5506-x-firepower-services/model.html\"\n},\n\"EOXInputType\": \"ShowEOXByPids\",\n\"EOXInputValue\": \"ASA5505-K8 \"\n}\n]\n}\n</code></pre> <p>Note</p> <p>Sometimes <code>MigrationProductName</code> returns a legacy model, so you should check it too if you want to be 100% confident that the replacement model is not EoL.</p>","tags":["cisco","restapi","postman"]},{"location":"blog/2020/08/14/using-cisco-support-api-with-postman/#conclusion","title":"Conclusion","text":"<p>I hope you find this article useful, especially the parts about getting access to the APIs which I find non-trivial. Please, leave a comment if you have any questions or found any inaccuracies.</p> <p>I'd also like to mention Cisco Services APIs Ansible Playbooks repo which helped me a lot when I was figuring out how to access Cisco Support APIs.</p>","tags":["cisco","restapi","postman"]},{"location":"network-automation-101/","title":"Network Automation 101","text":"<p>In this document, I gathered most of what I'd learned about network automation so far in a structured and concise manner. The main audience of this guide are engineers who want to start automating their networks but are overwhelmed by the abundance of terms, tools, and concepts.</p> <p> </p> Automation <p>I hope this guide will give you a good overview of the network automation landscape. If you decide to learn more I encourage you to set up a lab and get some hands-on experience. Then when you are ready to apply your new skills in daily work I recommend to start small and look for the low hanging fruits. For example, you can automate information gathering from your network devices (e.g. config backup) and then, when you feel more comfortable, begin to configure devices programmatically.</p>"},{"location":"network-automation-101/references/","title":"References and further reading","text":"<ul> <li>Network Programmability and Automation a book by Jason Edelman, Scott S. Lowe, Matt Oswalt</li> <li>Hands-on with NetDevOps by Julio Gomez</li> <li>What is NetDevOps? by Rick Donato</li> <li>A practical approach to building a network CI/CD pipeline by Samir Parikh</li> <li>NetDevOps: what does it even mean? by Madison Emery (Cumulus Networks)</li> <li>Awesome Network Automation \u2014 curated Awesome list about Network Automation</li> <li>6 Docker Basics You Should Completely Grasp When Getting Started by Vladislav Supalov</li> <li>First Steps With Python by Derrick Kearney</li> <li>Python Cheatsheet \u2014 handy one-page website with examples</li> <li>Fluent Python \u2014 a book by Luciano Ramalho</li> <li>Learning Python  \u2014 a free email Python course by Kirk Byers specifically intended for network engineers</li> <li>Data Structures And Algorithms In Python \u2014 a video tutorial by Dhaval Patel</li> </ul>"},{"location":"network-automation-101/social-media-resources/","title":"Social Media Resources","text":"<p>To keep up with the ever changing automation landscape I recommend to follow these fine people on Twitter:</p> <ul> <li> @ccurtis584</li> <li> @damgarros</li> <li> @danieldibswe</li> <li> @dbarrosop</li> <li> @dmfigol</li> <li> @IPvZero</li> <li> @jeaubin5</li> <li> @jedelman8</li> <li> @jstretch85</li> <li> @kirkbyers</li> <li> @lykinsb</li> <li> @mirceaulinic</li> <li> @natenka_says</li> <li> @networktocode</li> <li> @ntdvps</li> <li> @nwkautomaniac</li> <li> @rickjdon</li> <li> @simingy</li> <li> @tahigash3</li> <li> @vanderaaj</li> </ul>"},{"location":"network-automation-101/01-devops/","title":"DevOps","text":"<p>When trying to grasp a new concept or technology I find it helpful to spend some extra time learning about the subject's origins. It gives context and perspective which are crucial for grasping something complex. So before diving into the network automation topic I'd like to drop a few lines about where it all came from.</p> <p>Of course, in some way network automation has been around for quite a long time. You can remember such examples as using Expect to connect to network devices and issue commands or writing EEM scripts on Cisco routers, or maybe running scripts which retrieve useful information from network devices via SNMP. So what has changed since then? Why network automation is such a hot topic right now? My answer is \u2014 the rise of DevOps movement.</p> <p> </p> DevOps Lifecycle <p>DevOps term first emerged somewhere around 2008 and 2009 and is attributed to Patrick Debois. In 2009 he held an event called DevOpsDays which main purpose was to bring together developers and system administrators and discuss the ways of how to bridge the gap between the two. This gained enough traction and the DevOps became a buzzword.</p> <p>But what is DevOps? There is no academic definition, but the most common one states that it is a set of tools, practices, and philosophies aimed to bridge the gap between the development and operational teams in order to build quality software faster.</p> <p>If you want to learn more about DevOps I recommend this \ud83d\udc49  awesome list.</p> <p>DevOps has many aspects to it but I'd like to focus on three key practices which it brings: Infrastructure as Code, CI/CD, and version control.</p>"},{"location":"network-automation-101/01-devops/#infrastructure-as-code","title":"Infrastructure as Code","text":"<p>According to Wikipedia, IaC is ...</p> <p>... the process of managing and provisioning computer data centers through machine-readable definition files, rather than physical hardware configuration or interactive configuration tools.</p> <p>What this really means is that you have a bunch of text files where you define the desired state of your infrastructure: number of VMs, their properties, virtual networks, IP addresses etc. etc. Then these files are processed by IaC tool or framework (Terraform, SaltStack, Ansible are just a few examples) which translates that declared state into actual API calls and configuration files and applies it to the infrastructure in order to bring it to the desired state. This gives you a level of abstraction since you focus only on the resulting state and not on how to achieve it. Here I should mention one of the key features of the IaC approach which is idempotence. This feature allows you to run an IaC tool repeatedly and if something is already in the desired state it won't touch it. For example, if you declare that a certain VLAN should be configured on a switch and it is already there when you run an IaC tool against that switch it won't try to configure anything.</p> <p>Treating your infrastructure as text files enables you to apply the same tools and practices to infrastructure as one would apply to any other software project. CI/CD and version control are the main examples here.</p>"},{"location":"network-automation-101/01-devops/#cicd","title":"CI/CD","text":"<p>CI/CD stands for Continuous Integration / Continuous Delivery or Deployment. Let's look into each component in more detail.</p> <p>Continuous Integration \u2014 a process of frequent (up to several times a day) merges of code changes to the main code repository. These merges are accompanied by various tests and quality control processes such as unit and integration tests, static code analysis, extraction of documentation from the source code, etc. This approach allows to integrate code changes frequently by different developers therefore mitigating risks of integration conflicts.</p> <p>Continuous Delivery \u2014 extension of CI which takes care of automating the release process (e.g. packaging, image building, etc). Continuous delivery allows you to deploy your application to the production environment at any time.</p> <p>Continuous Deployment \u2014 extension of continuous delivery, but this time deployment to production is also automated.</p>"},{"location":"network-automation-101/01-devops/#version-control","title":"Version control","text":"<p>A version control system is a foundation for any automation project. It tracks changes in your project files (source code), logs who made those changes, and enables CI/CD workflows.</p> <p>Today Git is the de facto standard in version control systems. Essentially Git is just a command-line tool (though very powerful) that manages project versioning by creating and manipulating metadata kept in a separate hidden directory in the project's working directory. But all the magic comes with web-based source control systems such as GitHub or GitLab among others.</p> <p>Many people confuse Git and GitHub because the latter became a generic term for version control systems.</p> <p>Let's suppose you are on a team of developers working on a project hosted on GitHub. Your typical workflow  will go like this:</p> <ul> <li>You want to make changes to the source code. It may be a bug fix or a new feature. You create a new branch from the main one and start making commits. This doesn't affect the main branch in any way.</li> <li> <p>When the work seems to be done it's time to create a pull request. PR is a way to tell other developers (project maintainers) that you want to merge your branch with the main one. PR creation can trigger CI tests if they are configured. After all CI tests pass successfully the code is reviewed by other team members. If CI tests fail or something needs to be improved the PR will be rejected. Then you can fix your code in the same branch and create another PR.</p> <p>Usually, PR's are never merged automatically and someone needs to make the final decision.</p> </li> <li> <p>If everything is good your branch will be merged with the main one.</p> </li> <li>If CD is configured merging with the main branch triggers deployment to the production environment.</li> </ul>"},{"location":"network-automation-101/01-devops/#summary","title":"Summary","text":"<p>In this section, I gave a brief overview of what DevOps is and it's main tools and practices. In the next section, I'll try to explain how it can be applied to networks and network automation.</p>"},{"location":"network-automation-101/02-netdevops/","title":"NetDevOps","text":"<p>Now that you've read the previous section you should guess that NetDevOps is just a DevOps approach applied to networking. All of the aforementioned key DevOps practices can be aligned with the network: device configurations can be templated (IaC) and put into a version control system where CI/CD processes are applied.</p> <p>Below is the sample diagram representing the whole process.</p> <p> </p> NetDevOps Pipeline <p>The workflow starts with a network operator introducing a change (1) either to the Source of Truth or to the configuration templates. So what are those exactly?</p> <p>Source of Truth is a database (e.g. SQL DB or plain text files) where constants such as VLAN numbers and IP addresses are stored. Actually, this can be several databases \u2014 you can get your IP information from IPAM and interface descriptions from DCIM (Netbox is a great example that can do both). The key idea here is that each database must be the single source of truth for the particular piece of information, so when you need to change something you change it only in one place.</p> <p>Configuration templates are just text files written in a templating language of choice (I guess Jinja2 is the most popular one). When combined with the info from the SoT they produce device-specific config files. Templating allows you to break down device configurations into separate template files each one representing a specific config section and then mix and match them to produce configurations for different network devices. Some templates may be reused across multiple devices and some may be created for specific software versions or vendors.</p> <p>Making changes to the SoT or the templates triggers (2) the rest of the process. First, both those sources of information are used by the configuration management system (e.g. Ansible, more on this later) to generate the resulting configuration files to be applied to the network devices. These configs then must be validated (3). Validation usually includes several automated tests (syntax check, use of modeling software, spinning up virtual devices) and a peer review. If validation fails some form of feedback is given to the initiator of change (4) so they can remediate and start the whole process again. If validation is passed resulting configs can be deployed to the production network (5).</p> <p>Of course, the presented workflow is rather schematic and aims to give a general idea of the network automation process and the role of the core components in it.</p> <p>In the next section, I'm going to look at the tools and technologies one can utilize in network automation workflows.</p>"},{"location":"network-automation-101/03-data-models-encodings/","title":"Data Models and Encodings","text":"<p>Understanding how data can be structured and encoded is very important in programming in general and network automation in particular.</p>"},{"location":"network-automation-101/03-data-models-encodings/#yang-openconfig","title":"YANG &amp; Openconfig","text":"<p>YANG (Yet Another Next Generation) is a data modeling language originally developed for NETCONF and defined in RFC 6020 and then updated in RFC 7950. YANG and NETCONF can be considered as successors to SMIng and SNMP respectively. </p> <p>YANG provides a format-independent way to describe a data model that can be represented in XML or JSON.</p> <p>Jason Edelman, Scott S. Lowe, Matt Oswalt. Network Programmability and Automation, p. 183</p> <p>There are hundreds of YANG data models available both vendor-neutral and vendor-specific. The YANG catalog web site can be helpful if you need to find data models relevant to your tasks.</p> <p>Because of this abundance of data models and lack of coordination between standards developing organizations and vendors it seems that YANG and NETCONF are going the same path SNMP went (i.e. used only for data retrieval, but not configuration). OpenConfig workgroup tries to solve this by providing vendor-neutral data models, but I think that Ivan Pepelnjak's point from 2018 stating that \"seamless multi-vendor network device configuration is still a pipe dream\" still holds in 2020.</p>"},{"location":"network-automation-101/03-data-models-encodings/#xml","title":"XML","text":"<p>XML (eXtensible Markup Language) although a bit old is still widely used in various APIs. It uses tags to encode data hence is a bit hard to read by humans. It was initially designed for documents but is suitable to represent arbitrary data structures.</p> <p>You can refer to this tutorial to learn more about XML.</p> <p>Let's see how this sample CLI output of Cisco IOS <code>show vlan</code> command can be encoded with XML:</p> CLI outputXML <pre><code>VLAN Name                             Status    Ports\n---- -------------------------------- ---------   -------------------------------\n1    default                          active    Gi3/4, Gi3/5, Gi4/11\n\n&lt;...&gt;\n\nVLAN Type  SAID       MTU   Parent RingNo BridgeNo Stp  BrdgMode Trans1 Trans2\n---- ----- ---------- ----- ------ ------ -------- ---- -------- ------ ------\n1    enet  100001     1500  -      -      -        -    -        0      0\n</code></pre> <pre><code>&lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt;\n&lt;root&gt;\n&lt;vlans&gt;\n&lt;1&gt;\n&lt;interfaces&gt;GigabitEthernet3/4&lt;/interfaces&gt;\n&lt;interfaces&gt;GigabitEthernet3/5&lt;/interfaces&gt;\n&lt;interfaces&gt;GigabitEthernet4/11&lt;/interfaces&gt;\n&lt;mtu&gt;1500&lt;/mtu&gt;\n&lt;name&gt;default&lt;/name&gt;\n&lt;said&gt;100001&lt;/said&gt;\n&lt;shutdown&gt;false&lt;/shutdown&gt;\n&lt;state&gt;active&lt;/state&gt;\n&lt;trans1&gt;0&lt;/trans1&gt;\n&lt;trans2&gt;0&lt;/trans2&gt;\n&lt;type&gt;enet&lt;/type&gt;\n&lt;vlan_id&gt;1&lt;/vlan_id&gt;\n&lt;/1&gt;\n&lt;/vlans&gt;\n&lt;/root&gt;\n</code></pre>"},{"location":"network-automation-101/03-data-models-encodings/#yaml","title":"YAML","text":"<p>YAML (YAML Ain\u2019t Markup Language) is a human-friendly data serialization format. Because YAML is really easy to read and write it is widely used in modern automation tools  for configuration files and even for defining automation tasks logic (see Ansible).</p> <p>You can refer to this tutorial to learn more about YAML.</p> <p>Here is a <code>show vlan</code> output from previous subsection encoded in YAML:</p> <pre><code>---\nvlans:\n'1':\ninterfaces:\n- GigabitEthernet3/4\n- GigabitEthernet3/5\n- GigabitEthernet4/11\nmtu: 1500\nname: default\nsaid: 100001\nshutdown: false\nstate: active\ntrans1: 0\ntrans2: 0\ntype: enet\nvlan_id: '1'\n</code></pre> <p>Bonus: a collection of YAML shortcomings.</p>"},{"location":"network-automation-101/03-data-models-encodings/#json","title":"JSON","text":"<p>JSON (JavaScript Object Notation) is a modern data encoding format defined in RFC 7159 and widely used in web APIs. It's lightweight, human-readable, and is more suited for data models of modern programming languages than XML.</p> <p>You can refer to this tutorial to learn more about JSON.</p> <p>Here is the sample data from previous sections encoded in JSON:</p> <p><pre><code>{\n\"vlans\": {\n\"1\": {\n\"interfaces\": [\n\"GigabitEthernet3/4\",\n\"GigabitEthernet3/5\",\n\"GigabitEthernet4/11\"\n],\n\"mtu\": 1500,\n\"name\": \"default\",\n\"said\": 100001,\n\"shutdown\": false,\n\"state\": \"active\",\n\"trans1\": 0,\n\"trans2\": 0,\n\"type\": \"enet\",\n\"vlan_id\": \"1\"\n}\n}\n}\n</code></pre> As you can see it's almost as easy to read as YAML, however, native JSON doesn't support comments making it not very suitable for configuration files.</p>"},{"location":"network-automation-101/03-data-models-encodings/#summary","title":"Summary","text":"<p>Here is a summary table representing the key properties of the described data formats.</p> XML YAML JSON Human readable not really yes yes Purpose documents, APIs configuration files APIs Python libs xml, lxml PyYAML json <p>There are online tools like this one to convert data between all three formats.</p>"},{"location":"network-automation-101/04-technologies/","title":"Technologies","text":"<p>This section is quite opinionated and aims to introduce you to the essential tools leaving behind many others for the sake of brevity. I highly recommend to take a look at the Awesome Network Automation list later.</p>"},{"location":"network-automation-101/04-technologies/01-python/","title":"Python","text":"<p>Python is a go-to programming language when it comes to network automation. All of the popular network automation tools and libraries are written in Python.</p> <p> </p> Python <p>Due to its gentle learning curve and immense popularity (second most used language on GitHub after JavaScript as of the time of writing), Python is a great choice to get started with programming.</p> <p>Python basics are out of the scope of this guide. I've supplied several online resources that can help with learning Python in the References and further reading section.</p> <p>To effectively use Python to solve basic network automation problems you will need to learn this set of skills:</p> <ul> <li>Setting up Python on your system</li> <li>Using virtual environments and installing packages with Pip</li> <li>Understanding of the basic Python concepts such as:</li> <li>Variables</li> <li>Data structures</li> <li>Functions</li> <li>Imports</li> </ul> <p>As you can see it's not overwhelming and I encourage you to spend some time on it because it'll make your automation journey so much easier.</p>"},{"location":"network-automation-101/04-technologies/02-interacting/","title":"Interacting with network devices","text":"<p>There are two major ways of accessing network devices programmatically: CLI and API.</p>"},{"location":"network-automation-101/04-technologies/02-interacting/#cli","title":"CLI","text":"<p>For a long time, the only API of network devices was CLI which is designed to be used by humans and not automation scripts. These are the main drawbacks of using CLI as an API: * Inconsistent output   The same command outputs may differ from one NOS (Network Operating System) version to another. * Unstructured data   Data returned by command execution in CLI is plain text, which means you have to manually parse it (i.e. CLI scraping) * Unreliable command execution   You don't get a status code of an executed command and have to parse the output to determine whether the command succeeded or failed.</p> <p>Despite more and more networking vendors begin to include API support in their products it's unlikely that you won't have to deal with CLI during your network automation journey.</p> <p>To parse CLI output regular expressions are used. Not a very user-friendly technology to put it mildly.</p> <p>\u201cI don\u2019t know who you are. I don\u2019t know what you want. If you are looking for technical help, I can tell you I don\u2019t have any time. But what I do have are a very particular set of regexes. Regexes I have acquired over a very long career. Regexes that are a nightmare for people like you to debug. If you leave me alone now, that\u2019ll be the end of it. I will not look for you, I will not pursue you, but if you don\u2019t, I will look for you, I will find you and I will use them in your code.\u201d</p> <p>Quotes from the Cloudiest WebScaliest DevOps Teams</p> <p>Fortunately, there are a lot of tools and libraries today that make CLI scraping easier by doing a lot of the regex heavy lifting.</p>"},{"location":"network-automation-101/04-technologies/02-interacting/#apis","title":"APIs","text":"<p>If you are lucky and devices in your network have an API or maybe are even driven by SDN controller this section is for you. Network APIs fall into two major categories: HTTP-based and NETCONF-based.</p>"},{"location":"network-automation-101/04-technologies/02-interacting/#restful-apis","title":"RESTful APIs","text":"<p>REST stands for Representational State Transfer and defines a set of properties and constraints which an API must conform to in order to be called RESTful.</p> <p> </p> Insulting made easy <p>HTTP-based APIs may be RESTful and non-RESTful. Non-RESTful HTTP-based APIs are left out of scope because they are less common.</p> <p>RESTful APIs are quite easy to use and understand because they are based on HTTP protocol. Basically, RESTful API is just a set of HTTP URLs on which you can make GET and/or POST requests except for returned data is encoded in JSON or XML, not HTML. Since RESTful APIs are HTTP-based they are stateless by nature. This means each request is independent of another and has to supply all the needed information to be properly processed.</p> <p>To explore RESTful APIs you can use tools such as cURL or Postman, but when you are ready to write some code utilizing RESTful API you can use a Python library called requests.</p> <p>There are several mock REST APIs online which you can use for practice. For example, kanye.rest and JSONPlaceholder.</p>"},{"location":"network-automation-101/04-technologies/02-interacting/#netconf-restconf","title":"NETCONF &amp; RESTCONF","text":"<p>NETCONF is a protocol specifically designed for managing network devices. Unlike REST it uses SSH as transport and is stateful as a result. The other key differences of NETCONF are clear delineation between configurational and operational data and the concept of configuration datastores. NETCONF defines three datastores: running configuration, startup configuration, and candidate configuration. You may be familiar with all three of them in the context of network devices. The candidate configuration concept allows to deliver a configuration change consisting of many commands as one transaction. This means that if only one command in a transaction fails the transaction does not succeed avoiding a situation when the partial configuration is applied.</p> <p>Exploring NETCONF APIs is not as easy and straightforward as with RESTful APIs. To do so you need to establish an interactive SSH session to a device and send lengthy XML-encoded commands. To access NETCONF APIs programmatically there is a ncclient Python library.</p> <p>RESTCONF is another standard protocol which implements a subset of NETCONF functionality (e.g. transactions are not supported) and uses HTTP as transport and is RESTful.</p> <p>When choosing between NETCONF and RESTCONF it's advised to use the former for direct interactions with network devices and the latter for interactions with SDN-controllers and/or orchestrators.</p>"},{"location":"network-automation-101/04-technologies/02-interacting/#grpc-gnmi","title":"gRPC &amp; gNMI","text":"<p>gNMI is a new addition to network management protocols based on Google's gRPC and developed by OpenConfig working group. It is considered to be a more robust successor of NETCONF and supports streaming telemetry.</p> <p>Because gNMI is not yet as mature as NETCONF it is not very well supported in Python. Though there are a couple of libraries you can look into: cisco-gnmi and pygnmi.</p>"},{"location":"network-automation-101/04-technologies/02-interacting/#summary","title":"Summary","text":"<p>Here is a summary table representing the key properties of network API types.</p> REST NETCONF RESTCONF gNMI RFC - RFC 6241 RFC 8040 Draft Transport HTTP SSH HTTP gRPC (HTTP/2.0) Data encoding XML, JSON XML XML, JSON ProtoBuf (binary) Transaction support \u274c \u2705 \u274c \u2705 Python libs requests ncclient requests cisco-gnmi, pygnmi"},{"location":"network-automation-101/04-technologies/03-git/","title":"Git","text":"<p>This section covers basic Git usage and terminology. But first, I'd like to highlight several reasons why you should care about Git and version control in the first place.</p> <p> </p> Git"},{"location":"network-automation-101/04-technologies/03-git/#why-use-git","title":"Why use Git?","text":"<ul> <li>Visibility &amp; control   By placing your scripts, configuration templates, or even device configurations in Git you can start tracking all the changes and rollback to previous versions if needed.</li> <li>Experimenting   When working on a new feature it's very convenient to create a new branch in the same Git repository rather than copy the whole working directory to a new place.</li> <li>Teamwork   Sooner or later you'll need to share your work with your teammates. Git is the best tool to collaborate without the need to send each other file copies.</li> <li>CI/CD   CI/CD processes are based around source control. Events such as commits or branch merging trigger CI/CD pipelines.</li> </ul>"},{"location":"network-automation-101/04-technologies/03-git/#terminology","title":"Terminology","text":""},{"location":"network-automation-101/04-technologies/03-git/#repository","title":"Repository","text":"<p>Git repository is a project's directory containing all the project files plus a hidden directory named <code>.git</code> where all the Git metadata (change history, configuration, etc.) resides. In the example below <code>example-repo</code> is a Git repository.</p> <pre><code>example-repo\n\u251c\u2500\u2500 .git\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 ...\n\u251c\u2500\u2500 file1\n\u2514\u2500\u2500 file2\n...\n</code></pre> <p>Git repository consists of three \"trees\". The first one is your <code>Working Directory</code> or <code>Working Tree</code> where all the files you work with stay. The second one is the <code>Index</code> where you put files to be committed by issuing a <code>git add</code> command and finally the <code>HEAD</code> which points to the last commit you've made. <code>Index</code> and <code>HEAD</code> are stored in a <code>.git</code> subdirectory and you never interact with them directly.</p> <p>Git repository can be local or remote. All the changes you make to the working directory are stored in a local repository. The synchronization between local and remote repositories is always done manually.</p>"},{"location":"network-automation-101/04-technologies/03-git/#working-directory","title":"Working directory","text":"<p>Think of a Git working directory as a sandbox where you make changes to your project's files. Here is a good explanation from the official documentation:</p> <p>Finally, you have your working directory (also commonly referred to as the \u201cworking tree\u201d). The other two trees store their content in an efficient but inconvenient manner, inside the .git folder. The working directory unpacks them into actual files, which makes it much easier for you to edit them. Think of the working directory as a sandbox, where you can try changes out before committing them to your staging area (index) and then to history.</p>"},{"location":"network-automation-101/04-technologies/03-git/#staging","title":"Staging","text":"<p>When you want to put your changes to Git history, i.e. make a commit, you choose which files you want to commit and issue a <code>git add</code> on them. This way you can put changes in different files to different commits thus grouping them by their function or meaning. Staging also enables you to review your changes before committing.</p>"},{"location":"network-automation-101/04-technologies/03-git/#commit","title":"Commit","text":"<p>Commit saves staged changes to the local Git repository. It also includes metadata such as the author, the date of the commit, and a commit message.</p>"},{"location":"network-automation-101/04-technologies/03-git/#branch","title":"Branch","text":"<p>When you feel like adding a new feature or want to refactor the existing code it's a good idea to create a new branch, do your work there, and then merge it back to the main branch. This gives you confidence that you wouldn't break the existing code. It also allows different developers to work on the same codebase without blocking each other.</p> <p>Git branching is extremely lightweight and allows to create new branches and switch between them almost instantaneously.</p>"},{"location":"network-automation-101/04-technologies/03-git/#pull-merge-request","title":"Pull (merge) request","text":"<p>Pull (GitHub) or merge (GitLab) request is a feature specific to web-based Git-repository managers that provides a simple way to submit your work to the project. There is a lot of confusion about why it's called a pull request and not a push request as you want to add your changes to the repo. The reasoning behind this naming is simple. When you create a pull request you actually request the project's maintainer to pull your submitted changes to the repository.</p>"},{"location":"network-automation-101/04-technologies/03-git/#basic-usage","title":"Basic usage","text":""},{"location":"network-automation-101/04-technologies/03-git/#command-line","title":"Command line","text":"<p>To start using Git in the command line I recommend taking a look at this simple but useful guide for the beginners by Roger Dudler.</p>"},{"location":"network-automation-101/04-technologies/03-git/#dealing-with-mistakes","title":"Dealing with mistakes","text":"<p>Eventually, you will screw something up (e.g. make a commit to the wrong branch). For such situations, there is a good resource that can help with common Git headaches.</p>"},{"location":"network-automation-101/04-technologies/03-git/#gitignore","title":".gitignore","text":"<p>To make Git ignore specific files or even subdirectories you can list them in a special file called <code>.gitignore</code>. This is extremely useful when you want to keep your remote repository clean of temporary files or files containing sensitive information (e.g. passwords).</p>"},{"location":"network-automation-101/04-technologies/04-docker/","title":"Docker and containers","text":"<p>Linux containers have been around for quite a long time (and chroot and jail even longer) but Docker was what made it popular and accessible.</p> <p> </p> Containers <p>Containers allow to run software in an isolated environment, but contrary to VMs each container doesn't need a full-blown OS to run. This makes containers more resource-effective in terms of CPU, RAM, and storage not to mention that you don't need to maintain a separate OS for each container as with VMs.</p> <p>Docker (Docker Engine, to be precise) is a software that creates, deletes, and runs containers. You can think of it as similar to ESXi. Docker's ease of use is what made containers so popular.</p>"},{"location":"network-automation-101/04-technologies/04-docker/#why-use-docker","title":"Why use Docker?","text":"<p>What are the main reasons to use containers in general:</p> <ul> <li>Isolation   An application running inside a container has all the libraries of specific versions it needs. If another application needs other versions of the same libraries just use another container image.</li> <li>Portability   This comes as a result of the previous point. If you've managed to run your application inside a container you can easily run it anywhere where Docker is installed because the application environment doesn't change.</li> <li>Scalability   You can easily create lots of containers to distribute load between them (see Kubernetes)</li> <li>Performance   Faster to create, quicker to start, consume fewer resources.</li> <li>Community   There are millions of ready-made docker images on dockerhub which you can use directly or build your own images upon them.</li> </ul>"},{"location":"network-automation-101/04-technologies/04-docker/#basic-terminology","title":"Basic Terminology","text":"<p>To familiarize yourself with Docker you need to know the basic terminology and tools.</p> <p>Containerization topic is really huge and I don't want to go deep into technicalities here. If you want to learn more about Docker and containers I can recommend a book called Docker Deep Dive by Nigel Poulton\"</p>"},{"location":"network-automation-101/04-technologies/04-docker/#images","title":"Images","text":"<p>To continue the VM analogy you can think of Docker images as VM templates. An image contains all the necessary files to run a container and can hold predefined parameters, such as which TCP ports to expose. When you start a container you can override these parameters and add your own. You can run multiple containers from a single image. It is crucial to understand that containers themselves are ephemeral or stateless. This means that when you make any changes to the container's filesystem when it's running it won't persist after you restart that container. If you need persistency you should use external storage solutions such as volumes.</p>"},{"location":"network-automation-101/04-technologies/04-docker/#layers","title":"Layers","text":"<p>Docker images are made of layers. Essentially, a layer is a bunch of files created after running a command in a Dockerfile. If to build another image you use the same commands in a Dockerfile Docker will just reuse the previously created layer. This speeds up image building and saves storage space.</p>"},{"location":"network-automation-101/04-technologies/04-docker/#tags","title":"Tags","text":"<p>When you are using different versions of the same image you need a way to distinguish between them. That's where tags come in handy. When creating an image or pulling one from a repository you should specify a tag (e.g. python:3.8.5-slim-buster where 3.8.5-slim-buster is a tag), if you don't the <code>latest</code> tag will be used. Please note that <code>latest</code> has no special meaning, it's just a tag which not necessarily denotes the latest version of the image.</p>"},{"location":"network-automation-101/04-technologies/04-docker/#volumes","title":"Volumes","text":"<p>When starting a container you can specify directories or files to be mounted inside the container filesystem. Each such directory or file is called a volume. Volumes come in handy when you need the data to persist or to be shared among different containers. It's also an easy way to insert a custom config file into a container, or to use a container as a runtime environment for your script which is mounted inside a container so you can test it without the need to rebuild the container image.</p>"},{"location":"network-automation-101/04-technologies/04-docker/#dockerfiles","title":"Dockerfiles","text":"<p>Dockerfile is a text file with a set of instructions on how to build an image. It consists of the commands specifying such things as what another image should be used as a base image, what files to copy into the image, what packets to install, and so on.</p>"},{"location":"network-automation-101/04-technologies/04-docker/#docker-compose","title":"Docker Compose","text":"<p>Docker-compose is a simple orchestrator for Docker containers. To start several containers without docker-compose you need to type a lot of long commands with a multitude of arguments. Docker-compose allows you to specify all those arguments in a simple and clean manner of the YAML file. It also allows you to specify dependencies between containers, i.e. in what order they should start. But even if you need to run only one container it's better to write a <code>docker-compose.yml</code> just to place all those arguments on record.</p>"},{"location":"network-automation-101/04-technologies/04-docker/#docker-use-cases-for-network-automation","title":"Docker use cases for network automation","text":"<p>When talking about network automation Docker can come in handy in two major ways:</p> <ul> <li>You can build your own automation tools to run in Docker making them portable and automating the packaging process as a result.</li> <li>Most modern tools have dockerized versions that you can run by entering just one command. This one is really useful when you want to follow a tutorial or to try out a new tool but doesn't want to waste time on setup (which can be quite nontrivial)</li> </ul> <p>Here is a simple workflow to build and run your own Docker container:</p> <ul> <li>Write a <code>Dockerfile</code></li> <li>Write a <code>docker-compose.yml</code> file</li> <li>Run <code>docker-compose up</code></li> </ul> <p>There are tons of articles on how to write Dockerfiles and use docker-compose. But I guess at first you will use prebuilt images just to get familiar with Docker and you will need to know some basic CLI commands to start, stop. and monitor Docker containers. Here is a good write up on the essential Docker commands you will find useful from the start.</p>"},{"location":"network-automation-101/05-automation-tools/","title":"Automation Tools","text":"<p>Here I would like to give you a quick overview of the most popular and prominent network automation tools.</p>"},{"location":"network-automation-101/05-automation-tools/01-connection/","title":"Connection Management and CLI Scraping","text":""},{"location":"network-automation-101/05-automation-tools/01-connection/#netmiko","title":"Netmiko","text":"<p>Netmiko is a Python library based on paramiko and aimed to simplify SSH access to network devices. Created by Kirk Byers in 2014 this Python library stays the most popular and widely used tool for managing SSH connections to network devices.</p>"},{"location":"network-automation-101/05-automation-tools/01-connection/#scrapli","title":"Scrapli","text":"<p>Scrapli is a somewhat new python library (first release in 2019) that solves the same problems as Netmiko but aims to be \"as fast and flexible as possible\".</p>"},{"location":"network-automation-101/05-automation-tools/02-parsing/","title":"Parsing","text":""},{"location":"network-automation-101/05-automation-tools/02-parsing/#textfsm-and-ntc-templates","title":"TextFSM and NTC Templates","text":"<p>TextFSM is a Python module created by Google which purpose is to parse semi-formatted text (i.e. CLI output). It takes a template file and text as input and produces structured output. NTC templates is a collection of TextFSM templates for a variety of networking vendors. TextFSM can be used in conjunction with netmiko and scrapli.</p>"},{"location":"network-automation-101/05-automation-tools/02-parsing/#ttp-template-text-parser","title":"TTP (Template Text Parser)","text":"<p>TTP is the newest addition to the text parsing tools. It's also based on templates that resemble Jinja2 syntax but work in reverse. A simple TTP template looks much like the text it is aimed to parse but the parts you want to extract are put in {{ curly braces }}. It doesn't have a collection of prebuilt templates but given its relative ease of use, you can quickly create your own.</p>"},{"location":"network-automation-101/05-automation-tools/02-parsing/#pyats-genie","title":"PyATS &amp; Genie","text":"<p>These internal Cisco tools were publicly released a few years back and continue to develop rapidly. PyATS is a testing and automation framework. It has a lot to it and I encourage you to learn about it on Cisco DevNet resources. Here I would like to focus on two libraries within the PyATS framework: Genie parser and Dq. The first one as the name implies is aimed to parse CLI output and has a huge collection (2000+) of ready-made parsers for various devices (not limited to Cisco). The second one, Dq, is a great time saver when you need to access the parsed data. Often parsers such as Genie return data in complex data structures (e.g. nested dictionaries) and to access something you would need loops if statements and a strong understanding of where to look. With Dq, you can make queries without much caring of where in a nested structure your data resides.</p>"},{"location":"network-automation-101/05-automation-tools/03-configuring/","title":"Configuring devices","text":""},{"location":"network-automation-101/05-automation-tools/03-configuring/#napalm","title":"NAPALM","text":"<p>As the official documentation states</p> <p>NAPALM (Network Automation and Programmability Abstraction Layer with Multivendor support) is a Python library that implements a set of functions to interact with different network device Operating Systems using a unified API.</p>"},{"location":"network-automation-101/05-automation-tools/03-configuring/#supported-devices","title":"Supported devices","text":"<p>As of the time of writing NAPALM supported the following network operating systems:</p> <ul> <li>Arista EOS</li> <li>Cisco IOS</li> <li>Cisco IOS-XR</li> <li>Cisco NX-OS</li> <li>Juniper JunOS</li> </ul>"},{"location":"network-automation-101/05-automation-tools/03-configuring/#working-with-device-configuration","title":"Working with device configuration","text":"<p>With NAPALM you can push configuration and retrieve operational data from  devices. When manipulating device configuration you have two options:</p> <ul> <li>Replace the entire running configuration with a new one</li> <li>Merge the existing running configuration with a new one</li> </ul> <p>Replace and merge operations don't apply at once. Before committing the new configuration you can compare it to the currently running configuration and then either commit or discard it. And even after applying the new config, you have an option to rollback to the previously committed configuration if the network OS supports it. </p>"},{"location":"network-automation-101/05-automation-tools/03-configuring/#validating-deployment","title":"Validating deployment","text":"<p>The ability to retrieve operational data from devices brings a powerful NAPALM feature called compliance report or deployment validation. To get a compliance report you need to write a YAML file describing the desired state of the device and tell NAPALM to use it against the device with a <code>compliance_report</code> method.</p>"},{"location":"network-automation-101/05-automation-tools/03-configuring/#integration-with-other-tools","title":"Integration with other tools","text":"<p>Being a Python library NAPALM can be used directly in Python scripts or integrated with Ansible (napalm-ansible module), Nornir (nornir_napalm plugin) or SaltStack (native support).</p>"},{"location":"network-automation-101/05-automation-tools/03-configuring/#ansible","title":"Ansible","text":"<p>Ansible is a comprehensive automation framework initially developed to provision Linux servers. Due to its agentless nature, Ansible soon became very popular among network engineers. Contrary to the agent-based systems like Chef and Puppet, Ansible executes Python code on the target systems to perform its tasks. Therefore it only requires the target system to run SSH and Python. But how does it align with the network devices which cannot execute Python code? To solve this Ansible executes its network modules locally on the control node. </p>"},{"location":"network-automation-101/05-automation-tools/03-configuring/#ansible-galaxy","title":"Ansible Galaxy","text":"<p>To interact with different network platforms Ansible uses plugins grouped in collections. To install these collections you can use Ansible Galaxy which is like DockerHub or PyPi for Ansible, where users can share Ansible roles and plugins.</p>"},{"location":"network-automation-101/05-automation-tools/03-configuring/#terminology","title":"Terminology","text":"<p>Typical Ansible automation project consists of the following building blocks.</p>"},{"location":"network-automation-101/05-automation-tools/03-configuring/#inventory","title":"Inventory","text":"<p>Inventory file lists managed network devices, their hostnames or IP addresses, and optionally other variables like access credentials. Ansible can use Netbox as an inventory information source via a plugin.</p>"},{"location":"network-automation-101/05-automation-tools/03-configuring/#playbooks","title":"Playbooks","text":"<p>A playbook defines an ordered list of tasks to be performed against managed devices. It also can define which roles should be applied to devices.</p>"},{"location":"network-automation-101/05-automation-tools/03-configuring/#roles","title":"Roles","text":"<p>As the official documentation states</p> <p>Ansible roles are basically playbooks broken up into a known file structure.</p> <p>Roles allow you to group tasks and variables in separate directories. This makes an Ansible project more organized and lets you reuse those roles on different groups of managed hosts more easily.</p> <p>You can create roles according to different configuration sections: one for routing, another for basic settings such as NTP and DNS servers, etc. etc. Then you can apply those roles to different groups of devices. For example, routing is needed only on the core switches, and basic settings should be applied to all devices.</p>"},{"location":"network-automation-101/05-automation-tools/03-configuring/#pros-cons","title":"Pros &amp; Cons","text":"<p>Ansible uses its own DSL based on YAML to describe its playbooks logic. This design decision can be considered a two-edged sword. It requires minimal learning to solve simple tasks, but when you need to write something more complex it quickly becomes quite cumbersome and hard to debug.</p> <p>Speed and scalability are other aspects where Ansible doesn't shine in the context of network automation. </p> <p>In my opinion, Ansible is a great starting point for your network automation journey, as it is easy to learn and gives you a good idea of what modern automation tools are about. As John McGovern from CBT Nuggets said \"Ansible is like a CCNA for network automation\".</p> <p>Another Ansible advantage is that it can be used as a single automation solution for the whole IT infrastructure.</p>"},{"location":"network-automation-101/05-automation-tools/03-configuring/#nornir","title":"Nornir","text":"<p>Nornir was initially created by David Barroso, author of NAPALM.</p> <p>Nornir is an automation framework written in python to be used with python.</p> <p>Official Nornir documentation</p> <p>The last part of the definition is key here. Unlike Ansible, Nornir uses pure Python for describing its tasks (Nornir tasks are essentially Python functions). This makes Nornir far more flexible, fast, and easy to debug.</p> <p>Another aspect of Nornir being purely Python is that when you learn Nornir you also learn Python.</p> <p>Nornir is a pluggable system and starting with version 3.0 it comes only with the very basic plugins. A list of Nornir plugins can be found here. Plugins are installed with Python's standard package manager pip.</p> <p>Like Ansible, Nornir has a concept of inventory, which also can be written in YAML (YAMLInventory plugin), where you put host and group variables. You can also use existing Ansible inventory files (nornir_ansible) or take your inventory information directly from Netbox with nornir_netbox.</p> <p>To interact with network devices, Nornir can leverage NAPALM, netmiko, and scrapli libraries via respective plugins.</p>"},{"location":"network-automation-101/05-automation-tools/04-summary/","title":"Summary","text":"<p>All of the described tools have their advantages and use cases. I would recommend starting with more high-level tools such as NAPALM, Ansible, or Nornir.</p>"},{"location":"network-automation-101/06-text-editors/","title":"Text editors","text":"<p>A text editor is a piece of software you will spend most of your time with while automating networks. Here I would like to make an overview of the most popular modern text editors.</p>"},{"location":"network-automation-101/06-text-editors/#vs-code","title":"VS Code","text":"<p>Good or bad, but today's text editor market is clearly dominated by Visual Studio Code. It has a great and ever-expanding collection of plugins, nice UI, built-in Git support, intelligent code completion, you name it.</p> <p>VS Code is a free and open-source text editor built on Electron and owned by Microsoft. It was initially released in 2015.</p>"},{"location":"network-automation-101/06-text-editors/#atom","title":"Atom","text":"<p>Atom is another highly customizable open-source text editor created by GitHub. Since GitHub was acquired by Microsoft, Atom now is also a Microsoft product.</p> <p>Atom also is free, open-source, and built on Electron. It was initially released in 2014.</p>"},{"location":"network-automation-101/06-text-editors/#pycharm","title":"PyCharm","text":"<p>PyCharm is a full-blown Python IDE by JetBrains. I've heard a lot of praise towards it in the context of Python development, but never tried it myself. PyCharm is shipped in two versions: full-featured Professional ($89/year subscription license) and less functional but free Community Edition.</p> <p>PyCharm was initially released in 2010.</p>"},{"location":"network-automation-101/06-text-editors/#sublime-text","title":"Sublime Text","text":"<p>Sublime is the oldest text editor on the list. It has some great features to itself like multiline editing and \"Go To Anything\" command which allows to quickly jump to the specific part of the text in any open tab. It also can be extended with plugins, but the package manager is not included by default and you'll have to install it manually first.</p> <p>Sublime Text is a proprietary paid software written in C++ and initially released in 2008. It has a 30 day trial period. After that, you will be kindly reminded from time to time to buy an $80 license.</p>"},{"location":"network-automation-101/06-text-editors/#summary","title":"Summary","text":"<p>Learning to use a new text editor with all its shortcuts and plugins is a long-term time investment. If you haven't used any of these text editors I recommend picking VS Code as the most future-proof and well-rounded solution.</p>"},{"location":"blog/page/2/","title":"Blog","text":""}]}